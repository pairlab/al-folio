% =========
%  DOCS
entry types
patent
workshop
inproceedings
article
unpublished
misc

Fields (in addition to standard fields)
pdf - can be url or filetype.pdf
supplement -- can be url or filetype.pdf
poster -- can be url or filetype.pdf
slides -- can be url or filetype.pdf
video -- url
talk -- url -- use for talk video, otherwise use slides
html, 
code, 
blog, 
award, 
abstract, 
arxiv, 
degree (for thesis type)
% =========

% ==========
% Patents
% ==========
@patent{pouliot2014patient,
    title = {Patient-Specific Temporary Implants For Accurately Guiding Local Means of Tumor Control Along Patient-Specific Internal Channels to Treat Cancers},
    author ={Pouliot,Jean and Ken Goldberg, Hsu,I-Chow  and Cunha,J. Adam and  Garg, Animesh and  Patil, Sachin and  Abbeel, Pieter and Siauw,  Timmy},
    number = {US Patent 10,286,197},
    nationality = {US},
    yearfiled = {2019},
    monthfiled = {{May}},
    datefiled={14},
    html={https://patents.google.com/patent/US10286197B2/en}
}

@patent{lim2016precision,
  title={Precision injector/extractor for robot-assisted minimally-invasive surgery},
  author={Mckinley, Stephen and Garg, Animesh and Patil, Sachin and Lim, Susan ML and Goldberg, Ken},
  number = {U.S. Provisional. PCT International Application No.: PCT/US2016/039,026},
  nationality = {US},
  yearfiled={2016},
  monthfiled = {June},
  datefiled={23},
  note={WO Patent App. PCT/US2016/039,026},
  html={https://patents.google.com/patent/US20180177558A1/en}
}

@patent{mandlekar2024controlling,
  title={Controlling position of robot by determining goal proposals by using neural networks},
  author={Mandlekar, Ajay Uday and Ramos, Fabio Tozeto and Boots, Byron and Animesh, GARG and Fox, Dieter},
  yearfiled={2024},
  monthfiled = {apr},
  note={US Patent 11,958,529}
}

@patent{mandlekar2023methods,
  title={Methods and Systems to Remotely Operate Robotic Devices},
  author={Mandlekar, Ajay U and Zhu, Yuke and Animesh, GARG and Savarese, Silvio and Li, Fei-Fei},
  yearfiled={2023},
  monthfiled = {jul},
  datefiled={20},
  note={US Patent App. 17/755,587}
}

@patent{murali2023techniques,
  title={Techniques for robot control using neural implicit value functions},
  author={Murali, Adithyavairavan and Sundaralingam, Balakumar and Yun-Chun, CHEN and Fox, Dieter and Animesh, GARG},
  yearfiled={2023},
  monthfiled = {aug},
  datefiled={17},
  note={US Patent App. 17/856,699}
}

@patent{ramos2023predicting,
  title={Predicting object models},
  author={Ramos, Fabio Tozeto and Animesh, GARG and Jatavallabhula, Krishna Murthy and Macklin, Miles},
  yearfiled={2023},
  monthfiled = {dec},
  datefiled={14},
  note={US Patent App. 18/114,146}
}

@patent{singh2024prompt,
  title={Prompt generator for use with one or more machine learning processes},
  author={Singh, Ishika and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Animesh, GARG and Blukis, Valts},
  yearfiled={2024},
  monthfiled = {mar},
  datefiled={21},
  note={US Patent App. 18/122,594}
}

@patent{dvornik2024step,
  title={Step discovery and localization in instructional videos using a self-supervised transformer},
  author={Dvornik, Mikita and Hadji, Isma and Zhang, Ran and Derpanis, Konstantinos and Wildes, Richard and Animesh, GARG and Jepson, Allan Douglas},
  yearfiled={2024},
  monthfiled = {may},
  datefiled={23},
  note={US Patent App. 18/227,560}
}

@patent{garg2024scene,
  title={SCENE UNDERSTANDING USING LANGUAGE MODELS FOR ROBOTICS SYSTEMS AND APPLICATIONS},
  author={Garg, Animesh and Fox, Dieter and Hermans, Tucker Ryer and Liu, Weiyu},
  yearfiled={2024},
  monthfiled = {nov},
  datefiled={21},
  note={US Patent App. 18/319,546}
}

% ==========
% Workshops
% ==========

@workshop{mckinley2015autonomous,
  title={Autonomous Tumor Localization and Extraction: Palpation, Incision, Debridement and Adhesive Closure with the da Vinci Research Kit},
  author={McKinley, Stephen and Sen, Siddarth and Garg, Animesh and Jen, Yiming and Gealy, David and Abbeel, Pieter and Goldberg, Ken},
  booktitle={Hamlyn Surgical Robotics Conference, London},
  year={2015},
  month={jun},
  award={Best Video Award},
  video={https://www.youtube.com/watch?v=YiPq9t0tR3U}
}

@workshop{mckinley2015automated,
  title={Automated Delivery Instrument for Stem Cell Treatment Using the daVinci Robotic Surgical System},
  author={McKinley, Stephen and Garg, Animesh and Lim, Susan and Patil, Sachin and Goldberg, Ken},
  booktitle={Annual Meeting of the International Society for Stem Cell Research. Stockholm, Sweden.},
  year={2015},
  month={jun},
  poster={Stem-Cell-Delivery-Instrument-Poster-06-2015.pdf}
}

@workshop{garg15visual,
    title = {On Visual Feature Representations for Transition State Learning in Robotic Task Demonstrations},
    author = {Garg*, Animesh and Krishnan*, Sanjay and Murali, Adithyavairavan  and Darrell, Trevor and Abbeel, Pieter and Goldberg (* equal contribution), Ken},    
    booktitle = {{NIPS Workshop on Feature Extraction}},
    year={2015},
    month={dec},
    pdf={http://berkeleyautomation.github.io/tsc-dl/files/gkm-wk_nips15-tsc.pdf},
    html={http://berkeleyautomation.github.io/tsc-dl}
}

@workshop{krishnan2016hirl,
  title={{HIRL: Hierarchical inverse reinforcement learning for long-horizon tasks with delayed rewards}},
  author={Krishnan, Sanjay and Garg, Animesh and Liaw, Richard and Miller, Lauren and Pokorny, Florian T and Goldberg, Ken},
  journal={{R:SS 2016 Workshop on Bootstrapping Manipulation Skills}},
  year={2016},
  month={jul},
  arxiv={1604.06508}
}

@workshop{mandlekar17rldm,
  title={{Adversarially Robust Policy Learning through Active Construction of Physically-Plausible Perturbations}},
  author={Mandlekar*,Ajay and Zhu*, Yuke and Garg*, Animesh and Fei-Fei, Li and Savarese (* equal contribution), Silvio}, 
  booktitle={Multidisciplinary Conference on Reinforcement Learning and Decision Making (RLDM)},
  year={2017},
  pdf={http://www.princeton.edu/~ndaw/RLDM17ExtendedAbstracts.pdf#section*.69},
  month={jun}
}

@workshop{kuryenkov17corl,
  title={Towards Grasp Transfer using Shape Deformation.},
  author={Kuyenkov*, Andrey and Mehta*, Viraj and Ji, Jingwei and Garg, Animesh and Savarese (* equal contribution), Silvio},
  booktitle={Conference on Robot Learning (CoRL), workshop track},
  year={2017},
  month={nov},
  pdf={https://deformnet-site.github.io/DeformNet-website/files/corl.pdf},
  poster={corl17-deformnet_poster}
}

@workshop{xu17corl,
  title={Hierarchical Task Generalization with Neural Programs}, 
  author={Xu, Danfei and Zhu, Yuke and Gao, Julian and Garg, Animesh and Fei-Fei, Li and Savarese, Silvio},
  booktitle={Conference on Robot Learning (CoRL), workshop track},
  year={2017},
  month={nov},
  talk={https://youtu.be/_9Ny2ghjwuY?t=7h54m}
}


@workshop{xu17srssw,
  title={Hierarchical Task Generalization with Neural Programs}, 
  author={Xu, Danfei and Zhu, Yuke and Gao, Julian and Garg, Animesh and Fei-Fei, Li and Savarese, Silvio},
  booktitle={R:SS Workshop on New Frontiers for Deep Learning in Robotics},
  year={2017},
  month={jul},
  poster={files/ntp-rss17-ws.pdf}
}
  
@workshop{lee2019wkspcombining,
  title={Combining Model-Free and Model-Based Strategies for Sample-Efficient Reinforcement Learning},
  author={Lee, Michelle A. and Florensa, Carlos and Tremblay, Jonathan and Ratliff, Nathan and Garg, Animesh and Ramos, Fabio and Fox, Dieter},
  booktitle={Workshop on Robot Learning at NeurIPS},
  year={2019},
  month={dec},
  award={Best paper award at the workshop},
  pdf={http://www.robot-learning.ml/2019/files/papers/Guided%20Uncertainty-Aware%20Policy%20Optimization:%20Combining%20Learning%20and%20Model-Based%20Strategies%20for%20Sample-Efficient%20Policy%20Learning.pdf}
}

@workshop{portwoord2019turbulence,
  title={Turbulence forecasting via Neural ODE},
  author={Gavin Portwood and Peetak Mitra and Mateus Dias Ribeiro and Tan Minh Nguyen and Balasubramanya Nadiga and Juan Saenz and Micheal Chertkov and Animesh Garg and Anima Anandkumar and Andreas Dengel and Richard Baraniuk and David Schmidt},
  booktitle={Workshop on Machine Learning and the Physical Sciences at NeurIPS},
  year={2019},
  month={dec},
  pdf={https://ml4physicalsciences.github.io/2019/files/NeurIPS_ML4PS_2019_67.pdf}
}


@workshop{pitis2020wkspcounterfactual,
    title={Counterfactual Data Augmentation using Locally Factored Dynamics},
    author={Silviu Pitis and Elliot Creager and Animesh Garg},
    booktitle={Workshop on Object-Oriented Learning (OOL)  at ICML},
    year={2020},
    month={jul},
    poster={https://oolworkshop.github.io/program/ool_17.html},
    talk={https://slideslive.com/38930712/counterfactual-data-augmentationi-using-locally-factored-dynamics},
    code={https://github.com/spitis/mrl/tree/master/experiments/coda},
    award={Outstanding Paper Award at Object-Oriented Learning Workshop, ICML 2020},
}


@workshop{d2rl2020,
  title={D2RL: Deep Dense Architectures in Reinforcement Learning}, 
  author={Samarth Sinha and Homanga Bharadhwaj and Aravind Srinivas and Animesh Garg},
  booktitle={Workshop on Deep Reinforcement Learning (DRL) at Neurips},
  year={2020},
  month={Dec},
  arXiv = {2010.09163},
  html={https://sites.google.com/view/d2rl/home},
  talk={https://slideslive.com/38941315/d2rl-deep-dense-architectures-in-reinforcement-learning?ref=speaker-37161-latest},
  code={https://github.com/pairlab/d2rl},
  preview={d2rl-arxiv20.jpg},
  description={Architectures in RL do not need to be simple MLPs! Dense connections in both actor and critic improve representation learning and hence performance.}
}

@workshop{sinha2022uniform,
  title={Uniform Priors for Data-Efficient Transfer},
  author={Samarth Sinha and Karsten Roth and Anirudh Goyal and Marzyeh Ghassemi and Hugo Larochelle and Animesh Garg},
  booktitle={Workshop on Learning with Limited Labelled Data for Image and Video Understanding at CVPR},
  year={2022},
  month={jun},
  arXiv={2006.16524},
  talk={https://slideslive.com/38941948/uniform-priors-for-metalearning?ref=speaker-37161-latest},
  description={Features that are most transferable have high uniformity in the embedding space and propose a uniformity regularization scheme that encourages better transfer and feature reuse.}
}

@workshop{chen2022neural,
    title={Neural Motion Fields: Encoding Grasp Trajectories as Implicit Value Functions},
    author={Yun-Chun Chen and Adithyavairavan Murali and Balakumar Sundaralingam and Wei Yang and Animesh Garg and Dieter Fox},
    booktitle={Workshop on Implicit Representations for Robotic Manipulation at RSS},
    year={2022},
    arXiv={2206.14854},
    preview={nmf-rss22.jpg},
    description={Neural Motion Fields learns a value function that can be queried to generate reactive grasping.}
}

@workshop{islam2022offline,
      title={Offline Policy Optimization in RL with Variance Regularizaton}, 
      author={Riashat Islam and Samarth Sinha and Homanga Bharadhwaj and Samin Yeasar Arnob and Zhuoran Yang and Animesh Garg and Zhaoran Wang and Lihong Li and Doina Precup},
      year={2020},
      arXiv={2212.14405},
      booktitle={Workshop on Offline Reinforcement Learning at NeurIPS}
}


@workshop{zhou2023multi,
  title={Multi-Constraint Safe RL with Objective Suppression for Safety-Critical Applications},
  author={Zhou, Zihan and Booher, Jonathan and Liu, Wei and Petiushko, Aleksandr and Garg, Animesh},
  booktitle={Workshop on Machine Learning for Autonomous Driving (ML4AD)},
  year={2023}
}



@workshop{bagajo2024diffsim2real,
  title={DiffSim2Real: Deploying Quadrupedal Locomotion Policies Purely Trained in Differentiable Simulation},
  author={Bagajo, Joshua and Schwarke, Clemens and Klemm, Victor and Georgiev, Ignat and Sleiman, Jean-Pierre and Tordesillas, Jesus and Garg, Animesh and Hutter, Marco},
  booktitle={Workshop on Differentiable Optimization Everywhere at CoRL},
  arXiv={2411.02189},
  year={2024},
  month={nov}
}

% ==========
% Conferences
% ==========

@inproceedings{garg2011object,
  title={Object Identification and Mapping using Monocular Vision in an Autonomous Urban Driving System},
  author={Garg, Animesh and Toor, Anju and Thakkar, Sahil and Goel, Shiwangi and Maheshwari, Sachin and Chand, Satish},
  booktitle={International Conference of Machine Vision},
  year={2010}
}

@inproceedings{garg2012autotrix,
author = {Garg, Animesh and Toor, Anju and Thakkar, Sahil and Goel, Shiwangi and Maheshwari, Sachin and Chand, Satish},
title = {The Autotrix: Design and Implementation of an Autonomous Urban Driving System},
year = {2012},
month = {2feb},
ign-volume = {403},
ign-pages = {3884--3891},
booktitle = {MEMS, NANO and Smart Systems},
series = {Advanced Materials Research},
publisher = {Trans Tech Publications Ltd},
pdf = {10.4028/www.scientific.net/AMR.403-408.3884},
keywords = {Path Planning, Obstacle Avoidance, Monocular Vision, Autonomous Driving, Global Positioning System in Urban Driving},
abstract = {The Autotrix is an interactive, intelligent, Autonomous Guided Vehicle (AGV) designed to serve in urban environments. Autonomous ground vehicle navigation requires the integration of many technologies such as path planning, odometry, control, obstacle avoidance and situational awareness. The objective of this project is for this prototype to navigate autonomously in an urban environment and reach its destination while detecting and avoiding obstacles on the path .This will be achieved by extracting information from multiple sources of real-time data including digital camera, GPS &ultra sonic sensors, collecting data from this extracted information, processing this data and send controlling instructions to our platform (Autotrix). The significance of this work is in presenting the methods needed for real time navigation; GPS based continuous mapping and obstacle avoidance for intelligent autonomous driving systems.}
}

@inproceedings{thakkar2012dtmf,
author = {Thakkar, Sahil and Garg, Animesh and Midha, Adesh and Gaur, Prerna},
title = {Low-Cost Teleoperation of Remotely Located Actuators Based on Dual Tone Multi-Frequency Data Transfer},
year = {2012},
month = {feb},
ign-volume = {403},
ign-pages = {4727--4734},
booktitle = {MEMS, NANO and Smart Systems},
series = {Advanced Materials Research},
publisher = {Trans Tech Publications Ltd},
pdf = {10.4028/www.scientific.net/AMR.403-408.4727},
abstract = {DTMF (Dual Tone Multi Frequency) is a system of signal tones used for telecommunications. DTMF uses two tones to represent each key on the touch pad. DTMF data transfer technique has advantages such as high reliability, constant speed, and high signal to noise ratio, low cost and optimal utilization of existing resources. These features make DTMF an attractive Data Transfer Technique. It finds application in home and car security systems, robot control, SMS and voice call controlled industrial applications. In this paper, we discuss the use of DTMF data transfer in a voice call to control a toy car. Cell phone 1(CP 1), which is at user end, makes a call to cell phone 2(CP 2) at the machine end and establishes a connection. A key is pressed at the user side. Two tones corresponding to one key are encoded and sent through the cell phone network. Both tones are tapped through the earphone jack of cell phone at machine end and are decoded. The output is fed to a Micro-controller. The Micro-controller is connected to the remote control unit of the toy car, which in turn controls the motion of the car. The car moves in various directions according to the key pressed user. The electronic circuit is divided into 2 parts. The transmitter side consisting of Cell phone 1 with an inbuilt encoder and the receiver side consisting of Cell Phone 2, 8870 DTMF decoder and Atmega 16 micro-controller. The programming has been carried out on AVR Bascom®.}
}

@article{cunha2012robot,
  title={Robot-guided Delivery of Brachytherapy Needles along Non-Parallel Paths to Avoid Penile Bulb Puncture},
  author={Cunha, JAM and Garg, A and Siauw, T and Zhang, N and Zuo, Y and Goldberg, K and Stoianovici, D and Roach III, M and Pouliot, J},
  journal={Radiotherapy and Oncology},
  ign-volume={103},
  ign-pages={S45--S46},
  year={2012},
  month={may},
  publisher={Elsevier},
  pdf={https://www.thegreenjournal.com/article/S0167-8140(12)72081-9/abstract}
}

@article{cunha2012robotic,
  title={Robotic Brachytherapy Demonstration: Implant of {HDR} Brachytherapy Needle Configuration Computer-Optimized to Avoid Critical Structures Near the Bulb of the Penis},
  author={Cunha, JA and Siauw, T and Garg, A and Zhang, N and Goldberg, K and Stoianovici, D and Roach III, M and Hsu, I-C and Pouliot, J},
  journal={Medical Physics},
  ign-volume={39},
  ign-number={6},
  ign-pages={3931--3931},
  year={2012},
  month={jun},
  publisher={American Association of Physicists in Medicine},
  pdf={https://doi.org/10.1118/1.4736042}
}

@inproceedings{garg2012initial,
  title={Initial experiments toward automated robotic implantation of skew-line needle arrangements for HDR brachytherapy},
  shorttitle={automated needle implants},
  author={Garg, A. and Siauw, T. and Berenson, D. and Cunha, A. and Hsu, I-Chow and Pouliot, J. and Stoianovici, D. and Goldberg, K.},
  booktitle={IEEE International Conference  on Automation Science \& Engg. (CASE)},
  ing-pages={26--33},
  month={aug},
  year={2012},
  video={https://youtu.be/Kk_wHiu8nGg},
  talk={https://youtu.be/TGEIRpbuS_I},
  abstract={Automation seeks to improve the reliability and quality of processes. This study aims to automate high dose rate brachytherapy (HDR-BT), a radiation therapy that places radioactive sources at the site of the tumor using needles. Although HDR-BT has a high rate of clinical success in curing prostate cancer, it also has several side effects related to needle and dose trauma. A new planning algorithm from previous work optimizes needle arrangements using skew-lines (non-parallel, non-intersecting lines). This paper presents initial experiments towards an automated system for implanting skew-line needle arrangements computed from a planning system. We describe the interface, calibration and integration of the robotic hardware with the planning system, and present experiments using our robotic system to implant needles into anatomically-correct tissue phantoms. Results suggest that this system can achieve HDR-BT treatment objectives with reduced trauma to organs and low demands on operator skill, thus making the procedure more reliable and repeatable. In the future, we believe that robotic HDR-BT will improve overall treatment quality with reduced dependence on physician skill.},
  html={https://doi.org/10.1109/CoASE.2012.6386483},
  award={IEEE CASE Best Application Paper Award},
  preview={acubot-case12.gif}
}

@inproceedings{garg2013algorithm,
  title={An Algorithm for Computing Customized {3D} Printed Implants with Curvature Constrained Channels for Enhancing Intracavitary Brachytherapy Radiation Delivery},
  author={Garg, Animesh and Patil, Sachin and Siauw, Timmy and Cunha, J Adam M and Hsu, I and Abbeel, Pieter and Pouliot, Jean and Goldberg, Ken},
  booktitle={IEEE International Conference on Automation Science \& Engg. (CASE)},
  month={aug},
  ign-pages={466--473},
  year={2013},
  abstract={Brachytherapy is a widely-used treatment modality for cancer in many sites in the body. In brachytherapy, small radioactive sources are positioned proximal to cancerous tumors. An ongoing challenge is to accurately place sources on a set of dwell positions to sufficiently irradiate the tumors while limiting radiation damage to healthy organs and tissues. In current practice, standardized applicators with internal channels are inserted into body cavities to guide the sources. These standardized implants are one-size-fits-all and are prone to shifting inside the body, resulting in suboptimal dosages. We propose a new approach that builds on recent results in 3D printing and steerable needle motion planning to create customized implants containing customized curvature-constrained internal channels that fit securely, minimize air gaps, and precisely guide radioactive sources through printed channels. When compared with standardized implants, customized implants also have the potential to provide better coverage: more potential source dwell positions proximal to tumors. We present an algorithm for computing curvature-constrained channels based on rapidly-expanding randomized trees (RRT). We consider a prototypical case of OB/GYN cervical and vaginal cancer with three treatment options: standardized ring implant (current practice), customized implant with linear channels, and customized implant with curved channels. Results with a two-parameter coverage metric suggest that customized implants with curved channels can offer significant improvement over current practice.},
  pdf={},
  html={https://ieeexplore.ieee.org/document/6654002}
}

@article{siauw2014customized,
  title={{Customized Needle Guides for Inserting Non-Parallel Needle Arrangements in Prostate {HDR} Brachytherapy: A Phantom Study}},
  author={Siauw, Timmy and Cunha, J. Adam M. and Garg, Animesh and Goldberg, Ken and Hsu, I and Pouliot, Jean},
  journal={Brachytherapy},
  year={2014},
  month={mar},
  html={https://doi.org/10.1016/j.brachy.2014.02.439},
}

@inproceedings{garg2014exact,
  title={Exact Reachability Analysis for Planning Skew-Line Needle Arrangements for Automated Brachytherapy},
  author={Garg, Animesh and Siauw, Timmy and Yang, Guang and Patil, Sachin and Cunha, J Adam M and Hsu, I-Chow and Pouliot, Jean and Atamt{\"u}rk, Alper and Goldberg, Ken},
  booktitle={IEEE International Conference on Automation Science \& Engg. (CASE)},
  month={aug},
  year={2014},
  html={https://ieeexplore.ieee.org/document/6899376},
  abstract={When planning skew-line needle arrangements for automated brachytherapy, one objective is to identify a set of candidate needles that enter from a specified entry region, avoid specified organs-at-risk and sufficiently cover the target (tumor) volume. Existing methods use uniform or random sampling to generate a set of candidate needles, which may not adequately cover the target volume. In this paper we present an exact reachability analysis that can be used to guide the selection of candidate needles and to identify which subset of the target volume may not be reachable. Assuming linear needles, convex polyhedral representations of entry zone, organs-at-risk and target volume, we give an exact polynomial time algorithm for checking existence and calculation of the non-reachable set in the target volume. We perform experiments using patient data from 18 brachytherapy cases and found that 11 cases had non-empty occluded volume inside the target ranging from 0.01% to 4.3% of target volume. We also report a sensitivity study showing the change in the occluded volume with dilation of the avoidance volume and entry zone.}
}

@inproceedings{murali2015learning,
  title={Learning by Observation for Surgical Subtasks: Multilateral Cutting of {3D} Viscoelastic and {2D} Orthotropic Tissue Phantoms},
  author={Murali, Adithyavairavan and Sen, Siddarth and Kehoe, Ben and Garg, Animesh and McFarland, Seth and Patil, Sachin and Boyd, W Douglas and Lim, Susan and Abbeel, Pieter and Goldberg, Ken},
  booktitle={IEEE International Conference on Robotics \& Automation (ICRA)},
  month={may},
  year={2015},
  award={Finalist: Best Paper, Student Paper, and Medical Robotics Paper Award},
  abstract={Automating repetitive surgical subtasks such as suturing, cutting and debridement can reduce surgeon fatigue and procedure times and facilitate supervised tele-surgery. Programming is difficult because human tissue is deformable and highly specular. Using the da Vinci Research Kit (DVRK) robotic surgical assistant, we explore a “Learning By Observation” (LBO) approach where we identify, segment, and parameterize motion sequences and sensor conditions to build a finite state machine (FSM) for each subtask. The robot then executes the FSM repeatedly to tune parameters and if necessary update the FSM structure. We evaluate the approach on two surgical subtasks: debridement of 3D Viscoelastic Tissue Phantoms (3d-DVTP), in which small target fragments are removed from a 3D viscoelastic tissue phantom; and Pattern Cutting of 2D Orthotropic Tissue Phantoms (2d-PCOTP), a step in the standard Fundamentals of Laparoscopic Surgery training suite, in which a specified circular area must be cut from a sheet of orthotropic tissue phantom. We describe the approach and physical experiments with repeatability of 96% for 50 trials of the 3d-DVTP subtask and 70% for 20 trials of the 2d-PCOTP subtask.},
  html={https://ieeexplore.ieee.org/document/7139344},
  video={http://www.youtube.com/watch?v=beVWB6NtAaA},
  preview={lbo-icra15.gif}
}

@inproceedings{mckinley2015disposable,
  title={A Single-Use Haptic Palpation Probe for Locating Subcutaneous Blood Vessels in Robot-Assisted Minimally Invasive Surgery},
  author={McKinley, Stephen and Garg, Animesh and Sen, Siddarth and Kapadia, Rishi and Murali, Adithyavairavan and Nichols, Kirk and Lim, Susan and Patil, Sachin and Abbeel, Pieter and Okamura, Allison M. and Goldberg, Ken},
  booktitle= {IEEE International Conference on Automation Science \& Engg. (CASE)},
  month={aug},
  year={2015},
  award={Best Poster/Demo Award at ICRA 2015 Workshop on Shared Frameworks for Medical Robotics},
  pdf={http://berkeleyautomation.github.io/surgical-tools/files/mckinley-disposable-2015.pdf},
  abstract={We present the design and evaluation of a novel low-cost palpation probe for Robot assisted Minimally Invasive Surgery (RMIS) for localizing subcutaneous blood vessels. It measures probe tip deflection using a Hall Effect sensor as the spherical tip is moved tangentially across a surface under automated control. The probe is intended to be single-use and disposable, built from 3D printed parts and commercially available electronics. The prototype has a cross-section of less than 15mm×10mm and fits on the end of an 8mm diameter needle driver in the Intuitive Surgical da Vinci ® Research Kit (dVRK). We report experiments for quasi-static sliding palpation with silicone based tissue phantoms with embedded cylinders as subcutaneous blood vessel phantoms. We analyzed signal-to-noise ratios with multiple diameters of silicone cylinders (1.58-4.75 mm) at varying subcutaneous depths (1-5 mm) with a range of indentation depths (0-8 mm) and sliding speeds (0.5-21 mm/s). Results suggest that the probe can detect subcutaneous structures in phantoms of diameter 2.25 mm at a depth of up to 5mm below the tissue surface.},
  html={https://doi.org/10.1109/CoASE.2015.7294253},
  preview={sensor-case15.jpg}
  }

@inproceedings{krishnan2015tsc,
  title={Transition State Clustering: Unsupervised Surgical Trajectory Segmentation For Robot Learning},
  author={Krishnan*, Sanjay and Garg*, Animesh and Patil, Sachin and Lea, Colin and Hager, Gregory and Abbeel, Pieter and Goldberg (* equal contribution), Ken},
  booktitle={International Symposium on Robotics Research (ISRR)},
  year={2015},
  mon={sep},
  organization={Springer STAR},
  code={https://github.com/BerkeleyAutomation/tsc}
}

@inproceedings{murali2016tscdl,
  title={{TSC-DL:} Unsupervised Trajectory Segmentation of Multi-Modal Surgical Demonstrations with Deep Learning },
  author={Murali*, Adithyavairavan and Garg*, Animesh and Krishnan*, Sanjay and Pokorny, Florian and Abbeel, Pieter and Darrell, Trevor and Goldberg (* equal contribution), Ken},
  booktitle={IEEE International Conference on Robotics \& Automation (ICRA)},
  month={may},
  year={2016},
  html={http://berkeleyautomation.github.io/tsc-dl/},
  code={https://github.com/BerkeleyAutomation/tsc-dl},
  video={https://youtu.be/L561cJh7DLE}
}

@inproceedings{sen2016suturing,
  title={Automating Multi-Throw Multilateral Surgical Suturing with a Mechanical Needle Guide and Sequential Convex Optimization},
  author={Sen*, Siddarth and Garg*, Animesh and Gealy, David and McKinley, Stephen and Jen, Yiming and Goldberg (* equal contribution), Ken},
  booktitle={IEEE International Conference on Robotics \& Automation (ICRA)},
  month={may},
  year={2016},
  IGNOREorganization={IEEE},
  html={http://berkeleyautomation.github.io/amts/},
  video={https://youtu.be/z1ehShXFToc},
  preview={amts-icra16.gif}
}

@inproceedings{garg2016gpas,
  title={{Tumor localization using automated palpation with Gaussian Process Adaptive Sampling}},
  author={Garg, Animesh and Sen, Siddarth and Kapadia, Rishi and Jen, Yiming and McKinley, Stephen and Miller, Lauren and Goldberg, Ken},
  booktitle={IEEE International Conference on Automation Science \& Engg. (CASE)},
  year={2016},
  mon={aug},
  IGNOREorganization={IEEE},
  html={http://berkeleyautomation.github.io/gpas/},
  pdf={http://berkeleyautomation.github.io/gpas/files/garg-case16-gpas.pdf},
  preview={gpas-case16.jpg}
}

@inproceedings{mckinley2016pida,
  title={Interchangeable Surgical Instrument System with Application to Supervised Automation of Multilateral Tumor Resection. },
  author={McKinley, Stephen and Garg, Animesh and Sen, Siddarth and Gealy, David V. and McKinley, Jonathan and Jen, Yiming and Guo, Menglung and Boyd, Doug and Goldberg, Ken},
  booktitle={IEEE International Conference on Automation Science \& Engg. (CASE)},
  year={2016},
  month={aug},
  award={Best Video Award at 2015 Hamlyn Symposium},
  video={https://www.youtube.com/watch?v=YiPq9t0tR3U},
  html={http://berkeleyautomation.github.io/surgical-tools/},
  preview={pida-case16.gif}
}


@inproceedings{krishnan2016swirl,
  title={{SWIRL: A Sequential Windowed Inverse Reinforcement Learning Algorithm for Robot Tasks With Delayed Rewards}},
  author={Krishnan, Sanjay and Garg, Animesh and Liaw, Richard and Thananjeyan, Brijen and Miller, Lauren and Pokorny, Florian T and Goldberg, Ken},
  booktitle={Workshop on Algorithmic Foundations of Robotics (WAFR)},
  organization={Springer STAR},
  month={dec},
  year={2016},
  pdf={krishnan-SWIRL-WAFR-2016.pdf},
  talk={https://www.youtube.com/watch?v=r0RzS2DWb8M&index=4&list=PLYTiwx6hV33siv3qb--lW1Sw5BEMgGtR1},

}

@inproceedings{thananjeyan2017multilateral,
  title={Multilateral Surgical Pattern Cutting in 2D Orthotropic Gauze with Deep Reinforcement Learning Policies for Tensioning},
  author={Thananjeyan, Brijen and Garg, Animesh and Krishnan, Sanjay and Chen, Carolyn and Miller, Lauren and Goldberg, Ken},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  month={jun},
  video={https://www.youtube.com/watch?v=l6gQg2VbGcc},
  pdf={https://ieeexplore.ieee.org/document/7989275},
  year={2017}
}

@inproceedings{mandlekar2017arpl,
  title={{Adversarially Robust Policy Learning: Active Construction of Physically-Plausible Perturbations}},
  author={Mandlekar*,Ajay and Zhu*, Yuke and Garg*, Animesh and Fei-Fei, Li and  Savarese (* equal contribution), Silvio},
  booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},
  month={sep},
  year={2017},
  pdf={https://stanfordvl.github.io/ARPL/arpl_mzg_iros17.pdf},
  html={https://stanfordvl.github.io/ARPL/},
  video={https://www.youtube.com/watch?v=yZ-gSsbbzh0}
}


@inproceedings{gwak2017weakly,
  title={Weakly supervised 3D Reconstruction with Adversarial Constraint},
  author={Gwak*, JunYoung and Choy*, Christopher B and Garg, Animesh and Chandraker, Manmohan and Savarese (* equal contribution), Silvio},
  booktitle={IEEE Conference on 3D Vision (3DV)},
  year={2017},
  month={oct},
  code={https://github.com/jgwak/McRecon},
  arxiv={1705.10904} 
}


@inproceedings{harrison2017adapt,
  title={{AdaPT: Zero-Shot Adaptive Policy Transfer for Stochastic Dynamical Systems}},
  author={Harrison*, James and Garg*, Animesh and Ivanovic, Boris and Zhu, Yuke and Savarese, Silvio and Fei-Fei, Li and Pavone (* equal contribution), Marco},
  booktitle={International Symposium on Robotics Research (ISRR)},
  organization={Springer STAR},
  month={dec},
  year={2017},
  arxiv={1707.04674},
}

@inproceedings{xu2018neural,
  title={Neural Task Programming: Learning to generalize across hierarchical tasks},
  author={Xu, Danfei and Nair, Suraj and Zhu, Yuke and Gao, Julian and Garg, Animesh and Fei-Fei, Li and Savarese, Silvio},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  month={may},
  year={2018},
  arxiv={1710.01813},
  video={https://www.youtube.com/watch?v=THq7I7C5rkk&feature=youtu.be},
  html={https://stanfordvl.github.io/ntp/},
  talk={https://youtu.be/_9Ny2ghjwuY?t=7h54m},
  preview={ntp-icra18.gif}
}

@inproceedings{huang18ramil,
  title={{Finding It: Weakly-Supervised Reference-Aware Visual Grounding in Instructional Video}},
  author={Huang, De-An and Buch, Shyamal and Dery, Lucio and Garg, Animesh and  Fei-Fei, Li and Niebles, Juan Carlos},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month={jun},
  year={2018},
  talk={https://youtu.be/GBo4sFNzhtU?t=23m30s},
  award={Oral Presentation},
  html={https://finding-it.github.io/},
  poster={https://drive.google.com/file/d/1uvnw6VDn0r1nS3ePyFKaCbEx5GZw1ZEy/view},
  pdf={http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Finding_It_Weakly-Supervised_CVPR_2018_paper.pdf},
  supplement={https://finding-it.github.io/finding-it-suppmat.pdf},
  preview={finding-it-cvpr18.png}
}

@inproceedings{kurenkov2018deformnet,
  title={{DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction from a Single Image}},
  author={Kurenkov*, Andrey and Ji*, Jingwei and Garg, Animesh and Mehta, Viraj and Gwak, JunYoung and Choy, Christopher and Savarese (* equal contribution), Silvio},
  booktitle={IEEE Winter Conference on Applications of Computer Vision (WACV)},
  arXiv={1708.04672},
  month={mar},
  year={2018},
  html={https://deformnet-site.github.io/DeformNet-website/},
  talk={https://www.youtube.com/watch?v=cKzXVL6W--8}
}


@inproceedings{fang2018learning,
  title={Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision},
  author={Fang, Kuan and Zhu, Yuke and Garg, Animesh and Kurenkov, Andrey and Mehta, Viraj and Fei-Fei, Li and Savarese, Silvio},
  booktitle={{Robotics: Systems and Science (RSS)}},
  month={july},
  year={2018},
  arxiv={1806.09266},
  html={https://sites.google.com/view/task-oriented-grasp},
  video={https://www.youtube.com/watch?v=YI-3sf067f8},
  talk={https://youtu.be/v0ErAR8Dwy8?t=43s},
  preview={tog-rss18.png}
}

@inproceedings{mandlekar2018roboturk,
  title={{ROBOTURK: A Crowdsourcing Platform for Robotic Skill Learning through Imitation}},
  author={Mandlekar, Ajay and Zhu, Yuke and Garg, Animesh and Booher, Jonathan and Spero, Max and Tung, Albert and Gao, Julian and Emmons, John and Gupta, Anchit and Orbay, Emre and  Savarese, Silvio and Fei-Fei, Li},
  booktitle={Conference on Robot Learning (CoRL)},
  month={oct},
  year={2018},
  arxiv={1811.02790},
  pdf={http://proceedings.mlr.press/v87/mandlekar18a.html},
  html={http://roboturk.stanford.edu/},
  code={https://cvgl.stanford.edu/projects/roboturk/ccr-web/dataset_sim.html},
  blog={http://ai.stanford.edu/blog/roboturk/},
  talk={https://www.youtube.com/watch?v=ugCBLNLWDM8&t=24400s}
}

@inproceedings{lee2019making,
  title={Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks},
  author={Lee*, Michelle A and Zhu*, Yuke and Srinivasan, Krishnan and Shah, Parth and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Bohg (* equal contribution), Jeannette},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  arxiv={1810.10191},
  month={may},
  year={2019},
  award={ICRA Best Paper Award and Finalist: Best Cognitive Robotics Paper},
  html={https://sites.google.com/view/visionandtouch},
  video={https://youtu.be/usFQ8hNtE8c},
  preview={multimodal-icra19.gif}
}

@inproceedings{huang2018ntg,
  title={Neural Task Graphs: Generalizing to unseen tasks from a single video demonstration},
  author={Huang, De-An and Nair, Suraj and Xu, Danfei and Zhu, Yuke and Garg, Animesh and Fei-Fei, Li and Savarese, Silvio and Niebles, Juan Carlos},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  ign-pages={8565--8574},
  month={june},
  year={2019},
  arxiv={1807.03480},
  video={https://www.youtube.com/watch?v=Rwog52mbMCI&feature=youtu.be},  
  award={Oral Presentation},
  preview={ntg-cvpr19.png}
}

@inproceedings{danielczuk2019mech,
  title={Mechanical Search: Multi-Step Retrieval of a Target Object Occluded by Clutter},
  author={Danielczuk, Mike and Kurenkov, Andrey and Balakrishna, Ashwin and Matl, Matthew and Mart\'{i}n-Mart\'{i}n, Roberto and Garg, Animesh and Savarese, Silvio and Goldberg, Ken},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  month={may},
  year={2019},
  arxiv={1903.01588},
  html={https://ai.stanford.edu/mech-search/},
  video={https://youtu.be/lCwdGSDkbG4},
  abstract={When operating in unstructured environments such as warehouses, homes, and retail centers, robots are frequently required to interactively search for and retrieve specific objects from cluttered bins, shelves, or tables. Mechanical Search describes the class of tasks where the goal is to locate and extract a known target object. In this paper, we formalize Mechanical Search and study a version where distractor objects are heaped over the target object in a bin. The robot uses an RGBD perception system and control policies to iteratively select, parameterize, and perform one of 3 actions -- push, suction, grasp -- until the target object is extracted, or either a time limit is exceeded, or no high confidence push or grasp is available. We present a study of 5 algorithmic policies for mechanical search, with 15,000 simulated trials and 300 physical trials for heaps ranging from 10 to 20 objects. Results suggest that success can be achieved in this long-horizon task with algorithmic policies in over 95% of instances and that the number of actions required scales approximately linearly with the size of the heap.},
  preview={mechsearch-icra19.gif}
}

@inproceedings{martin2019variable,
  title={Variable Impedance Control in End-Effector Space: An Action Space for Reinforcement Learning in Contact-Rich Tasks},
  author={Mart{\'\i}n-Mart{\'\i}n, Roberto and Lee, Michelle A and Gardner, Rachel and Savarese, Silvio and Bohg, Jeannette and Garg, Animesh},
  booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},
  month={nov},
  year={2019},
  arxiv={1906.08880},
  html={https://stanfordvl.github.io/vices/}
}

@inproceedings{mandlekar2019roboturkreal,
  title={Scaling Robot Supervision to Hundreds of Hours with RoboTurk: Robotic Manipulation Dataset through Human Reasoning and Dexterity},
  author={Mandlekar, Ajay and Booher, Jonathan and Spero, Max and Tung, Albert and Gupta, Anchit and Zhu, Yuke and Garg, Animesh and Savarese, Silvio and Fei-Fei, Li},
  booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},
  award={IROS Best Cognitive Robotics Paper Finalist},
  month={nov},
  year={2019},
  arxiv={1911.04052},
  html={http://roboturk.stanford.edu/realrobotdataset},
  code={https://cvgl.stanford.edu/projects/roboturk/ccr-web/dataset_real.html},
  blog={http://ai.stanford.edu/blog/roboturk/},
  preview={roboturk-real-iros19.gif}
}

@inproceedings{huang2019continuous,
  title={Continuous Relaxation of Symbolic Planner for One-Shot Imitation Learning},
  author={Huang, De-An and Xu, Danfei and Zhu, Yuke and Garg, Animesh and Savarese, Silvio and Fei-Fei, Li and Carlos, Juan Carlos},
  booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},
  month={nov},
  year={2019},
  arxiv={1908.06769},
  video={https://www.youtube.com/watch?v=emSbxWlOQBc}
}

@inproceedings{fang2019dynamics,
  title={Dynamics Learning with Cascaded Variational Inference for Multi-Step Manipulation},
  author={Fang, Kuan and Zhu, Yuke and Garg, Animesh and Savarese, Silvio and Fei-Fei, Li},
  booktitle={Conference on Robot Learning (CoRL)},
  month={oct},
  year={2019},
  arxiv={1910.13395},
  html={http://pair.stanford.edu/cavin/},
  award={Oral Presentation},
  preview={cavin-corl19.gif}
}


@inproceedings{kurenkov2019ac,
  title={AC-Teach: A Bayesian Actor-Critic Method for Policy Learning with an Ensemble of Suboptimal Teachers},
  author={Kurenkov, Andrey and Mandlekar, Ajay and Mart\'{i}n-Mart\'{i}n, Roberto and Savarese, Silvio and Garg, Animesh},
  booktitle={Conference on Robot Learning (CoRL)},
  month={oct},
  year={2019},
  arxiv={1909.04121},
  blog={http://ai.stanford.edu/blog/acteach/},
  html={https://sites.google.com/view/acteach/},
  code={https://github.com/StanfordVL/ac-teach},
  preview={acteach-corl19.gif}
}

@inproceedings{losey2020controlling,
 title={{Controlling Assistive Robots with Learned Latent Actions}},
 author={Losey, Dylan P. and Srinivasan, Krishnan and Mandlekar, Ajay and Garg, Animesh and Sadigh, Dorsa},
 booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
 year={2020},
 month={May},
 arxiv={1909.09674},
 video={https://youtu.be/wjnhrzugBj4},
 talk={https://youtu.be/zsVK7dW2748},
 blog={http://ai.stanford.edu/blog/assistive-latent-spaces/},
 preview={lsc-icra20.gif},
 description={Learn a action space encoding from expert demonstrations, align the encoding with lower-dimension controller to enable efficient teleoperation.}
}


@inproceedings{mandlekar2020iris,
  title={IRIS: Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data},
  author={Ajay Mandlekar and Fabio Ramos and Byron Boots and Silvio Savarese and Li Fei-Fei and Animesh Garg and Dieter Fox},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2020},
  month={May},
  arxiv={1911.05321},
  video={https://youtu.be/H9KZgrI2I7I},
  html={https://sites.google.com/stanford.edu/iris/},
  talk={https://youtu.be/_7P41XHVHtM},
  preview={iris-icra20.gif},
  description={Offline demonstrations are both suboptimal and multimodal. Use two-stage model-learning: a high leven generative model to fit multi-modal state density, and a low-level imitation model for near optimal control.}
}

@inproceedings{huang2020motion,
  title={Motion Reasoning for Goal-Based Imitation Learning},
  author={De-An Huang and Yu-Wei Chao and Chris Paxton and Xinke Deng and Li Fei-Fei and Juan Carlos Niebles and Animesh Garg and Dieter Fox},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2020},
  month={May},
  arxiv={1911.05864},
  video={https://www.youtube.com/watch?v=OdqJuvAHvGE},
  preview={motion-reasoning-iros19.gif},
  description={Combine task & motion planning to disambiguate the true intention of the demonstrator from video where they performed multiple subtasks but only a subset was relevant to true objective, others were constraint satisfaction.}
}

@inproceedings{lee2020combining,
  title={Guided Uncertainty-Aware Policy Optimization: Combining Learning and Model-Based Strategies for Sample-Efficient Policy Learning},
  author={Lee, Michelle A. and Florensa, Carlos and Tremblay, Jonathan and Ratliff, Nathan and Garg, Animesh and Ramos, Fabio and Fox, Dieter},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2020},
  month={May},
  arXiv={2005.10872},
  video={https://youtu.be/NwMukXa8kys},
  talk={https://youtu.be/_RGBMdiSMgw},
  award={Best Paper Award at 2019 Neurips Workshop on Robot Learning},
  preview={guapo-icra20.jpg}
}

@inproceedings{nie2020semisupervised,
  title={Semi-Supervised StyleGAN for Disentanglement Learning},
  author={Weili Nie and Tero Karras and Animesh Garg and Shoubhik Debhath and Anjul Patney and Ankit B. Patel and Anima Anandkumar},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020},
  month={July},  
  arXiv={2003.03461},
  code={https://github.com/NVlabs/High-res-disentanglement-datasets},
  slides={https://docs.google.com/presentation/d/127ChXpeWUNXIOkf6Z6qB201BhnJUxZepK4mvtsq9ELM/edit?usp=sharing},
  talk={https://slideslive.com/38928035/semisupervised-stylegan-for-disentanglement-learning?ref=search},
  html={https://sites.google.com/nvidia.com/semi-stylegan},
  preview={s3gan-icml20.gif},
  description={Dientanglement in GANs with 0.25-2.5% labelled dataset for high-resolution fine-grained control over image generation.}
}

@inproceedings{chen2020avh,
  Author = {Beidi Chen and Weiyang Liu and Animesh Garg and Zhiding Yu and Anshumali Shrivastava and Jan Kautz and Anima Anandkumar},
  Title = {Angular Visual Hardness},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020},
  month={July}, 
  html={https://proceedings.icml.cc/paper/2020/hash/7cc5ca26d6fbb6db2b134ef07cc68925-Abstract.html},
  slides={https://icml.cc/media/Slides/icml/2020/virtual(no-parent)-14-15-00UTC-6648-angular_visual_.pdf},
  talk={https://slideslive.com/38928378/angular-visual-hardness?ref=search},
  arXiv = {1912.02279},
  preview={avh-icml20.jpg},
  description={Normalized angular distance between the sample feature embedding and the target classifier to measure sample hardness.}
}

@inproceedings{ren2020ocean,
  Author = {Hongyu Ren and Yuke Zhu and Jure Leskovec and Anima Anandkumar and Animesh Garg},
  Title = {Ocean: Online Task Inference for Compositional Tasks with Context Adaptation},
  booktitle={Conference on Uncertainty in Artificial Intelligence (UAI)},
  year={2020},
  month={August},
  pdf={http://www.auai.org/uai2020/proceedings/569_main_paper.pdf},
  arXiv={2008.07087},
  supplement={http://auai.org/uai2020/proceedings/569_supp.pdf},
  talk={https://www.youtube.com/watch?v=h7eDUUuxs_g&list=PLTrdDEfEeShmhkbbCtmaPst7f7CFll0kc&index=55},
  code={https://github.com/pairlab/ocean},
  preview={ocean-uai21.gif},
  description={A hierarchical latent variable prior that goes beyond vanilla gaussians to capture global and local context in sequential decision making for Meta-RL.}  
}

@inproceedings{kurenkov2020vismechsearch,
  title={{Visuomotor Mechanical Search: Learning to Retrieve Target Objects in Clutter}},
  author ={Kurenkov, Andrey and Taglic, Joseph and  Kulkarni, Rohun and Dominguez-Kuhne, Marcus and Garg, Animesh and Mart\'{i}n-Mart\'{i}n, Roberto and Saverese, Silvio},
  booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},
  html={https://ai.stanford.edu/mech-search/iros/},
  arXiv={2008.06073},
  month={oct},
  year={2020},
  talk={https://www.iros2020.org/ondemand/episode?id=1579&id2=Learning%20about%20objects%20and%20affordances&1604158157108},
  website={https://ai.stanford.edu/mech-search/},
  preview={visuomotor-ms-iros20.gif}

}


@inproceedings{da2020learning,
  Author = {Xingye Da and Zhaoming Xie and David Hoeller and Byron Boots and Animashree Anandkumar and Yuke Zhu and Buck Babich and Animesh Garg},
  Title = {{Learning a Contact-Adaptive Controller for Robust, Efficient Legged Locomotion}},
  booktitle={Conference on Robot Learning (CoRL)},
  Year = {2020},
  month={nov},
  video={https://www.youtube.com/watch?v=JJOmFZKpYTo},
  blog={https://news.developer.nvidia.com/contact-adaptive-controller-locomotion/},
  arXiv = {2009.10019},
  preview={adaptive-corl21.gif},
  description={}
}

@inproceedings{li2020vcdn,
  Author = {Yunzhu Li and Antonio Torralba and Animashree Anandkumar and Dieter Fox and Animesh Garg},
  Title = {{Causal Discovery in Physical Systems from Videos}},
  booktitle={Advances in Neural Information Processing Systems 33 (NeurIPS)},
  Year = {2020},
  month={dec},
  arXiv = {2007.00631},
  html={https://yunzhuli.github.io/V-CDN/},
  talk={https://slideslive.com/38937105/causal-discovery-in-physical-systems-from-videos},
  preview={vcdn-neurips20.gif},
  description={Learn the underlying generative model as a causal graph with a few frames of observation. Generalize across variable latent dynamics (both graph connectivity and parameters).}
}

@inproceedings{pitis2020counterfactual,
    title={Counterfactual Data Augmentation using Locally Factored Dynamics},
    author={Silviu Pitis and Elliot Creager and Animesh Garg},
    booktitle={Advances in Neural Information Processing Systems 33 (NeurIPS)},
    year={2020},
    month={dec},
    arXiv={2007.02863},
    talk={https://slideslive.com/38930712/counterfactual-data-augmentationi-using-locally-factored-dynamics},
    code={https://github.com/spitis/mrl/tree/master/experiments/coda},
    award={Outstanding Paper Award at Object-Oriented Learning Workshop, ICML 2020},
    preview={coda-neurips21.png}
}

@inproceedings{sinha2020cbs,
  title = {Curriculum By Smoothing},
  author = {Samarth Sinha and Animesh Garg and Hugo Larochelle},
  booktitle={Advances in Neural Information Processing Systems 33 (NeurIPS)},
  Year = {2020},
  month={dec},
  arXiv = {2003.01367},
  talk={https://slideslive.com/38937950/curriculum-by-smoothing?ref=speaker-37161-latest},
  award={Spotlight Talk},
  preview={cbs-neurips20.png},
  description={Curriculum deisgn to improve representation learning in CNN by restricting access to high frequency information until later in the training}
}

@inproceedings{sinha2021dibs,
  title={{DIBS: Diversity inducing Information Bottleneck in Model Ensembles}},
  author={Samarth Sinha and Homanga Bharadhwaj and Anirudh Goyal and Hugo Larochelle and Animesh Garg and Florian Shkurti},
  booktitle={Confernce on Artificial Intelligence (AAAI)},
  year={2021},
  arXiv={2003.04514},
  month={feb},
  primaryClass={cs.LG},
  preview={dibs-aaai21.jpg},
  description={Ensembles of deep nets to model uncertianty in modeling multi-modal data by encouraging diversity in prediction through adversarial loss for learning the stochastic latent variables}
}

@inproceedings{xie2021skill,
  title={{Latent Skill Planning for Exploration and Transfer}}, 
  author={Kevin Xie and Homanga Bharadhwaj and Danijar Hafner and Animesh Garg and Florian Shkurti},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021},
  month={may},
  arXiv = {2011.13897},
  html={https://sites.google.com/view/partial-amortization-hierarchy/home},
  talk={https://slideslive.com/38953774/latent-skill-planning-for-exploration-and-transfer},
  description={Combine benefits of learned world-model with a set of modular skills for faster online test-time adaptation. Use learned skills during planning stage improves both speed and data efficiency},
  preview={lsp-iclr21.jpg}
}

@inproceedings{naderian2021clearning,
  title={{C-Learning: Horizon-Aware Cumulative Accessibility Estimation}}, 
  author={Panteha Naderian and Gabriel Loaiza-Ganem and Harry J. Braviner and Anthony L. Caterini and Jesse C. Cresswell and Tong Li and Animesh Garg},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021},
  month={may},
  arXiv = {2011.12363},
  html={https://sites.google.com/view/learning-cae/},
  talk={https://slideslive.com/38953967/clearning-horizonaware-cumulative-accessibility-estimation},
  preview={clearning-iclr21.gif},
  description={Horizon-Aware policies trade off safety and performance while encoding multimodal solutions. Insight is to learn cumulative accessibility C(s,a,h) with time horizon h instead of the usual Q-function Q(s,a).}
}

@inproceedings{bharadhwaj2021csc,
  title={Conservative Safety Critics for Exploration}, 
  author={Homanga Bharadhwaj and Aviral Kumar and Nicholas Rhinehart and Sergey Levine and Florian Shkurti and Animesh Garg},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021},
  month={may},
  arXiv = {2010.14497},
  html={https://sites.google.com/view/conservative-safety-critics/home},
  talk={https://youtu.be/1E6wtSSL2Zs},
  preview={csc-iclr21.gif},
  description={We need to guarantee safety during training in RL. Instead of unintuitive specification of state based safety, we can learn safety as a separate value function, and can jointly optimize for task performance with safety value as a constraint.}
}

@inproceedings{bharadhwaj2021leaf,
  title={{LEAF: Latent Exploration Along the Frontier}},
  author={Homanga Bharadhwaj and Animesh Garg and Florian Shkurti},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2021},
  month={jun},
  day={1},
  arXiv={2005.10934},
  html={https://sites.google.com/view/leaf-exploration},
  preview={leaf-icra21.gif},
  description={Learn a dynamics aware manifold of reachable states, and then use this for guided exploration in hard continuous control tasks with RL.}
}

@inproceedings{pan2021emergent,
  title={{Emergent Hand Morphology and Control from Optimizing Robust Grasps of Diverse Objects}}, 
  author={Xinlei Pan and Animesh Garg and Animashree Anandkumar and Yuke Zhu},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2021},
  month={jun},
  day={1},
  arXiv = {2012.12209},
  html={https://xinleipan.github.io/emergent_morphology/},
  preview={labo-icra21.gif},
  description={A data-driven bayesian optimization approach to jointly optimize hand-design along with policy for grasping diverse objects in multiple modes.}
}

@inproceedings{allshire2021laser,
  title={{LASER: Learning a Latent Action Space for Efficient Reinforcement Learning}}, 
  author={Allshire, Arthur and Martin-Martin, Roberto and Lin, Charles and Mendes, Shawn and Savarese, Silvio and Garg, Animesh},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2021},
  month={jun},
  day={2},
  arXiv = {2103.15793},
  html={https://www.pair.toronto.edu/laser/},
  video={https://youtu.be/c3Vb-_2HSxk},
  preview={laser-icra21.jpg},
  description={Learn a lower dimensional action-space that results in efficient exploration in similar tasks.}
}

@inproceedings{xie2021dynamics,
  title={{Dynamics Randomization Revisited:A Case Study for Quadrupedal Locomotion}}, 
  author={Zhaoming Xie and Xingye Da and Michiel {van de Panne} and Buck Babich and Animesh Garg},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2021},
  month={jun},
  day={2},
  arXiv = {2011.02404},
  html={https://www.pair.toronto.edu/understanding-dr/},
  preview={dynrand-icra21.gif},
  description={Dynamics randomization is neither necessary nor sufficient for sim-to-real transfer of learning robust locomotion policies.}
}

@inproceedings{mahajan2021tesseract,
  title={{Tesseract: Tensorised Actors for Multi-Agent Reinforcement Learning}}, 
  author={Anuj Mahajan and Mikayel Samvelyan and Lei Mao and Viktor Makoviychuk and Animesh Garg and Jean Kossaifi and Shimon Whiteson and Yuke Zhu and Anima Anandkumar},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021},
  month={jul},
  day={14},  
  arXiv = {2106.00136},
  preview={tesseract-icml21.jpg},
  description={Tensorised formulation of the Bellman equation in Cooperative multi-agent RL is an effective solution to exponential blowup of the action space with the number of agents.}
}

@inproceedings{lutter2021cfvi,
  title={{Value Iteration in Continuous Actions, States and Time}}, 
  author={Michael Lutter and Shie Mannor and Jan Peters and Dieter Fox and Animesh Garg},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021},
  month={jul},
  day={16},  
  arXiv = {2105.04682},
  html={https://sites.google.com/view/value-iteration},
  preview={cfvi-icml21.jpg},
  description={RL in continuous states and actions can be solved with a closed-form extention of value iteration in cases of non-linear control-affine dynamics, resulting in a practical alternative to policy search.}
}

@inproceedings{bai2021exploration,
  title={{Principled Exploration via Optimistic Bootstrapping and Backward Induction}}, 
  author={Chenjia Bai and Lingxiao Wang and Lei Han and Jianye Hao and Animesh Garg and Peng Liu and Zhaoran Wang},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021},
  month={jul},
  day={15},    
  arXiv = {2105.06022},
  code={https://github.com/Baichenjia/OB2I},
  preview={ob2i-icml21.jpg},
  description={Improving exploration in RL through Optimistic Bootstrapping using UCB-bonus to capture epistemic uncertainty. Time-consistent uncertainty propagation through backward induction.}
}

@inproceedings{liu2021coach,
  title={{Coach-Player Multi-agent Reinforcement Learning for Dynamic Team Composition}}, 
  author={Bo Liu and Qiang Liu and Lei Han and Peter Stone and Animesh Garg and Yuke Zhu and Anima Anandkumar},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2021},
  month={jul}, 
  day={15},   
  arXiv = {2105.08692},
  award={Long Talk},
  preview={coach-icml21.jpg},
  description={Coordinating teams with time-varying composition and roles requires oversight from coach who can help with low-frequency updates to role assignments and team strategy.}
}

@inproceedings{heiden2021disect,
  title={{DiSeCT: A Differentiable Simulation Engine for Autonomous Robotic Cutting}}, 
  author={Eric Heiden and Miles Macklin and Yashraj Narang and Dieter Fox  and Animesh Garg and Fabio Ramos},
  booktitle={{Robotics: Systems and Science (RSS)}},
  year={2021},
  month={jul}, 
  day={17},   
  arXiv = {2105.12244},
  website= {https://diff-cutting-sim.github.io/},
  video={https://youtu.be/JEMLGq7eRLc},
  blog={https://developer.nvidia.com/blog/nvidia-research-disect-a-differentiable-simulation-engine-for-autonomous-robotic-cutting/},
  code={https://github.com/NVlabs/DiSECt},
  preview={disect-rss21.gif},
  award={Best Student Paper Award},
  description={Differenctiable Cutting made easy.}
}

@inproceedings{lutter2021rfvi,
  title={{Robust Value Iteration for Continuous Control Tasks}}, 
  author={Michael Lutter and Shie Mannor and Jan Peters and Dieter Fox and Animesh Garg},
  booktitle={{Robotics: Systems and Science (RSS)}},
  year={2021},
  month={jul}, 
  day={18},   
  arXiv = {2105.12189},
  html={https://sites.google.com/view/rfvi},
  preview={rfvi-rss21.jpg},
  description={Robustness to Sim2Real via Dynamic Programming based Value Iteration in Continuous time RL.}
}

@inproceedings{turpin2021gift,
  title={{GIFT: Generalizable Interaction-aware Functional Tool Affordances without Labels}}, 
  author={Dylan Turpin and Liquan Wang and Stavros Tsogkas and Sven Dickinson and Animesh Garg},
  booktitle={{Robotics: Systems and Science (RSS)}},
  year={2021},
  month={jul}, 
  day={18},   
  arXiv = {2106.14973},
  video={https://streamable.com/eylzdj},
  blog = {https://www.pair.toronto.edu/blog/2021/giftturpin/},
  preview={gift-rss21.gif},
  description={Interaction-aware affordance mapping to unsupervised keypoints for tool-use in different scenarios.}
}

@inproceedings{xiong2021lbw,
  title={{Learning by Watching: Physical Imitation of Manipulation Skills from Human Videos}}, 
  author={Haoyu Xiong and Quanzhou Li and Yun-Chun Chen and Homanga Bharadhwaj and Samarth Sinha and Animesh Garg},
  booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},
  month={sep},
  year={2021},
  arXiv = {2101.07241},
  html={https://www.pair.toronto.edu/lbw-kp/},
  video={https://youtu.be/Retu1q-BbEo},
  preview={lbw-arxiv21.gif},
  description={Style transfer human videos to robot perspective, then sparse unsupervised keypoints for reward estimation, use RL for model-free task completion.}
}

@inproceedings{transpareNet2021,
  title={{Seeing Glass: Joint Point-Cloud and Depth Completion for Transparent Objects}}, 
  author={Haoping Xu and Yi Ru Wang and Sagi Eppel and Alan Aspuru-Guzik and Florian Shkurti and Animesh Garg},
  year={2021},
  booktitle={Conference on Robot Learning (CoRL)},
  month={nov},
  arxiv={2110.00087},
  html={https://www.pair.toronto.edu/TranspareNet/},
  code={https://github.com/pairlab/TranspareNet},
  talk={https://www.youtube.com/watch?v=SuUMKy52b4E},
  award={Oral Presentation},
  preview={corl21-transparenet.gif},
  description={TraspareNet is a joint point cloud and depth completion method to recover learned depth of transparent objects in cluttered and complex scenes, even with partially filled fluid contents within the vessels}
}

@inproceedings{sinha2021s4rl,
  title={{S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning}}, 
  author={Samarth Sinha and Ajay Mandlekar and Animesh Garg},
  year={2021},
  booktitle={Conference on Robot Learning (CoRL)},
  month={nov},
  arXiv = {2103.06326},
  preview={s4rl-offline-rl-arxiv21.jpg},
  description={Data-augmentation with simple perturbations improve robustness, generalization, and OOD performance in Offline RL}
}

@inproceedings{blukis2021hlsm,
  title={{A Persistent Spatial Semantic Representation for High-level Natural Language Instruction Execution}}, 
  author={Valts Blukis and Chris Paxton and Dieter Fox and Animesh Garg and Yoav Artzi},
  year={2021},
  booktitle={Conference on Robot Learning (CoRL)},
  month={nov},
  arXiv = {2107.05612},
  html={https://hlsm-alfred.github.io/},
  poster={https://openreview.net/attachment?id=NeGDZeyjcKa&name=poster},
  code={https://github.com/valtsblukis/hlsm},
  preview={corl21-hlsm.gif},
  description={Data-augmentation with simple perturbations improve robustness, generalization, and OOD performance in Offline RL}
}

@inproceedings{bauer21rrc,
  title =    {Real Robot Challenge: A Robotics Competition in the Cloud},
  author =   {Bauer, Stefan and W{\"u}thrich, Manuel and Widmaier, Felix and Buchholz, Annika and Stark, Sebastian and Goyal, Anirudh and Steinbrenner, Thomas and Akpo, Joel and Joshi, Shruti and Berenz, Vincent and Agrawal, Vaibhav and Funk, Niklas and Urain De Jesus, Julen and Peters, Jan and Watson, Joe and Chen, Claire and Srinivasan, Krishnan and Zhang, Junwu and Zhang, Jeffrey and Walter, Matthew and Madan, Rishabh and Yoneda, Takuma and Yarats, Denis and Allshire, Arthur and Gordon, Ethan and Bhattacharjee, Tapomayukh and Srinivasa, Siddhartha and Garg, Animesh and Maeda, Takahiro and Sikchi, Harshit and Wang, Jilong and Yao, Qingfeng and Yang, Shuyu and McCarthy, Robert and Sanchez, Francisco and Wang, Qiang and Bulens, David and McGuinness, Kevin and O'Connor, Noel and Stephen, Redmond and Sch{\"o}lkopf, Bernhard},
  booktitle =    {Neural Information Processing Systems (NeurIPS) Competitions and Demonstrations Track},  
  year =   {2021},
  month =    {Dec},  
  pdf =    {https://proceedings.mlr.press/v176/bauer22a/bauer22a.pdf},
  arXiv = {2109.10957},
  preview={trifinger-report.jpg},
  description={A framework for democratizing multi-finger manipulation using a common hardware and software benchmark.}
}

@inproceedings{bai2021db,
  title={{Dynamic Bottleneck for Robust Self-Supervised Exploration}}, 
  author={Chenjia Bai and Lingxiao Wang and Lei Han and Animesh Garg and Jianye Hao and Peng Liu and Zhaoran Wang},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021},
  month={dec},
  arXiv = {2110.10735},
  preview={db-neurips21.jpg},
  description={Robust exploration via dynamic bottleneck-based representation and UCB-based bonus.}
}

@inproceedings{poli2021nha,
  title={{Neural Hybrid Automata: Learning Dynamics with Multiple Modes and Stochastic Transitions}}, 
  author={Michael Poli and Stefano Massaroli and Luca Scimeca and Seong Joon Oh and Sanghyuk Chun and Atsushi Yamashita and Hajime Asama and Jinkyoo Park and Animesh Garg},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021},
  month={dec},
  arXiv = {2106.04165},
  preview={nha-neurips21.jpg},
  description={A recipe for learning SHS dynamics without a priori knowledge on the number of modes and inter-modal transition dynamics. Method leverages Normalizing Flows and Stochastic ODEs.}
}

@inproceedings{dvornik2021dropdtw,
  title={{Drop-DTW: Aligning Common Signal Between Sequences While Dropping Outliers}}, 
  author={Nikita Dvornik and Isma Hadji and Konstantinos G. Derpanis and Animesh Garg and Allan D. Jepson},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021},
  month={dec},
  arXiv = {2108.11996},
  preview={drop-dtw21.jpg},
  description={Drop-DTW efficiently computes the optimal alignment between two variable-length sequences while automatically dropping the outlier elements from the matching.}
}

@inproceedings{zhang2022convergence ,
  title={{Convergence and Optimality of Policy Gradient Methods in Weakly Smooth Settings}}, 
  author={Matthew Shunshi Zhang and Murat Erdogdu and Animesh Garg},
  booktitle={Confernce on Artificial Intelligence (AAAI)},
  year={2022},
  month={feb},
  arXiv = {2111.00185},
  description={ Convergence analysis in RL relies on non-intuitive, impractical and often opaque conditions such as strict smoothness and bounded function approximation. In this work, we establish explicit convergence rates of policy gradient methods without relying on these conditions, instead extending the convergence regime to weakly smooth policy classes with L2 integrable gradient.}
}

@inproceedings{zhang2022marco,
  title={{Centralized Model and Exploration Policy for Multi-Agent RL}}, 
  author={Qizhen Zhang and Chris Lu and Animesh Garg and Jakob Foerster},
  booktitle={International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)},
  year={2022},
  month={april},
  arXiv = {2107.06434},
  award={Oral Presentation},
  preview={marco2021.jpg},
  description={Fully cooperative multi-agent settings (Dec-POMDPs) are fiendlishly hard. MARCO builds on the insight that using just a polynomial number of samples, it can learn a centralized model that generalizes across different policies.}
}

@inproceedings{bai2022pbrl,
  title={{Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning}}, 
  author={Chenjia Bai and Lingxiao Wang and Zhuoran Yang and Zhi-Hong Deng and Animesh Garg and Peng Liu and Zhaoran Wang},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022},
  month={may},
  date={8},
  arxiv={2202.11566},
  description={Generalization beyond dataset in offline RL: Uncertainty quantification via the disagreement of bootstrapped Q-functions, and pessimistic updates by penalizing the value function based on the estimated uncertainty},
  preview={res-pbrl-iclr22.jpg}
}

@inproceedings{voelcker2022vagram,
  title={{Value Gradient weighted Model-Based Reinforcement Learning}}, 
  author={Claas A Voelcker and Victor Liao and Animesh Garg and Amir-massoud Farahmand},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022},
  month={may},
  date={9},
  html={https://openreview.net/forum?id=4-D6CZkRXxI},
  arxiv={2204.01464},
  description={Value aware model learning to fix Objective Mismatch in Model-based RL. The gradient of the empirical value function as a measure of the sensitivity of the RL algorithm to model errors},
  preview={res-vagram-iclr22.jpg}
}

@inproceedings{xie2022shac,
  title={{Accelerated Policy Learning with Parallel Differentiable Simulation}}, 
  author={Jie Xu and Viktor Makoviychuk and Yashraj Narang and Fabio Ramos and Wojciech Matusik and Animesh Garg and Miles Macklin},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022},
  month={may},
  date={10},
  pdf={https://openreview.net/forum?id=ZSKRQMvttc},
  html={https://short-horizon-actor-critic.github.io/},
  description={A high-performance differentiable simulator and a new policy learning algorithm (SHAC) that can effectively leverage simulation gradients, even in the presence of non-smoothness},
  preview={res-shac-iclr22.jpg}
}

@inproceedings{sinha2022lfiw,
  title={Experience Replay with Likelihood-free Importance Weights},
  author={Samarth Sinha and Jiaming Song and Animesh Garg and Stefano Ermon},
  booktitle={Learning for Dynamics and Control (L4DC)},
  year={2022},
  month={jun},
  date={10},
  preview={lfiw-l4dc22.jpg},
  award={Best Paper Finlist},
  arXiv={2006.13169},
  description={A likelihood-free density ratio estimator to reweight experiences based on their likelihood under the stationary distribution of the current policy.}
}

@inproceedings{xie2022glide,
  title={{GLiDE: Generalizable Quadrupedal Locomotion in Diverse Environments with a Centroidal Model}}, 
  author={Zhaoming Xie and Xingye Da and Buck Babich and Animesh Garg and Michiel {van de Panne}},
  booktitle={Workshop on Algorithmic Foundations of Robotics (WAFR)},
  organization={Springer STAR},
  year={2022},
  month={jun},
  date={18},
  arXiv = {2104.09771},
  website= {https://www.pair.toronto.edu/glide-quadruped/},
  preview={glide-arxiv21.gif},
  description={Model-Free RL in centroidal model for desired body accelerations with subsequent computation of ground reaction forces using a robot model.}
}

@inproceedings{gorti2022xpool,
  title={{X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval}}, 
  author={Satya Krishna Gorti and Noel Vouitsis and Junwei Ma and Keyvan Golestan and Maksims Volkovs and Animesh Garg and Guangwei Yu},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022},
  month={jun},
  date={24},
  arxiv={2203.15086},
  preview={xpool-cvpr22.jpg},
  html={https://layer6ai-labs.github.io/xpool/},
  code={https://github.com/layer6ai-labs/xpool},
  description={Text to video retrieval with a scaled dot product attention for a text to attend to its most semantically similar frames.}
}

@inproceedings{yu2022mac,
  title={{Modular Action Concept Grounding in Semantic Video Prediction}}, 
  author={Wei Yu and Wenxin Chen and Songheng Yin and Steve Easterbrook and Animesh Garg},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022},
  month={jun},
  date={25},
  arXiv = {2011.11201},
  html={http://pair.toronto.edu/mac},
  preview={mac-arxiv21.gif},
  description={Object-Oriented semantic manipulation of scenes with unsupervised capsule networks which learn grounding of both objects and actions.}
}

@inproceedings{chen2022nsm,
  title={{Neural Shape Mating: Self-Supervised Object Assembly with Adversarial Shape Priors}}, 
  author={Yun-Chun Chen and Haoda Li and Dylan Turpin and Alec Jacobson and Animesh Garg},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022},
  month={jun},
  date={26},
  html={https://neural-shape-mating.github.io/},
  preview={nsm-cvpr22.jpg},
  description={Pairwise 3D geometric shape mating as general framework for part to part 3D pose matching for shape assembly.}
}

@inproceedings{weissenbacher2022icml,
  title={{Koopman Q-learning: Offline Reinforcement Learning via Symmetries of Dynamics}}, 
  author={Matthias Weissenbacher and Samarth Sinha and Animesh Garg and Yoshinobu Kawahara},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2022},
  month={jul},
  arXiv = {2111.01365},
  preview={koopman-rl-iclr22.jpg},
  description={Koopman Forward (Conservative) Q-learning (KFC): a model-free RL algorithm which uses the symmetries in the dynamics of the environment to guide data augmentation in Offline RL.}
}


@inproceedings{allshire2022trifinger,
  title={{Transferring Dexterous Manipulation from GPU Simulation to a Remote Real-World TriFinger}}, 
  author={Arthur Allshire and Mayank Mittal and Varun Lodaya and Viktor Makoviychuk and Denys Makoviichuk and Felix Widmaier and Manuel Wüthrich and Stefan Bauer and Ankur Handa and Animesh Garg},
  booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},
  year={2022},
  month={oct},
  date={20},
  arXiv = {2108.09779},
  html={https://s2r2-ig.github.io/},
  preview={s2r2-21.gif},
  description={A framework for learning a challenging dexterous manipulation task. The systems builds on IsaacGym for large scale simulation, keypoint based state representation and Cross-Atlantic remote sim2real to demonstrate the viability to scalability of robot learning.}
}

@inproceedings{articulated2021mittal,
  title={{Articulated Object Interaction in Unknown Scenes with Whole-Body Mobile Manipulation}}, 
  author={Mayank Mittal and David Hoeller and Farbod Farshidian and Marco Hutter and Animesh Garg},
  booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)},
  year={2022},
  month={oct},
  date={20},
  arXiv = {2103.10534},
  website= {https://www.pair.toronto.edu/articulated-mm/},
  preview={mm-articulated-arxiv21.gif},
  description={Predict expected keyframes of operating an articulated object, then plan for close-loop dyanmically-feasible whole-body motion to match predicted object trajectory.}
}


@inproceedings{turpin2022graspd,
  title={{Grasp'D: Differentiable Contact-rich Grasp Synthesis for Multi-fingered Hands}}, 
  author={Dylan Turpin and Liquan Wang and Eric Heiden and Yun-Chun Chen and Miles Macklin and Stavros Tsogkas and Sven Dickinson and Animesh Garg},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2022},
  month={Oct},
  date={25},
  arxiv={2208.12250},
  html={https://graspd-eccv22.github.io/},
  video={https://youtu.be/tkl_lywZ94o},
  code={https://github.com/dylanturpin/graspd},
  preview={graspd-eccv22.gif},
  award={Oral (Top 2.7\%)},
  description={Differentiable Contact Simulation enables more realistic denser contact multifinger grasping than grasp computation with analytical metrics.}
}

@inproceedings{nguyen2022infocnf,
  Author = {Tan M. Nguyen and Animesh Garg and Richard G. Baraniuk and Anima Anandkumar},
  Title = {InfoCNF: An Efficient Conditional Continuous Normalizing Flow with Adaptive Solvers},
  booktitle={IEEE Asilomar Conference on Signals, Systems, and Computers},
  Year = {2022},
  month={Nov},
  Day = {2},
  arXiv = {1912.03978},
  teaser = {infocnf-asilomar22.jpg},
  description = {InfoCNF is an efficient conditional CNF that partitions the latent space into a class-specific supervised code and an unsupervised code that shared among all classes for efficient use of labeled information}
}

@inproceedings{murathy2022bom,
  title={{Bayesian Object Models for Robotic Interaction with Differentiable Probabilistic Programming}},
  author={Krishna Murthy Jatavallabhula and Miles Macklin and Dieter Fox and Animesh Garg and Fabio Ramos},
  booktitle={Conference on Robot Learning (CoRL)},
  date={15},
  month={Dec},
  year={2022},
  pdf={https://openreview.net/forum?id=QSUsBMuw0uV},
  html={https://bayesianobjects.github.io/},
  description = {We present a differentiable probabilistic program that helps robots build mental representations of complex everyday objects.},
  preview={bom-corl22.jpg}
}


@inproceedings{xiong2022robotube,
  title={{RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments}},
  author={Haoyu Xiong and Haoyuan Fu and Jieyi Zhang and Chen Bao and Qiang Zhang and Yongxi Huang and Wenqiang Xu and Animesh Garg and Cewu Lu},
  booktitle={Conference on Robot Learning (CoRL)},
  date={16},
  month={Dec},
  year={2022},
  pdf={https://openreview.net/forum?id=SYUEnQtK85o},
  html={https://sites.google.com/view/robotube},
  video={https://youtu.be/oTnsZs7yOVc},
  description = {Reproducible and democratized benchmark for learning household robotic manipulation from 5000+ human videos. Also, a simulated twin environment RT-sim with matching assets for learning from these demonstrations.},
  award={Oral Presentation},
  preview={robotube-corl22.jpg}
}

@inproceedings{sellan2022breaking,
  title={{Breaking Bad: A Dataset for Geometric Fracture and Reassembly}}, 
  author={Silvia Sellán and Yun-Chun Chen and Ziyi Wu and Animesh Garg and Alec Jacobson},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks},
  year={2022},
  month={nov},
  day={30},
  arxiv={2210.11463},
  award={Featured Paper Presentation},
  pdf = {https://openreview.net/forum?id=mJWt6pOcHNy},
  html={https://breaking-bad-dataset.github.io/},
  preview={breaking-bad-neurips22.jpg},
  description={A large-scale dataset (1M+) of fractured objects to enable the study of fractured object reassembly and presents new challenges for geometric shape understanding.}
}

@inproceedings{zhang2022smpl,
  title={{SMPL: Simulated Industrial Manufacturing and Process Control Learning Environments}}, 
  author={Mohan Zhang and Xiaozhou Wang and Benjamin Decardi-Nelson and Bo Song and An Zhang and Jinfeng Liu and Sile Tao and Jiayi Cheng and Xiaohong Liu and Dengdeng Yu and Matthew Poon and Animesh Garg},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks},
  year={2022},
  month={nov},
  day={30},
  arXiv = {2206.08851},
  html={https://smpl-env.github.io/smpl-document/index.html},
  code={https://github.com/smpl-env/smpl},
  preview={smpl-neurips22.jpg},
  description={An easy-to-use library that includes five high-fidelity simulation environments for manufacturing processes and an extensive Offline and online RL Benchmark}
}

@inproceedings{pitis2022mocoda,
  title={{MoCoDA: Model-based Counterfactual Data Augmentation}}, 
  author={Silviu Pitis and Elliot Creager and Ajay Mandlekar and Animesh Garg},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022},
  month={nov},
  day={30},
  arXiv = {2210.11287},
  preview={mocoda-neurips22.jpg},
  description={MOCODA uses a locally factored model to create out-of-distribution data, and enable otherwise unsolvable tasks in offline RL.}
}

@inproceedings{zhou2023sea,
  title={{Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward}}, 
  author={Zihan Zhou and Animesh Garg},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023},
  month={may},
  day={4},  
  website= {https://openreview.net/forum?id=NDWl9qcUpvy},
  preview={sea-iclr23.jpg},
  description={Structured Exploration with Achievements (SEA), a multi-stage reinforcement learning algorithm that learns the environment structure with offline data and uses the learned structure to learn different skills and improve overall exploration with online environment interactions in a particular type of environment that has an internal achievement system.}
}

@inproceedings{wu2023slotformer,
  title={{SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models}}, 
  author={Ziyi Wu and Nikita Dvornik and Klaus Greff and Thomas Kipf and Animesh Garg},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023},
  month={may},
  day={4},   
  arXiv = {2210.05861},
  website= {https://slotformer.github.io/},
  preview={slotformer-iclr23.gif},
  description={A Transformer-based autoregressive model operating on learned object-centric representations. Evalaute on video prediction, Visual Question Answering (VQA), and goal-conditioned planning.}  
}

@inproceedings{singh2023progprompt,
  title={{ProgPrompt: Generating Situated Robot Task Plans using Large Language Models}}, 
  author={Ishika Singh and Valts Blukis and Arsalan Mousavian and Ankit Goyal and Danfei Xu and Jonathan Tremblay and Dieter Fox and Jesse Thomason and Animesh Garg},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023},
  month={may},
  day={30},
  arXiv = {2209.11302},
  website= {https://progprompt.github.io/},
  preview={progprompt-icra23.jpg},
  description={We present a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks. Our key insight is to prompt the LLM with program-like specifications of the available actions and objects in an environment, as well as with example programs that can be executed.}
}

@inproceedings{nerf2nerf,
  title={{nerf2nerf: Pairwise Registration of Neural Radiance Fields}}, 
  author={ Lily Goli and Daniel Rebain and Sara Sabour and Animesh Garg and Andrea Tagliasacchi},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023},
  month={may},
  day={30},
  arXiv = {2211.01600},
  website= {https://nerf2nerf.github.io/},
  code={https://github.com/nerf2nerf/nerf2nerf},
  preview={slotformer-iclr23.gif},
  description={We introduce a technique for pairwise registration of neural fields that extends classical optimization-based local registration (i.e. ICP) to operate on Neural Radiance Fields (NeRF) – neural 3D scene representations trained from collections of calibrated images.}
}

@inproceedings{wang2023actaim,
  title={{Self-Supervised Learning of Action Affordances as Interaction Modes}}, 
  author={Liquan Wang and Nikita Dvornik and Rafael Dubeau and Mayank Mittal and Animesh Garg},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023},
  month={may},
  day={30},
  website = {https://actaim.github.io/},
  preview={actaim-icra23.gif},
  description={We learn interaction modes as priors of useful interactions with articulated objects. In contrast to the prior art, we only use perception data from sensors in both training ad testing.}
}

@inproceedings{turpin2023fast,
  title={{Fast-Grasp'D: Dexterous Multi-finger Grasp Generation Through Differentiable Simulation}}, 
  author={Dylan Turpin and Tao Zhong and Shutong Zhang and Guanglei Zhu and Jingzhou Liu and Ritvik Singh and Eric Heiden and Miles Macklin and Stavros Tsogkas and Sven Dickinson and Animesh Garg},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023},
  month={may},
  day={30},
  website= {https://dexgrasp.github.io/},
  arXiv={2306.08132},
  preview={dexgrasp-icra23.jpg},
  video={https://youtu.be/1tBuHEsAf3Q},
  description={DexGrasp-1M: a large-scale dataset for multi-finger robotic grasping synthesized with FastGrasp’D, a novel diffferentiable grasping simulator. DexGrasp1M contains one million training examples for three (three, four and five-fingered) robotic hands, each with multimodal visual inputs (RGB+depth+segmentation, available in mono and stereo).}
}

@inproceedings{wang2023mvtrans,
  title={{MVTrans: Multi-View Perception of Transparent Objects}}, 
  author={Yi Ru Wang and Yuchi Zhao and Haoping XU and Sagi Eppel and Alan Aspuru-Guzik and Florian Shkurti and Animesh Garg},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023},
  month={may},
  day={30},
  arXiv={2302.11683},
  website= {https://ac-rad.github.io/MVTrans/},
  video={https://youtu.be/8Qdc_xWVp-k},
  preview={mvtrans-icra23.jpg},
  description={MVTrans is an end-to-end multi-view architecture with multiple perception capabilities, including depth estimation, segmentation, and pose estimation. We also present a procedural photo-realistic large-scale transparent object detection dataset, Syn-TODD.}
}


@inproceedings{wu2023slotdiffusion,
  title={Slotdiffusion: Object-centric generative modeling with diffusion models},
  author={Wu, Ziyi and Hu, Jingyu and Lu, Wuyue and Gilitschenski, Igor and Garg, Animesh},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023},
  month={dec},
  ign-volume={36},
  ign-pages={50932--50958},
  arxiv={2305.11281},
  website={https://slotdiffusion.github.io/},
}

@inproceedings{liu2023composable,
  title={Composable part-based manipulation},
  author={Liu, Weiyu and Mao, Jiayuan and Hsu, Joy and Hermans, Tucker and Garg, Animesh and Wu, Jiajun},
  booktitle={Conference on Robot Learning},
  year={2023},
  month={nov},
  arxiv={2405.05876},
  wesite={https://cpmcorl2023.github.io/}
}

@inproceedings{attarian2023geometry,
  title={Geometry Matching for Multi-Embodiment Grasping},
  author={Attarian, Maria and Asif, Muhammad Adil and Liu, Jingzhou and Hari, Ruthrash and Garg, Animesh and Gilitschenski, Igor and Tompson, Jonathan},
  booktitle={Conference on Robot Learning},
  year={2023},
  month={nov},
  arxiv={2312.03864},
  website={https://geo-match.github.io/},
  code={https://github.com/google-deepmind/geomatch}
}


@inproceedings{zhang2024handypriors,
  title={Handypriors: Physically consistent perception of hand-object interactions with differentiable priors},
  author={Zhang, Shutong and Qiao, Yi-Ling and Zhu, Guanglei and Heiden, Eric and Turpin, Dylan and Liu, Jingzhou and Lin, Ming and Macklin, Miles and Garg, Animesh},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2024},
  month={may},
  arxiv={2311.16552},
  website={https://handypriors.github.io/},
}


@inproceedings{2023open,
  title={Open X-Embodiment: Robotic learning datasets and RT-X models},
  author={Open X-Embodiment Collaboration},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2024},
  month={may},
  website={https://open-x-embodiment.github.io/},
  award_name={ICRA Best Paper},
  award={ICRA Best Paper Award}
}


@inproceedings{yu2024orbit,
  title={ORBIT-Surgical: An Open-Simulation Framework for Learning Surgical Augmented Dexterity},
  author={Yu, Qinxi and Moghani, Masoud and Dharmarajan, Karthik and Schorp, Vincent and Panitch, William Chung-Ho and Liu, Jingzhou and Hari, Kush and Huang, Huang and Mittal, Mayank and Goldberg, Ken and Animesh Garg},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  arXiv={2404.16027},
  year={2024},
  arxiv={2404.16027},
  website={https://orbit-surgical.github.io/},
  code={https://github.com/orbit-surgical/orbit-surgical}
}


@inproceedings{georgiev2024adaptive,
  title={Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich Differentiable Simulation},
  author={Georgiev, Ignat and Srinivasan, Krishnan and Xu, Jie and Heiden, Eric and Garg, Animesh},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  year={2024},
  month={jul},
  organization={PMLR 235:15418-15437},
  arxiv={2405.17784},
  website={https://adaptive-horizon-actor-critic.github.io},
}


@inproceedings{walker2024fast,
  title={Fast Explicit-Input Assistance for Teleoperation in Clutter},
  author={Walker, Nick and Yang, Xuning and Garg, Animesh and Cakmak, Maya and Fox, Dieter and P{\'e}rez-D’Arpino, Claudia},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  ign-pages={9270--9276},
  year={2024},
  month={oct},
  organization={IEEE},
  arxiv={2402.02612}
}

@inproceedings{moghani2024sufia,
  title={SuFIA: Language-Guided Augmented Dexterity for Robotic Surgical Assistants},
  author={Moghani, Masoud and Doorenbos, Lars and Panitch, William Chung-Ho and Huver, Sean and Azizian, Mahdi and Goldberg, Ken and Garg, Animesh},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  arXiv={2405.05226},
  year={2024},
  month={oct},
  arxiv={2405.05226},
  website={https://orbit-surgical.github.io/sufia/}
}


@inproceedings{wang2024discovering,
  title={Discovering Robotic Interaction Modes with Discrete Representation Learning},
  author={Wang, Liquan and Goyal, Ankit and Xu, Haoping and Garg, Animesh},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024},
  month={nov},
  arxiv={2410.20258},
  website={https://actaim2.github.io/},
  video={https://actaim2.github.io/static/videos/corl_video.mp4}
}

@inproceedings{zhou2024spire,
  title={SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for Long-Horizon Manipulation},
  author={Zhou, Zihan and Garg, Animesh and Fox, Dieter and Garrett, Caelan Reed and Mandlekar, Ajay},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024},
  month={nov},
  website={https://sites.google.com/view/spire-corl-2024},
  arxiv={2410.18065}
}

@inproceedings{mu2024adademo,
  title={AdaDemo: Data-Efficient Demonstration Expansion for Generalist Robotic Agent},
  author={Mu, Tongzhou and Guo, Yijie and Xu, Jie and Goyal, Ankit and Su, Hao and Fox, Dieter and Garg, Animesh},
  arXiv={2404.07428},
  booktitle={International Symposium on Robotics Research (ISRR)},
  year={2024},
  month={dec}
}

@inproceedings{mete2024quest,
  title={Quest: Self-supervised skill abstractions for learning continuous control},
  author={Mete, Atharva and Xue, Haotian and Wilcox, Albert and Chen, Yongxin and Garg, Animesh},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  ign-volume={37},
  ign-pages={4062--4089},
  year={2024},
  month={dec},
  arxiv={https://arxiv.org/abs/2407.15840},
  website={https://quest-model.github.io/}
}

@inproceedings{georgiev2024pwm,
  title={PWM: Policy Learning with Large World Models},
  author={Georgiev, Ignat and Giridhar, Varun and Hansen, Nicklas and Garg, Animesh},
  booktitle={International Conference on Learning Representations (ICLR)},
  arXiv={2407.02466},
  year={2025},
  month={apr},
  website={https://www.imgeorgiev.com/pwm/},
  keywords={Reinforcement Learning, World Models, Policy Learning}
}

@inproceedings{yu2024egosim,
  title={EgoSim: Egocentric Exploration in Virtual Worlds with Multi-modal Conditioning},
  author={Yu, Wei and Yin, Songheng and Easterbrook, Steve and Garg, Animesh},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2025},
  month={apr},
  website={https://egosim.github.io/EgoSim/},
  html={https://openreview.net/forum?id=zAyS5aRKV8}
}


@inproceedings{byrnes2024climb,
  title={CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building},
  author={Byrnes, Walker and Bogdanovic, Miroslav and Balakirsky, Avi and Balakirsky, Stephen and Garg, Animesh},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  arXiv={2410.13756},
  year={2025},
  month={may},
  website={https://plan-with-climb.github.io/}
}

@inproceedings{ameperosa2024rocoda,
  title={RoCoDA: Counterfactual Data Augmentation for Data-Efficient Robot Learning from Demonstrations},
  author={Ameperosa, Ezra and Collins, Jeremy A and Jain, Mrinal and Garg, Animesh},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  arXiv={2411.16959},
  year={2025},
  month={may},
  website={https://rocoda.github.io/},
}


% ==========
% Journal
% ==========

@article{garg2013robot,
author={Garg, Animesh and Siauw, Timmy and Berenson, Dmitry and Cunha, J Adam M and Hsu, I-C and Pouliot, Jean and Stoianovici, Dan and Goldberg, Ken},
  journal={IEEE Transactions on Automation Science and Engineering (T-ASE)},
  title={Robot-Guided Open-Loop Insertion of Skew-Line Needle Arrangements for High Dose Rate Brachytherapy},
  year={2013},
  abstract={We present a study in human-centered automation that has potential to reduce patient side effects from high dose rate brachytherapy (HDR-BT). To efficiently deliver radiation to the prostate while minimizing trauma to sensitive structures such as the penile bulb, we modified the Acubot-RND 7-axis robot to guide insertion of diamond-tip needles into desired skew-line geometric arrangements. We extend and integrate two algorithms: Needle Planning with Integer Programming (NPIP) and Inverse Planning with Integer Programming (IPIP) to compute skew-line needle and dose plans. We performed three physical experiments with anatomically correct phantom models to study performance: two with the robot and one control experiment with an expert human physician (coauthor Hsu) without the robot. All were able to achieve needle arrangements that meet the RTOG-0321 clinical dose objectives with zero trauma to the penile bulb. We analyze systematic and random errors in needle placement; total RMS error for the robot system operating without feedback ranged from 2.6 to 4.3 mm, which is comparable to the RMS error of 2.7 mm obtained in an earlier study for PPI-BT treatment using a robot with 3D ultrasound feedback.},
  pdf={https://doi.org/10.1109/TASE.2013.2276940},
  month={Oct},
}

@article{mellis2015material,
  title={Evaluation of PC‐ISO for customized, 3D printed, gynecologic 192Ir HDR brachytherapy applicators},
  author={Mellis, Katherine and Siauw, Timmy and Sudhyadhom, Atchar and Sethi, Rajni and Hsu, I-Chow and Pouliot, Jean and Garg, Animesh and Goldberg, Ken},
  journal={Journal of Applied Clinical Medical Physics (JACMP)},
  year={2015},
  mon={jan},
  html={https://www.ncbi.nlm.nih.gov/pubmed/25679174}
}

@article{tsc-ijrr17,
  author = {Krishnan*, Sanjay and Garg*, Animesh and Patil, Sachin and Lea, Colin and Hager, Gregory and Abbeel, Pieter and Goldberg (* equal contribution), Ken},
  title ={{Transition State Clustering: Unsupervised surgical trajectory segmentation for robot learning}},
  journal = {International Journal of Robotics Research (IJRR)},
  year = {2017},
  month={dec},
  pdf = {https://dl.acm.org/doi/abs/10.1177/0278364917743319},
  code={https://github.com/BerkeleyAutomation/tsc}
}

@article{swirl-ijrr18,
  title={{SWIRL: A Sequential Windowed Inverse Reinforcement Learning Algorithm for Robot Tasks With Delayed Rewards}},
  author={Krishnan, Sanjay and Garg, Animesh and Liaw, Richard and Thananjeyan, Brijen and Miller, Lauren and Pokorny, Florian T and Goldberg, Ken},
  journal={International Journal of Robotics Research (IJRR)},
  year={2018},
  month={jul},
  pdf={garg_swirl_ijrr18.pdf},
  html={https://doi.org/10.1177%2F0278364918784350}
}


@article{fang2018tog-ijrr,
  title={Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision},
  author={Fang, Kuan and Zhu, Yuke and Garg, Animesh and Kurenkov, Andrey and Mehta, Viraj and Fei-Fei, Li and Savarese, Silvio},
  journal = {International Journal of Robotics Research (IJRR)},
  month={aug},
  year={2019},
  video={https://www.youtube.com/watch?v=YI-3sf067f8},
  html={https://sites.google.com/view/task-oriented-grasp},
  pdf={https://doi.org/10.1177%2F0278364919872545},
}

@article{lee2020making,
  title={Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks},
  author={Michelle A. Lee and Yuke Zhu and Peter Zachares and Matthew Tan and Krishnan Srinivasan and Silvio Savarese and Li Fei-Fei and Animesh Garg and Jeannette Bohg},
  year={2020},
  month={mar},
  arXiv={1907.13098},
  html={https://sites.google.com/view/visionandtouch},
  journal={IEEE Transactions on Robotics (T-RO)},
  preview={lee-tro20-making.png}
}

@article{joseph2020condensa,
  Author = {Vinu Joseph and Ganesh Gopalakrishnan and Saurav Muralidharan and Michael Garland and Animesh Garg},
  journal={IEEE Micro}, 
  title={A Programmable Approach to Neural Network Compression}, 
  year={2020},
  month={aug},
  pdf={https://ieeexplore.ieee.org/document/9151283},
  arXiv = {1911.02497},
  code={https://github.com/NVlabs/condensa},
  html={https://sites.google.com/view/condensa-bo/home},
  description={Demystifying network compression: user inputs pretrained model, compression scheme, objective and constraints. Condensa uses bayesian optimization to infer optimal sparsity ratio and corresponding compressed model.},
  preview={condensa-micro20.jpg}
}
  
@article{dundar2021pami,
  Author = {Aysegul Dundar and Kevin J. Shih and Animesh Garg and Robert Pottorf and Andrew Tao and Bryan Catanzaro},
  journal={Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)}, 
  Title = {Unsupervised Disentanglement of Pose, Appearance and Background from Images and Videos},
  Year = {2021},
  month={jan},
  arXiv = {2001.09518},
  code={https://github.com/NVIDIA/UnsupervisedLandmarkLearning},
  preview={unsup-kp-pami21.gif}
}

@article{losey2021auro,
  Author = {Dylan P. Losey and Hong Jun Jeon and Mengxi Li and Krishnan Srinivasan and Ajay Mandlekar and Animesh Garg and Jeannette Bohg and Dorsa Sadigh},
  journal={Autonomous Robots (AURO)}, 
  Title = {Learning Latent Actions to Control Assistive Robots},
  Year = {2021},
  month={aug},
  arXiv = {2107.02907},
  preview={losey_auro2021.png}
}

@article{sun2022plate,
  title={{PlaTe: Visually-Grounded Planning with Transformers in Procedural Tasks}}, 
  author={Jiankai Sun and De-An Huang and Bo Lu and Yun-Hui Liu and Bolei Zhou and Animesh Garg},
  year={2022},
  month={may},
  date={30},
  journal={IEEE Robotics and Automation Letters (RA-L) and ICRA}, 
  arXiv = {2109.04869},
  html={https://www.pair.toronto.edu/plate-planner/},
  code={https://github.com/Jiankai-Sun/plate-pytorch},
  preview={plate-21.jpg},
  description={Planning Transformer to learn structured and plannable state and action spaces directly from unstructured videos. The model learns both action-conditional video prediction and goal conditioned planning.}
}


@article{Lutter2022cfvi,
  title={{Continuous-Time Fitted Value Iteration for Robust Policies}}, 
  author={Michael Lutter and Boris Belousov and Shie Mannor and Dieter Fox and Animesh Garg and Jan Peters},
  journal={Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)}, 
  year={2022},
  month={oct},
  arXiv = {2110.01954},
  html={https://sites.google.com/view/rfvi},
  preview={cfvi-pami22.jpg},
  description={Solving HJB differential equation and its extension the Hamilton-Jacobi-Isaacs equation yields a robust optimal policy that achieves the maximum reward on a give task. We propose continuous and robust fitted value iteration that leverage the non-linear control-affine dynamics and separable state & action reward in continuous control to derive the optimal policy and optimal adversary in closed form.}
}

@article{bai2022monotonic,
  title={{Monotonic Quantile Network for Worst-Case Offline Reinforcement Learning}}, 
  author={Chenjia Bai and Ting Xiao and Zhoufan Zhu and Lingxiao Wang and Fan Zhou and Animesh Garg and Bin He and Peng Liu and Zhaoran Wang},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  year={2022},
  month={nov},
  day={15},
  pdf = {https://doi.org/10.1109/TNNLS.2022.3217189},
  preview={mqn-cqr.jpg},
  description={Learning a distributional value function in offline RL and optimizing a worst-case criterion of returns. We propose monotonic quantile network (MQN) with conservative quantile regression (CQR) for risk-averse policy learning.}
}


@article{heiden2023disect,
  title={{DiSECt: A Differentiable Simulator for Parameter Inference and Control in Robotic Cutting}}, 
  author={Eric Heiden and Miles Macklin and Yashraj Narang and Dieter Fox  and Animesh Garg and Fabio Ramos},
  journal={Autonomous Robots (AURO)}, 
  year={2023},
  month={mar},   
  arXiv = {2203.10263},
  website= {https://diff-cutting-sim.github.io/},
  video={https://youtu.be/JEMLGq7eRLc},
  blog={https://developer.nvidia.com/blog/nvidia-research-disect-a-differentiable-simulation-engine-for-autonomous-robotic-cutting/},
  code={https://github.com/NVlabs/DiSECt},
  preview={disect-rss21.gif},
  description={Differenctiable Cutting made easier. Now on real robots!}
}

@article{mittal2023orbit,
    title={ORBIT: A Unified Simulation Framework for Interactive Robot Learning Environments},
    author={Mayank Mittal and Calvin Yu and Qinxi Yu and Jingzhou Liu and Nikita Rudin and David Hoeller and Jia Lin Yuan and Pooria Poorsarvi Tehrani and Ritvik Singh and Yunrong Guo and Hammad Mazhar and Ajay Mandlekar and Buck Babich and Gavriel State and Marco Hutter and Animesh Garg},
    year={2023},
    journal={IEEE Robotics and Automation Letters (RA-L) and ICRA}, 
    mon={apr},
    arXiv={2301.04195},
    website= {https://isaac-orbit.github.io/},
    code={https://github.com/NVIDIA-Omniverse/orbit},
    preview={orbit-ral23.gif},
    description={Orbit is a unified and modular framework for robotics and robot learning. Supports different types of physics, robot types and sensors. Supports differen Robot Learning workflows: RL, imitation, and motion planning. }
}


@article{bourdillon2023integration,
  title={Integration of reinforcement learning in a virtual robotic surgical simulation},
  author={Bourdillon, Alexandra T and Garg, Animesh and Wang, Hanjay and Woo, Y Joseph and Pavone, Marco and Boyd, Jack},
  journal={Journal of Surgical Innovation},
  ign-volume={30},
  ign-number={1},
  ign-pages={94--102},
  year={2023},
  mon={jul},
  publisher={SAGE Publications Sage CA: Los Angeles, CA},
  preview={rl-surg-sim-journal.jpg}
}

@article{yoshikawa2023digital,
  title={Digital pipette: open hardware for liquid transfer in self-driving laboratories},
  author={Yoshikawa, Naruki and Darvish, Kourosh and Vakili, Mohammad Ghazi and Garg, Animesh and Aspuru-Guzik, Al{\'a}n},
  journal={Digital Discovery},
  ign-volume={2},
  ign-number={6},
  ign-pages={1745--1751},
  year={2023},
  mon={aug},
  publisher={Royal Society of Chemistry}
}


@article{yoshikawa2023large,
  title={Large language models for chemistry robotics},
  author={Yoshikawa, Naruki and Skreta, Marta and Darvish, Kourosh and Arellano-Rubach, Sebastian and Ji, Zhi and Bj{\o}rn Kristensen, Lasse and Li, Andrew Zou and Zhao, Yuchi and Xu, Haoping and Kuramshin, Artur and Alán Aspuru-Guzik and Florian Shkurti and Animesh Garg },
  journal={Autonomous Robots},
  ign-volume={47},
  ign-number={8},
  ign-pages={1057--1086},
  year={2023},
  mon={sep},
  publisher={Springer US New York}
}

@article{singh2023progprompt,
  title={ProgPrompt: program generation for situated robot task planning using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  journal={Autonomous Robots},
  ign-pages={1--14},
  year={2023},
  mon={sep},
  publisher={Springer},
  website={https://progprompt.github.io/},
}

@article{dharmarajan2023robot,
  title={Robot-Assisted Vascular Shunt Insertion with the dVRK Surgical Robot},
  author={Dharmarajan, Karthik and Panitch, Will and Shi, Baiyu and Huang, Huang and Chen, Lawrence Yunliang and Moghani, Masoud and Yu, Qinxi and Hari, Kush and Low, Thomas and Fer, Danyal and Animesh Garg and Ken Goldberg},
  journal={Journal of Medical Robotics Research},
  ign-volume={8},
  ign-number={03n04},
  ign-pages={2340006},
  year={2023},
  month={oct},
  publisher={World Scientific Publishing Company}
}


@article{melnik2023benchmarks,
  title={Benchmarks for Physical Reasoning {AI}},
  author={Andrew Melnik and Robin Schiewer and Moritz Lange and Andrei Ioan Muresanu and mozhgan saeidi and Animesh Garg and Helge Ritter},
  journal={Transactions on Machine Learning Research},
  ign-issn={2835-8856},
  year={2023},
  month={nov},
  html={https://openreview.net/forum?id=cHroS8VIyN},
  note={Survey Certification},
  code={https://github.com/ndrwmlnk/Awesome-Benchmarks-for-Physical-Reasoning-AI}
}


@article{darvish2025organa,
  title={ORGANA: a robotic assistant for automated chemistry experimentation and characterization},
  author={Darvish, Kourosh and Skreta, Marta and Zhao, Yuchi and Yoshikawa, Naruki and Som, Sagnik and Bogdanovic, Miroslav and Cao, Yang and Hao, Han and Xu, Haoping and Aspuru-Guzik, Al{\'a}n and Animesh Garg and Florian Shkurti},
  journal={Matter},
  ign-volume={8},
  ign-number={2},
  year={2025},
  month={jan},
  publisher={Elsevier},
  arxiv={2401.06949},
  website={https://ac-rad.github.io/organa/},
  video={https://www.youtube.com/watch?v=N6qMMwJ8hKQ},

}

@article{cooper2025accelerating,
  title={Accelerating Discovery in Natural Science Laboratories with AI and Robotics: Perspectives and Challenges from the 2024 IEEE ICRA Workshop, Yokohama, Japan},
  author={Andrew I. Cooper and Patrick Courtney and Kourosh Darvish and Moritz Eckhoff and Hatem Fakhruldeen and Andrea Gabrielli and Animesh Garg and Sami Haddadin and Kanako Harada and Jason Hein and Maria Hübner and Dennis Knobbe and Gabriella Pizzuto and Florian Shkurti and Ruja Shrestha and Kerstin Thurow and Rafael Vescovi and Birgit Vogel-Heuser and Ádám Wolf and Naruki Yoshikawa and Yan Zeng and Zhengxue Zhou and Henning Zwirnmann},
  journal={Science Robotics},
  arXiv={2501.06847},
  year={2025}
}

% ==========
% Thesis
% ==========

@phdthesis{garg2016phdthesis,
  title={Optimization and Design for Automation of Brachytherapy Delivery and Learning Robot-Assisted Surgical Sub-Tasks},
  author={Garg, Animesh},
  year={2016},
  Month = {Aug},
  website= {http://escholarship.org/uc/item/89k6f68d},
  degree = {PhD Thesis},
  school={University of California, Berkeley}
}

@mastersthesis{garg2016msthesis,
  Author = {Garg, Animesh},
  Editor = {Goldberg, Ken and Abbeel, Pieter and Atamturk, Alper},
  Title = {Autonomous Palpation for Tumor Localization: Design of a Palpation Probe and Gaussian Process Adaptive Sampling},
  School = {EECS Department, University of California, Berkeley},
  degree = {MS Thesis},
  Year = {2016},
  Month = {Aug},
  website= {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-140.html},
  Number = {UCB/EECS-2016-140}
}


% ===========
%  Preprints
% ===========



@unpublished{zhao2025anyplace,
  title={AnyPlace: Learning Generalized Object Placement for Robot Manipulation},
  author={Zhao, Yuchi and Bogdanovic, Miroslav and Luo, Chengyuan and Tohme, Steven and Darvish, Kourosh and Aspuru-Guzik, Al{\'a}n and Shkurti, Florian and Garg, Animesh},
  arXiv={2502.04531},
  year={2025}
}

% =============
%  Older Misc
% =============


@techreport{paluri2010autonomous,
  title={Autonomous localization and navigation using 2D laser scanners},
  author={Paluri, Manohar and Garg, Animesh and Christensen, Henrik},
  year={2010}
}

@techreport{1711.01503,
  author={Liaw, Richard and Krishnan, Sanjay and Garg, Animesh and Crankshaw, Daniel and Gonzalez, Joseph E and Goldberg, Ken},
Title = {Composing Meta-Policies for Autonomous Driving Using Hierarchical Deep Reinforcement Learning},
Year = {2017},
month={nov},
arXiv = {1711.01503},
}

@techreport{1909.02749,
Author = {Kevin J. Shih and Aysegul Dundar and Animesh Garg and Robert Pottorf and Andrew Tao and Bryan Catanzaro},
Title = {Video Interpolation and Prediction with Unsupervised Landmarks},
Year = {2019},
month={sept},
arXiv = {1909.02749},
}


@techreport{2007.00177,
  Author = {Homanga Bharadhwaj and Dylan Turpin and Animesh Garg and Ashton Anderson},
  Title = {{De-anonymization of authors through arXiv submissions during double-blind review}},
  Year = {2020},
  month={jul},
  arXiv = {2007.00177},
  blog={https://homangab.github.io/ri-blog/2017/06/21/an-overview-of-deep-learning.html},
  description={Doubt-blind reviewing process may tilt the scales in favor of eminent authors who de-anonymize through concurrent arxiv release.}
}


@techreport{2009.08577,
  Author = {Tim Barfoot and Jessica Burgner-Kahrs and Eric Diller and Animesh Garg and Andrew Goldenberg and Jonathan Kelly and Xinyu Liu and Hani E. Naguib and Goldie Nejat and Angela P. Schoellig and Florian Shkurti and Hallie Siegel and Yu Sun and Steven Waslander},
  Title = {{Making Sense of the Robotized Pandemic Response: A Comparison of Global and Canadian Robot Deployments and Success Factors}},
  Year = {2020},
  month={sep},
  arXiv = {2009.08577},
  blog={https://robotics.utoronto.ca/covid-19-white-paper/}
}

@techreport{2109.12456,
  title={{Auditing AI models for Verified Deployment under Semantic Specifications}}, 
  author={Homanga Bharadhwaj and De-An Huang and Chaowei Xiao and Animashree Anandkumar and Animesh Garg},
  year={2021},
  month={sept},
  arXiv = {2109.12456},
  html={https://sites.google.com/view/audit-ai/},
  blog={https://developer.nvidia.com/blog/nvidia-research-auditing-ai-models-for-verified-deployment-under-semantic-specifications/},
  preview={audit-ai-banner.png},
  description={How can we design a similarly motivated auditing scheme for deep learning models? We propose a sequence of semantically aligned unit tests each to verify a predefined specification.}
}


@techreport{2210.03825,
  title={{See, Plan, Predict: Language-guided Cognitive Planning with Video Prediction}}, 
  author={Maria Attarian and Advaya Gupta and Ziyi Zhou and Wei Yu and Igor Gilitschenski and Animesh Garg},
  year={2022},
  month={spr},   
  arXiv = {2210.03825},
  website= {https://see-pp.github.io/},
  preview={see-pp-2022.jpg},
  description={A new video prediction architecture using pre-trained transformers for language conditioned goal prediction and planning.}
}

@techreport{yoshikawa2022adaptive,
    title={An Adaptive Robotics Framework for Chemistry Lab Automation},
    author={Naruki Yoshikawa and Andrew Zou Li and Kourosh Darvish and Yuchi Zhao and Haoping Xu and Alan Aspuru-Guzik and Animesh Garg and Florian Shkurti},
    year={2022},
    mon={dec},
    arXiv={2212.09672},
    website = {https://ac-rad.github.io/robot-chemist-tamp/},
    video={https://youtu.be/NjpZmaKQWls},
    preview={chemrobot-arxiv22.gif},
    description={We propose a framework for robots to assist chemists by performing lab experiments autonomously. The solution allows a general-purpose robot to perform diverse chemistry experiments and efficiently make use of available lab tools. }
}

@techreport{skreta2023errors,
      title={Errors are Useful Prompts: Instruction Guided Task Programming with Verifier-Assisted Iterative Prompting}, 
      author={Marta Skreta and Naruki Yoshikawa and Sebastian Arellano-Rubach and Zhi Ji and Lasse Bjørn Kristensen and Kourosh Darvish and Alán Aspuru-Guzik and Florian Shkurti and Animesh Garg},
      year={2023},
      mon={mar},
      arXiv={2303.14100},
      website= {https://ac-rad.github.io/clairify/},
      video={https://youtu.be/-87yrXytluw},
      preview={clairify-iros23.gif},
      description={CLAIRify is a novel approach that combines automatic iterative prompting in LLMs with program verification to ensure programs written in domain-specific languages are syntactically valid and incorporate environment constraints.}
}


@techreport{devaguptapu2023deltanetworks,
      title={{$\Delta$-Networks for Efficient Model Patching}}, 
      author={Chaitanya Devaguptapu and Samarth Sinha and K J Joseph and Vineeth N Balasubramanian and Animesh Garg},
      year={2023},
      arXiv={2303.14772}
}


@techreport{skreta2024replan,
  title={Replan: Robotic replanning with perception and language models},
  author={Skreta, Marta and Zhou, Zihan and Yuan, Jia Lin and Darvish, Kourosh and Aspuru-Guzik, Al{\'a}n and Garg, Animesh},
  journal={arXiv preprint arXiv:2401.04157},
  mon={jan},
  year={2024},
  arXiv={2401.04157},  
}


