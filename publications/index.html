<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | PAIR </title> <meta name="author" content="PAIR Lab"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/al-folio/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/al-folio/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/al-folio/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%99%BE%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/al-folio/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pairlab.github.io/al-folio/publications/"> <script src="/al-folio/assets/js/theme.js?d25c4b117d08504ee8ffd95485db4720"></script> <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/venobox@2.1.8/dist/venobox.min.css" integrity="sha256-ohJEB0/WsBOdBD+gQO/MGfyJSbTUI8OOLbQGdkxD6Cg=" crossorigin="anonymous"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/al-folio/"> <img alt="PAIR Logo" src="https://pairlab.github.io/al-folio/assets/img/pair-logo-2-bw.png" height="40" style="margin-top:5px"> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/al-folio/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/research/">Research Agenda </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/people/">people </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/contact/">contact </a> </li> <li class="nav-item "> <a class="nav-link" href="/al-folio/blog/">blog </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/al-folio/teaching/">Courses</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/news/">News Archive</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/resources/">code &amp; talks</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/al-folio/cv/">PI Profile</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p>For the up-to-date publication list, please see <a href="http://scholar.google.com/citations?user=zp8V7ZMAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank"><strong>Google Scholar</strong></a> or <a href="https://www.semanticscholar.org/author/Animesh-Garg/1873736" rel="external nofollow noopener" target="_blank"><strong>Semantic Scholar</strong></a> pages.<br> For coverage of research in press, please see <a href="/al-folio/news/">News</a></p> <script src="/al-folio/assets/js/bibsearch.js?584973046a1f088a432f92bb0a7be14a" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="tags"> <button type="button" class="btn btn-sm btn-outline-dark z-depth-0 tag-filter" data-tag="robotics"> robotics </button> <button type="button" class="btn btn-sm btn-outline-dark z-depth-0 tag-filter" data-tag=" vision"> vision </button> <button type="button" class="btn btn-sm btn-outline-dark z-depth-0 tag-filter" data-tag=" machine learning"> machine learning </button> <button type="button" class="btn btn-sm btn-outline-dark z-depth-0 tag-filter" data-tag=" reinforcement learning"> reinforcement learning </button> <button type="button" class="btn btn-sm btn-outline-dark z-depth-0 tag-filter" data-tag=" simulation"> simulation </button> </div> <div class="publications"> <h2 class="bibliography">Papers (Journals &amp; Conferences)</h2> <ol class="bibliography" reversed="true"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="byrnes2024climb" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2410.13756" target="_blank" rel="external nofollow noopener">CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building.</a> </div> <div class="author"> Walker Byrnes, Miroslav Bogdanovic, Avi Balakirsky, Stephen Balakirsky, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2025 </div> <div class="links"> <a href="http://arxiv.org/abs/2410.13756" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://plan-with-climb.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ameperosa2024rocoda" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2411.16959" target="_blank" rel="external nofollow noopener">RoCoDA: Counterfactual Data Augmentation for Data-Efficient Robot Learning from Demonstrations.</a> </div> <div class="author"> Ezra Ameperosa, Jeremy A Collins, Mrinal Jain, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2025 </div> <div class="links"> <div class="keywords" style="display:none;"> <span class="badge bg-secondary" data-keywords="Counterfactual Data Augmentation, Robot Learning, Data Efficiency, causality">Counterfactual Data Augmentation, Robot Learning, Data Efficiency, causality</span> </div> <div class="tags" style="display:none;"> <a class="tag-filter btn btn-sm z-depth-0" data-tag="Data Augmentation" role="button">Data Augmentation</a> </div> <a href="http://arxiv.org/abs/2411.16959" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://rocoda.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="georgiev2024pwm" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2407.02466" target="_blank" rel="external nofollow noopener">PWM: Policy Learning with Large World Models.</a> </div> <div class="author"> Ignat Georgiev, Varun Giridhar, Nicklas Hansen, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2025 </div> <div class="links"> <div class="tags" style="display:none;"> <a class="tag-filter btn btn-sm z-depth-0" data-tag="Reinforcement Learning" role="button">Reinforcement Learning</a> <a class="tag-filter btn btn-sm z-depth-0" data-tag=" World Models" role="button"> World Models</a> <a class="tag-filter btn btn-sm z-depth-0" data-tag=" Policy Learning" role="button"> Policy Learning</a> </div> <a href="http://arxiv.org/abs/2407.02466" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://www.imgeorgiev.com/pwm/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yu2024egosim" class="col-sm-9"> <div class="title"> <a href="https://openreview.net/forum?id=zAyS5aRKV8" target="_blank" rel="external nofollow noopener">EgoSim: Egocentric Exploration in Virtual Worlds with Multi-modal Conditioning.</a> </div> <div class="author"> Wei Yu, Songheng Yin, Steve Easterbrook, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2025 </div> <div class="links"> <a href="https://openreview.net/forum?id=zAyS5aRKV8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://egosim.github.io/EgoSim/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="darvish2025organa" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2401.06949" target="_blank" rel="external nofollow noopener">ORGANA: a robotic assistant for automated chemistry experimentation and characterization.</a> </div> <div class="author"> Kourosh Darvish, Marta Skreta, Yuchi Zhao, Naruki Yoshikawa, Sagnik Som, Miroslav Bogdanovic, Yang Cao, Han Hao, Haoping Xu, Alán Aspuru-Guzik, <em>Animesh Garg</em>, and Florian Shkurti </div> <div class="periodical"> <em>Matter</em>, 2025 </div> <div class="links"> <a href="http://arxiv.org/abs/2401.06949" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=N6qMMwJ8hKQ" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://ac-rad.github.io/organa/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="cooper2025accelerating" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2501.06847" target="_blank" rel="external nofollow noopener">Accelerating Discovery in Natural Science Laboratories with AI and Robotics: Perspectives and Challenges from the 2024 IEEE ICRA Workshop, Yokohama, Japan.</a> </div> <div class="author"> Andrew I. Cooper, Patrick Courtney, Kourosh Darvish, Moritz Eckhoff, Hatem Fakhruldeen, Andrea Gabrielli, <em>Animesh Garg</em>, Sami Haddadin, Kanako Harada, Jason Hein, Maria Hübner, Dennis Knobbe, Gabriella Pizzuto, Florian Shkurti, Ruja Shrestha, Kerstin Thurow, <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Rafael Vescovi, Birgit Vogel-Heuser, Ádám Wolf, Naruki Yoshikawa, Yan Zeng, Zhengxue Zhou, Henning Zwirnmann' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>Science Robotics</em>, 2025 </div> <div class="links"> <a href="http://arxiv.org/abs/2501.06847" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mu2024adademo" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2404.07428" target="_blank" rel="external nofollow noopener">AdaDemo: Data-Efficient Demonstration Expansion for Generalist Robotic Agent.</a> </div> <div class="author"> Tongzhou Mu, Yijie Guo, Jie Xu, Ankit Goyal, Hao Su, Dieter Fox, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In International Symposium on Robotics Research (ISRR)</em>, 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2404.07428" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mete2024quest" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2407.15840" target="_blank" rel="external nofollow noopener">Quest: Self-supervised skill abstractions for learning continuous control.</a> </div> <div class="author"> Atharva Mete, Haotian Xue, Albert Wilcox, Yongxin Chen, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS)</em>, 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2407.15840" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://quest-model.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="wang2024discovering" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2410.20258" target="_blank" rel="external nofollow noopener">Discovering Robotic Interaction Modes with Discrete Representation Learning.</a> </div> <div class="author"> Liquan Wang, Ankit Goyal, Haoping Xu, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In 8th Annual Conference on Robot Learning</em>, 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2410.20258" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://actaim2.github.io/static/videos/corl_video.mp4" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://actaim2.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="zhou2024spire" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2410.18065" target="_blank" rel="external nofollow noopener">SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for Long-Horizon Manipulation.</a> </div> <div class="author"> Zihan Zhou, <em>Animesh Garg</em>, Dieter Fox, Caelan Reed Garrett, and Ajay Mandlekar </div> <div class="periodical"> <em>In 8th Annual Conference on Robot Learning</em>, 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2410.18065" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://sites.google.com/view/spire-corl-2024" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="walker2024fast" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2402.02612" target="_blank" rel="external nofollow noopener">Fast Explicit-Input Assistance for Teleoperation in Clutter.</a> </div> <div class="author"> Nick Walker, Xuning Yang, <em>Animesh Garg</em>, Maya Cakmak, Dieter Fox, and Claudia Pérez-D’Arpino </div> <div class="periodical"> <em>In 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2402.02612" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="moghani2024sufia" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2405.05226" target="_blank" rel="external nofollow noopener">SuFIA: Language-Guided Augmented Dexterity for Robotic Surgical Assistants.</a> </div> <div class="author"> Masoud Moghani, Lars Doorenbos, William Chung-Ho Panitch, Sean Huver, Mahdi Azizian, Ken Goldberg, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2405.05226" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://orbit-surgical.github.io/sufia/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="georgiev2024adaptive" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2405.17784" target="_blank" rel="external nofollow noopener">Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich Differentiable Simulation.</a> </div> <div class="author"> Ignat Georgiev, Krishnan Srinivasan, Jie Xu, Eric Heiden, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Proceedings of the 41st International Conference on Machine Learning</em>, 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2405.17784" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://adaptive-horizon-actor-critic.github.io" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="zhang2024handypriors" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2311.16552" target="_blank" rel="external nofollow noopener">Handypriors: Physically consistent perception of hand-object interactions with differentiable priors.</a> </div> <div class="author"> Shutong Zhang, Yi-Ling Qiao, Guanglei Zhu, Eric Heiden, Dylan Turpin, Jingzhou Liu, Ming Lin, Miles Macklin, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2311.16552" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://handypriors.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="2023open" class="col-sm-9"> <div class="title"> Open X-Embodiment: Robotic learning datasets and RT-X models. </div> <div class="author"> Open X-Embodiment Collaboration </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  ICRA Best Paper</span> </a> <br> <a href="https://open-x-embodiment.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>ICRA Best Paper Award</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yu2024orbit" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2404.16027" target="_blank" rel="external nofollow noopener">ORBIT-Surgical: An Open-Simulation Framework for Learning Surgical Augmented Dexterity.</a> </div> <div class="author"> Qinxi Yu, Masoud Moghani, Karthik Dharmarajan, Vincent Schorp, William Chung-Ho Panitch, Jingzhou Liu, Kush Hari, Huang Huang, Mayank Mittal, Ken Goldberg, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2404.16027" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/orbit-surgical/orbit-surgical" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://orbit-surgical.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="wu2023slotdiffusion" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2305.11281" target="_blank" rel="external nofollow noopener">Slotdiffusion: Object-centric generative modeling with diffusion models.</a> </div> <div class="author"> Ziyi Wu, Jingyu Hu, Wuyue Lu, Igor Gilitschenski, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2305.11281" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://slotdiffusion.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="liu2023composable" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2405.05876" target="_blank" rel="external nofollow noopener">Composable part-based manipulation.</a> </div> <div class="author"> Weiyu Liu, Jiayuan Mao, Joy Hsu, Tucker Hermans, <em>Animesh Garg</em>, and Jiajun Wu </div> <div class="periodical"> <em>In Conference on Robot Learning</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2405.05876" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="attarian2023geometry" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2312.03864" target="_blank" rel="external nofollow noopener">Geometry Matching for Multi-Embodiment Grasping.</a> </div> <div class="author"> Maria Attarian, Muhammad Adil Asif, Jingzhou Liu, Ruthrash Hari, <em>Animesh Garg</em>, Igor Gilitschenski, and Jonathan Tompson </div> <div class="periodical"> <em>In Conference on Robot Learning</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2312.03864" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/google-deepmind/geomatch" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://geo-match.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="melnik2023benchmarks" class="col-sm-9"> <div class="title"> <a href="https://openreview.net/forum?id=cHroS8VIyN" target="_blank" rel="external nofollow noopener">Benchmarks for Physical Reasoning AI.</a> </div> <div class="author"> Andrew Melnik, Robin Schiewer, Moritz Lange, Andrei Ioan Muresanu, saeidi, <em>Animesh Garg</em>, and Helge Ritter </div> <div class="periodical"> <em>Transactions on Machine Learning Research</em>, 2023 </div> <div class="periodical"> Survey Certification </div> <div class="links"> <a href="https://openreview.net/forum?id=cHroS8VIyN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://github.com/ndrwmlnk/Awesome-Benchmarks-for-Physical-Reasoning-AI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="dharmarajan2023robot" class="col-sm-9"> <div class="title"> Robot-Assisted Vascular Shunt Insertion with the dVRK Surgical Robot. </div> <div class="author"> Karthik Dharmarajan, Will Panitch, Baiyu Shi, Huang Huang, Lawrence Yunliang Chen, Masoud Moghani, Qinxi Yu, Kush Hari, Thomas Low, Danyal Fer, <em>Animesh Garg</em>, and Ken Goldberg </div> <div class="periodical"> <em>Journal of Medical Robotics Research</em>, 2023 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/progprompt-icra23.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="progprompt-icra23.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="singh2023progprompt" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2209.11302" target="_blank" rel="external nofollow noopener">ProgPrompt: Generating Situated Robot Task Plans using Large Language Models.</a> </div> <div class="author"> Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2209.11302" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://progprompt.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/slotformer-iclr23.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="slotformer-iclr23.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nerf2nerf" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2211.01600" target="_blank" rel="external nofollow noopener">nerf2nerf: Pairwise Registration of Neural Radiance Fields.</a> </div> <div class="author"> Lily Goli, Daniel Rebain, Sara Sabour, <em>Animesh Garg</em>, and Andrea Tagliasacchi </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2211.01600" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/nerf2nerf/nerf2nerf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://nerf2nerf.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/actaim-icra23.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="actaim-icra23.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2023actaim" class="col-sm-9"> <div class="title"> Self-Supervised Learning of Action Affordances as Interaction Modes. </div> <div class="author"> Liquan Wang, Nikita Dvornik, Rafael Dubeau, Mayank Mittal, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023 </div> <div class="links"> <a href="https://actaim.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/dexgrasp-icra23.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dexgrasp-icra23.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="turpin2023fast" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2306.08132" target="_blank" rel="external nofollow noopener">Fast-Grasp’D: Dexterous Multi-finger Grasp Generation Through Differentiable Simulation.</a> </div> <div class="author"> Dylan Turpin, Tao Zhong, Shutong Zhang, Guanglei Zhu, Jingzhou Liu, Ritvik Singh, Eric Heiden, Miles Macklin, Stavros Tsogkas, Sven Dickinson, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2306.08132" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/1tBuHEsAf3Q" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://dexgrasp.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/mvtrans-icra23.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mvtrans-icra23.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2023mvtrans" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2302.11683" target="_blank" rel="external nofollow noopener">MVTrans: Multi-View Perception of Transparent Objects.</a> </div> <div class="author"> Yi Ru Wang, Yuchi Zhao, Haoping XU, Sagi Eppel, Alan Aspuru-Guzik, Florian Shkurti, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2302.11683" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/8Qdc_xWVp-k" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://ac-rad.github.io/MVTrans/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/sea-iclr23.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sea-iclr23.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhou2023sea" class="col-sm-9"> <div class="title"> Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward. </div> <div class="author"> Zihan Zhou and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2023 </div> <div class="links"> <a href="https://openreview.net/forum?id=NDWl9qcUpvy" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/slotformer-iclr23.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="slotformer-iclr23.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wu2023slotformer" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2210.05861" target="_blank" rel="external nofollow noopener">SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models.</a> </div> <div class="author"> Ziyi Wu, Nikita Dvornik, Klaus Greff, Thomas Kipf, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2210.05861" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://slotformer.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/disect-rss21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="disect-rss21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="heiden2023disect" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2203.10263" target="_blank" rel="external nofollow noopener">DiSECt: A Differentiable Simulator for Parameter Inference and Control in Robotic Cutting.</a> </div> <div class="author"> Eric Heiden, Miles Macklin, Yashraj Narang, Dieter Fox, <em>Animesh Garg</em>, and Fabio Ramos </div> <div class="periodical"> <em>Autonomous Robots (AURO)</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2203.10263" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/JEMLGq7eRLc" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://developer.nvidia.com/blog/nvidia-research-disect-a-differentiable-simulation-engine-for-autonomous-robotic-cutting/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> <a href="https://github.com/NVlabs/DiSECt" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://diff-cutting-sim.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/orbit-ral23.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="orbit-ral23.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mittal2023orbit" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2301.04195" target="_blank" rel="external nofollow noopener">ORBIT: A Unified Simulation Framework for Interactive Robot Learning Environments.</a> </div> <div class="author"> Mayank Mittal, Calvin Yu, Qinxi Yu, Jingzhou Liu, Nikita Rudin, David Hoeller, Jia Lin Yuan, Pooria Poorsarvi Tehrani, Ritvik Singh, Yunrong Guo, Hammad Mazhar, Ajay Mandlekar, Buck Babich, Gavriel State, Marco Hutter, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters (RA-L) and ICRA</em>, 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2301.04195" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/NVIDIA-Omniverse/orbit" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://isaac-orbit.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/rl-surg-sim-journal.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rl-surg-sim-journal.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bourdillon2023integration" class="col-sm-9"> <div class="title"> Integration of reinforcement learning in a virtual robotic surgical simulation. </div> <div class="author"> Alexandra T Bourdillon, <em>Animesh Garg</em>, Hanjay Wang, Y Joseph Woo, Marco Pavone, and Jack Boyd </div> <div class="periodical"> <em>Journal of Surgical Innovation</em>, 2023 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yoshikawa2023digital" class="col-sm-9"> <div class="title"> Digital pipette: open hardware for liquid transfer in self-driving laboratories. </div> <div class="author"> Naruki Yoshikawa, Kourosh Darvish, Mohammad Ghazi Vakili, <em>Animesh Garg</em>, and Alán Aspuru-Guzik </div> <div class="periodical"> <em>Digital Discovery</em>, 2023 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="yoshikawa2023large" class="col-sm-9"> <div class="title"> Large language models for chemistry robotics. </div> <div class="author"> Naruki Yoshikawa, Marta Skreta, Kourosh Darvish, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen, Andrew Zou Li, Yuchi Zhao, Haoping Xu, Artur Kuramshin, Alán Aspuru-Guzik, Florian Shkurti, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>Autonomous Robots</em>, 2023 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="singh2023progprompu" class="col-sm-9"> <div class="title"> ProgPrompt: program generation for situated robot task planning using large language models. </div> <div class="author"> Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>Autonomous Robots</em>, 2023 </div> <div class="links"> <a href="https://progprompt.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/bom-corl22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bom-corl22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="murathy2022bom" class="col-sm-9"> <div class="title"> <a href="https://openreview.net/forum?id=QSUsBMuw0uV" target="_blank" rel="external nofollow noopener">Bayesian Object Models for Robotic Interaction with Differentiable Probabilistic Programming.</a> </div> <div class="author"> Krishna Murthy Jatavallabhula, Miles Macklin, Dieter Fox, <em>Animesh Garg</em>, and Fabio Ramos </div> <div class="periodical"> <em>In Conference on Robot Learning (CoRL)</em>, 2022 </div> <div class="links"> <a href="https://openreview.net/forum?id=QSUsBMuw0uV" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://bayesianobjects.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/robotube-corl22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="robotube-corl22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xiong2022robotube" class="col-sm-9"> <div class="title"> <a href="https://openreview.net/forum?id=SYUEnQtK85o" target="_blank" rel="external nofollow noopener">RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments.</a> </div> <div class="author"> Haoyu Xiong, Haoyuan Fu, Jieyi Zhang, Chen Bao, Qiang Zhang, Yongxi Huang, Wenqiang Xu, <em>Animesh Garg</em>, and Cewu Lu </div> <div class="periodical"> <em>In Conference on Robot Learning (CoRL)</em>, 2022 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="https://openreview.net/forum?id=SYUEnQtK85o" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/oTnsZs7yOVc" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://sites.google.com/view/robotube" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral Presentation</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/breaking-bad-neurips22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="breaking-bad-neurips22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sellan2022breaking" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2210.11463" target="_blank" rel="external nofollow noopener">Breaking Bad: A Dataset for Geometric Fracture and Reassembly.</a> </div> <div class="author"> Silvia Sellán, Yun-Chun Chen, Ziyi Wu, <em>Animesh Garg</em>, and Alec Jacobson </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks</em>, 2022 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2210.11463" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://openreview.net/forum?id=mJWt6pOcHNy" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://breaking-bad-dataset.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Featured Paper Presentation</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/smpl-neurips22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="smpl-neurips22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2022smpl" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2206.08851" target="_blank" rel="external nofollow noopener">SMPL: Simulated Industrial Manufacturing and Process Control Learning Environments.</a> </div> <div class="author"> Mohan Zhang, Xiaozhou Wang, Benjamin Decardi-Nelson, Bo Song, An Zhang, Jinfeng Liu, Sile Tao, Jiayi Cheng, Xiaohong Liu, Dengdeng Yu, Matthew Poon, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2206.08851" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/smpl-env/smpl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://smpl-env.github.io/smpl-document/index.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/mocoda-neurips22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mocoda-neurips22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pitis2022mocoda" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2210.11287" target="_blank" rel="external nofollow noopener">MoCoDA: Model-based Counterfactual Data Augmentation.</a> </div> <div class="author"> Silviu Pitis, Elliot Creager, Ajay Mandlekar, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2210.11287" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/mqn-cqr.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mqn-cqr.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bai2022monotonic" class="col-sm-9"> <div class="title"> <a href="https://doi.org/10.1109/TNNLS.2022.3217189" target="_blank" rel="external nofollow noopener">Monotonic Quantile Network for Worst-Case Offline Reinforcement Learning.</a> </div> <div class="author"> Chenjia Bai, Ting Xiao, Zhoufan Zhu, Lingxiao Wang, Fan Zhou, <em>Animesh Garg</em>, Bin He, Peng Liu, and Zhaoran Wang </div> <div class="periodical"> <em>IEEE Transactions on Neural Networks and Learning Systems</em>, 2022 </div> <div class="links"> <a href="https://doi.org/10.1109/TNNLS.2022.3217189" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="nguyen2022infocnf" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1912.03978" target="_blank" rel="external nofollow noopener">InfoCNF: An Efficient Conditional Continuous Normalizing Flow with Adaptive Solvers.</a> </div> <div class="author"> Tan M. Nguyen, <em>Animesh Garg</em>, Richard G. Baraniuk, and Anima Anandkumar </div> <div class="periodical"> <em>In IEEE Asilomar Conference on Signals, Systems, and Computers</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/1912.03978" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/s2r2-21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="s2r2-21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="allshire2022trifinger" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2108.09779" target="_blank" rel="external nofollow noopener">Transferring Dexterous Manipulation from GPU Simulation to a Remote Real-World TriFinger.</a> </div> <div class="author"> Arthur Allshire, Mayank Mittal, Varun Lodaya, Viktor Makoviychuk, Denys Makoviichuk, Felix Widmaier, Manuel Wüthrich, Stefan Bauer, Ankur Handa, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2108.09779" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://s2r2-ig.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/mm-articulated-arxiv21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mm-articulated-arxiv21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="articulated2021mittal" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2103.10534" target="_blank" rel="external nofollow noopener">Articulated Object Interaction in Unknown Scenes with Whole-Body Mobile Manipulation.</a> </div> <div class="author"> Mayank Mittal, David Hoeller, Farbod Farshidian, Marco Hutter, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2103.10534" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://www.pair.toronto.edu/articulated-mm/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/graspd-eccv22.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="graspd-eccv22.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="turpin2022graspd" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2208.12250" target="_blank" rel="external nofollow noopener">Grasp’D: Differentiable Contact-rich Grasp Synthesis for Multi-fingered Hands.</a> </div> <div class="author"> Dylan Turpin, Liquan Wang, Eric Heiden, Yun-Chun Chen, Miles Macklin, Stavros Tsogkas, Sven Dickinson, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV)</em>, 2022 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2208.12250" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/tkl_lywZ94o" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://github.com/dylanturpin/graspd" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://graspd-eccv22.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral (Top 2.7%)</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/cfvi-pami22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cfvi-pami22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Lutter2022cfvi" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2110.01954" target="_blank" rel="external nofollow noopener">Continuous-Time Fitted Value Iteration for Robust Policies.</a> </div> <div class="author"> Michael Lutter, Boris Belousov, Shie Mannor, Dieter Fox, <em>Animesh Garg</em>, and Jan Peters </div> <div class="periodical"> <em>Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2110.01954" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://sites.google.com/view/rfvi" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/koopman-rl-iclr22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="koopman-rl-iclr22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="weissenbacher2022icml" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2111.01365" target="_blank" rel="external nofollow noopener">Koopman Q-learning: Offline Reinforcement Learning via Symmetries of Dynamics.</a> </div> <div class="author"> Matthias Weissenbacher, Samarth Sinha, <em>Animesh Garg</em>, and Yoshinobu Kawahara </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2111.01365" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/lfiw-l4dc22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lfiw-l4dc22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sinha2022lfiw" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2006.13169" target="_blank" rel="external nofollow noopener">Experience Replay with Likelihood-free Importance Weights.</a> </div> <div class="author"> Samarth Sinha, Jiaming Song, <em>Animesh Garg</em>, and Stefano Ermon </div> <div class="periodical"> <em>In Learning for Dynamics and Control (L4DC)</em>, 2022 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2006.13169" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Paper Finlist</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/glide-arxiv21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="glide-arxiv21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xie2022glide" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2104.09771" target="_blank" rel="external nofollow noopener">GLiDE: Generalizable Quadrupedal Locomotion in Diverse Environments with a Centroidal Model.</a> </div> <div class="author"> Zhaoming Xie, Xingye Da, Buck Babich, <em>Animesh Garg</em>, and Michiel van de Panne </div> <div class="periodical"> <em>In Workshop on Algorithmic Foundations of Robotics (WAFR)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2104.09771" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://www.pair.toronto.edu/glide-quadruped/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/xpool-cvpr22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="xpool-cvpr22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="gorti2022xpool" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2203.15086" target="_blank" rel="external nofollow noopener">X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval.</a> </div> <div class="author"> Satya Krishna Gorti, Noel Vouitsis, Junwei Ma, Keyvan Golestan, Maksims Volkovs, <em>Animesh Garg</em>, and Guangwei Yu </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2203.15086" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/layer6ai-labs/xpool" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://layer6ai-labs.github.io/xpool/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/mac-arxiv21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mac-arxiv21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yu2022mac" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2011.11201" target="_blank" rel="external nofollow noopener">Modular Action Concept Grounding in Semantic Video Prediction.</a> </div> <div class="author"> Wei Yu, Wenxin Chen, Songheng Yin, Steve Easterbrook, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2011.11201" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="http://pair.toronto.edu/mac" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/nsm-cvpr22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="nsm-cvpr22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2022nsm" class="col-sm-9"> <div class="title"> Neural Shape Mating: Self-Supervised Object Assembly with Adversarial Shape Priors. </div> <div class="author"> Yun-Chun Chen, Haoda Li, Dylan Turpin, Alec Jacobson, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022 </div> <div class="links"> <a href="https://neural-shape-mating.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/res-pbrl-iclr22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="res-pbrl-iclr22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bai2022pbrl" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2202.11566" target="_blank" rel="external nofollow noopener">Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning.</a> </div> <div class="author"> Chenjia Bai, Lingxiao Wang, Zhuoran Yang, Zhi-Hong Deng, <em>Animesh Garg</em>, Peng Liu, and Zhaoran Wang </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2202.11566" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/res-vagram-iclr22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="res-vagram-iclr22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="voelcker2022vagram" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2204.01464" target="_blank" rel="external nofollow noopener">Value Gradient weighted Model-Based Reinforcement Learning.</a> </div> <div class="author"> Claas A Voelcker, Victor Liao, <em>Animesh Garg</em>, and Amir-massoud Farahmand </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2204.01464" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://openreview.net/forum?id=4-D6CZkRXxI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/res-shac-iclr22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="res-shac-iclr22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xie2022shac" class="col-sm-9"> <div class="title"> <a href="https://openreview.net/forum?id=ZSKRQMvttc" target="_blank" rel="external nofollow noopener">Accelerated Policy Learning with Parallel Differentiable Simulation.</a> </div> <div class="author"> Jie Xu, Viktor Makoviychuk, Yashraj Narang, Fabio Ramos, Wojciech Matusik, <em>Animesh Garg</em>, and Miles Macklin </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2022 </div> <div class="links"> <a href="https://openreview.net/forum?id=ZSKRQMvttc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://short-horizon-actor-critic.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/plate-21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="plate-21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sun2022plate" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2109.04869" target="_blank" rel="external nofollow noopener">PlaTe: Visually-Grounded Planning with Transformers in Procedural Tasks.</a> </div> <div class="author"> Jiankai Sun, De-An Huang, Bo Lu, Yun-Hui Liu, Bolei Zhou, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters (RA-L) and ICRA</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2109.04869" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/Jiankai-Sun/plate-pytorch" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://www.pair.toronto.edu/plate-planner/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/marco2021.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="marco2021.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2022marco" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2107.06434" target="_blank" rel="external nofollow noopener">Centralized Model and Exploration Policy for Multi-Agent RL.</a> </div> <div class="author"> Qizhen Zhang, Chris Lu, <em>Animesh Garg</em>, and Jakob Foerster </div> <div class="periodical"> <em>In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)</em>, 2022 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2107.06434" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral Presentation</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="zhang2022convergence" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2111.00185" target="_blank" rel="external nofollow noopener">Convergence and Optimality of Policy Gradient Methods in Weakly Smooth Settings.</a> </div> <div class="author"> Matthew Shunshi Zhang, Murat Erdogdu, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Confernce on Artificial Intelligence (AAAI)</em>, 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2111.00185" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/trifinger-report.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="trifinger-report.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bauer21rrc" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2109.10957" target="_blank" rel="external nofollow noopener">Real Robot Challenge: A Robotics Competition in the Cloud.</a> </div> <div class="author"> Stefan Bauer, Manuel Wüthrich, Felix Widmaier, Annika Buchholz, Sebastian Stark, Anirudh Goyal, Thomas Steinbrenner, Joel Akpo, Shruti Joshi, Vincent Berenz, Vaibhav Agrawal, Niklas Funk, Julen Urain De Jesus, Jan Peters, Joe Watson, Claire Chen, <span class="more-authors" title="click to view 25 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '25 more authors' ? 'Krishnan Srinivasan, Junwu Zhang, Jeffrey Zhang, Matthew Walter, Rishabh Madan, Takuma Yoneda, Denis Yarats, Arthur Allshire, Ethan Gordon, Tapomayukh Bhattacharjee, Siddhartha Srinivasa, Animesh Garg, Takahiro Maeda, Harshit Sikchi, Jilong Wang, Qingfeng Yao, Shuyu Yang, Robert McCarthy, Francisco Sanchez, Qiang Wang, David Bulens, Kevin McGuinness, Noel O’Connor, Redmond Stephen, Bernhard Schölkopf' : '25 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">25 more authors</span> </div> <div class="periodical"> <em>In Neural Information Processing Systems (NeurIPS) Competitions and Demonstrations Track</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2109.10957" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://proceedings.mlr.press/v176/bauer22a/bauer22a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/db-neurips21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="db-neurips21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bai2021db" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2110.10735" target="_blank" rel="external nofollow noopener">Dynamic Bottleneck for Robust Self-Supervised Exploration.</a> </div> <div class="author"> Chenjia Bai, Lingxiao Wang, Lei Han, <em>Animesh Garg</em>, Jianye Hao, Peng Liu, and Zhaoran Wang </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2110.10735" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/nha-neurips21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="nha-neurips21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="poli2021nha" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2106.04165" target="_blank" rel="external nofollow noopener">Neural Hybrid Automata: Learning Dynamics with Multiple Modes and Stochastic Transitions.</a> </div> <div class="author"> Michael Poli, Stefano Massaroli, Luca Scimeca, Seong Joon Oh, Sanghyuk Chun, Atsushi Yamashita, Hajime Asama, Jinkyoo Park, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2106.04165" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/drop-dtw21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="drop-dtw21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="dvornik2021dropdtw" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2108.11996" target="_blank" rel="external nofollow noopener">Drop-DTW: Aligning Common Signal Between Sequences While Dropping Outliers.</a> </div> <div class="author"> Nikita Dvornik, Isma Hadji, Konstantinos G. Derpanis, <em>Animesh Garg</em>, and Allan D. Jepson </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2108.11996" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/corl21-transparenet.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="corl21-transparenet.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="transpareNet2021" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2110.00087" target="_blank" rel="external nofollow noopener">Seeing Glass: Joint Point-Cloud and Depth Completion for Transparent Objects.</a> </div> <div class="author"> Haoping Xu, Yi Ru Wang, Sagi Eppel, Alan Aspuru-Guzik, Florian Shkurti, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Conference on Robot Learning (CoRL)</em>, 2021 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2110.00087" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/pairlab/TranspareNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://www.pair.toronto.edu/TranspareNet/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral Presentation</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/s4rl-offline-rl-arxiv21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="s4rl-offline-rl-arxiv21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sinha2021s4rl" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2103.06326" target="_blank" rel="external nofollow noopener">S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning.</a> </div> <div class="author"> Samarth Sinha, Ajay Mandlekar, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Conference on Robot Learning (CoRL)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2103.06326" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/corl21-hlsm.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="corl21-hlsm.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="blukis2021hlsm" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2107.05612" target="_blank" rel="external nofollow noopener">A Persistent Spatial Semantic Representation for High-level Natural Language Instruction Execution.</a> </div> <div class="author"> Valts Blukis, Chris Paxton, Dieter Fox, <em>Animesh Garg</em>, and Yoav Artzi </div> <div class="periodical"> <em>In Conference on Robot Learning (CoRL)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2107.05612" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/valtsblukis/hlsm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://openreview.net/attachment?id=NeGDZeyjcKa&amp;name=poster" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-tv"></i> Poster</a> <a href="https://hlsm-alfred.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/lbw-arxiv21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lbw-arxiv21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xiong2021lbw" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2101.07241" target="_blank" rel="external nofollow noopener">Learning by Watching: Physical Imitation of Manipulation Skills from Human Videos.</a> </div> <div class="author"> Haoyu Xiong, Quanzhou Li, Yun-Chun Chen, Homanga Bharadhwaj, Samarth Sinha, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2101.07241" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/Retu1q-BbEo" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://www.pair.toronto.edu/lbw-kp/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/losey_auro2021.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="losey_auro2021.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="losey2021auro" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2107.02907" target="_blank" rel="external nofollow noopener">Learning Latent Actions to Control Assistive Robots.</a> </div> <div class="author"> Dylan P. Losey, Hong Jun Jeon, Mengxi Li, Krishnan Srinivasan, Ajay Mandlekar, <em>Animesh Garg</em>, Jeannette Bohg, and Dorsa Sadigh </div> <div class="periodical"> <em>Autonomous Robots (AURO)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2107.02907" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/rfvi-rss21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rfvi-rss21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lutter2021rfvi" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2105.12189" target="_blank" rel="external nofollow noopener">Robust Value Iteration for Continuous Control Tasks.</a> </div> <div class="author"> Michael Lutter, Shie Mannor, Jan Peters, Dieter Fox, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Robotics: Systems and Science (RSS)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2105.12189" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://sites.google.com/view/rfvi" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/gift-rss21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="gift-rss21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="turpin2021gift" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2106.14973" target="_blank" rel="external nofollow noopener">GIFT: Generalizable Interaction-aware Functional Tool Affordances without Labels.</a> </div> <div class="author"> Dylan Turpin, Liquan Wang, Stavros Tsogkas, Sven Dickinson, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Robotics: Systems and Science (RSS)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2106.14973" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://streamable.com/eylzdj" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://www.pair.toronto.edu/blog/2021/giftturpin/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/disect-rss21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="disect-rss21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="heiden2021disect" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2105.12244" target="_blank" rel="external nofollow noopener">DiSeCT: A Differentiable Simulation Engine for Autonomous Robotic Cutting.</a> </div> <div class="author"> Eric Heiden, Miles Macklin, Yashraj Narang, Dieter Fox, <em>Animesh Garg</em>, and Fabio Ramos </div> <div class="periodical"> <em>In Robotics: Systems and Science (RSS)</em>, 2021 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2105.12244" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/JEMLGq7eRLc" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://developer.nvidia.com/blog/nvidia-research-disect-a-differentiable-simulation-engine-for-autonomous-robotic-cutting/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> <a href="https://github.com/NVlabs/DiSECt" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://diff-cutting-sim.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Student Paper Award</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/cfvi-icml21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cfvi-icml21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lutter2021cfvi" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2105.04682" target="_blank" rel="external nofollow noopener">Value Iteration in Continuous Actions, States and Time.</a> </div> <div class="author"> Michael Lutter, Shie Mannor, Jan Peters, Dieter Fox, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2105.04682" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://sites.google.com/view/value-iteration" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/ob2i-icml21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ob2i-icml21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bai2021exploration" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2105.06022" target="_blank" rel="external nofollow noopener">Principled Exploration via Optimistic Bootstrapping and Backward Induction.</a> </div> <div class="author"> Chenjia Bai, Lingxiao Wang, Lei Han, Jianye Hao, <em>Animesh Garg</em>, Peng Liu, and Zhaoran Wang </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2105.06022" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/Baichenjia/OB2I" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/coach-icml21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="coach-icml21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="liu2021coach" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2105.08692" target="_blank" rel="external nofollow noopener">Coach-Player Multi-agent Reinforcement Learning for Dynamic Team Composition.</a> </div> <div class="author"> Bo Liu, Qiang Liu, Lei Han, Peter Stone, <em>Animesh Garg</em>, Yuke Zhu, and Anima Anandkumar </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2021 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2105.08692" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Long Talk</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/tesseract-icml21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tesseract-icml21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mahajan2021tesseract" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2106.00136" target="_blank" rel="external nofollow noopener">Tesseract: Tensorised Actors for Multi-Agent Reinforcement Learning.</a> </div> <div class="author"> Anuj Mahajan, Mikayel Samvelyan, Lei Mao, Viktor Makoviychuk, <em>Animesh Garg</em>, Jean Kossaifi, Shimon Whiteson, Yuke Zhu, and Anima Anandkumar </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2106.00136" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/laser-icra21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="laser-icra21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="allshire2021laser" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2103.15793" target="_blank" rel="external nofollow noopener">LASER: Learning a Latent Action Space for Efficient Reinforcement Learning.</a> </div> <div class="author"> Arthur Allshire, Roberto Martin-Martin, Charles Lin, Shawn Mendes, Silvio Savarese, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2103.15793" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/c3Vb-_2HSxk" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://www.pair.toronto.edu/laser/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/dynrand-icra21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dynrand-icra21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xie2021dynamics" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2011.02404" target="_blank" rel="external nofollow noopener">Dynamics Randomization Revisited:A Case Study for Quadrupedal Locomotion.</a> </div> <div class="author"> Zhaoming Xie, Xingye Da, Michiel van de Panne, Buck Babich, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2011.02404" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://www.pair.toronto.edu/understanding-dr/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/leaf-icra21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="leaf-icra21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bharadhwaj2021leaf" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2005.10934" target="_blank" rel="external nofollow noopener">LEAF: Latent Exploration Along the Frontier.</a> </div> <div class="author"> Homanga Bharadhwaj, <em>Animesh Garg</em>, and Florian Shkurti </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2005.10934" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://sites.google.com/view/leaf-exploration" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/labo-icra21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="labo-icra21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pan2021emergent" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2012.12209" target="_blank" rel="external nofollow noopener">Emergent Hand Morphology and Control from Optimizing Robust Grasps of Diverse Objects.</a> </div> <div class="author"> Xinlei Pan, <em>Animesh Garg</em>, Animashree Anandkumar, and Yuke Zhu </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2012.12209" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://xinleipan.github.io/emergent_morphology/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/lsp-iclr21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lsp-iclr21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xie2021skill" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2011.13897" target="_blank" rel="external nofollow noopener">Latent Skill Planning for Exploration and Transfer.</a> </div> <div class="author"> Kevin Xie, Homanga Bharadhwaj, Danijar Hafner, <em>Animesh Garg</em>, and Florian Shkurti </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2011.13897" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://sites.google.com/view/partial-amortization-hierarchy/home" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/clearning-iclr21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="clearning-iclr21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="naderian2021clearning" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2011.12363" target="_blank" rel="external nofollow noopener">C-Learning: Horizon-Aware Cumulative Accessibility Estimation.</a> </div> <div class="author"> Panteha Naderian, Gabriel Loaiza-Ganem, Harry J. Braviner, Anthony L. Caterini, Jesse C. Cresswell, Tong Li, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2011.12363" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://sites.google.com/view/learning-cae/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/csc-iclr21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="csc-iclr21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bharadhwaj2021csc" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2010.14497" target="_blank" rel="external nofollow noopener">Conservative Safety Critics for Exploration.</a> </div> <div class="author"> Homanga Bharadhwaj, Aviral Kumar, Nicholas Rhinehart, Sergey Levine, Florian Shkurti, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2010.14497" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://sites.google.com/view/conservative-safety-critics/home" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/dibs-aaai21.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dibs-aaai21.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sinha2021dibs" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2003.04514" target="_blank" rel="external nofollow noopener">DIBS: Diversity inducing Information Bottleneck in Model Ensembles.</a> </div> <div class="author"> Samarth Sinha, Homanga Bharadhwaj, Anirudh Goyal, Hugo Larochelle, <em>Animesh Garg</em>, and Florian Shkurti </div> <div class="periodical"> <em>In Confernce on Artificial Intelligence (AAAI)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2003.04514" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/unsup-kp-pami21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="unsup-kp-pami21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="dundar2021pami" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2001.09518" target="_blank" rel="external nofollow noopener">Unsupervised Disentanglement of Pose, Appearance and Background from Images and Videos.</a> </div> <div class="author"> Aysegul Dundar, Kevin J. Shih, <em>Animesh Garg</em>, Robert Pottorf, Andrew Tao, and Bryan Catanzaro </div> <div class="periodical"> <em>Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</em>, 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2001.09518" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/NVIDIA/UnsupervisedLandmarkLearning" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/vcdn-neurips20.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="vcdn-neurips20.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="li2020vcdn" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2007.00631" target="_blank" rel="external nofollow noopener">Causal Discovery in Physical Systems from Videos.</a> </div> <div class="author"> Yunzhu Li, Antonio Torralba, Animashree Anandkumar, Dieter Fox, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems 33 (NeurIPS)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2007.00631" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://yunzhuli.github.io/V-CDN/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/coda-neurips21.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="coda-neurips21.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pitis2020counterfactual" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2007.02863" target="_blank" rel="external nofollow noopener">Counterfactual Data Augmentation using Locally Factored Dynamics.</a> </div> <div class="author"> Silviu Pitis, Elliot Creager, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems 33 (NeurIPS)</em>, 2020 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2007.02863" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/spitis/mrl/tree/master/experiments/coda" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Outstanding Paper Award at Object-Oriented Learning Workshop, ICML 2020</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/cbs-neurips20.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cbs-neurips20.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sinha2020cbs" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2003.01367" target="_blank" rel="external nofollow noopener">Curriculum By Smoothing.</a> </div> <div class="author"> Samarth Sinha, <em>Animesh Garg</em>, and Hugo Larochelle </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems 33 (NeurIPS)</em>, 2020 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2003.01367" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Spotlight Talk</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/adaptive-corl21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="adaptive-corl21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="da2020learning" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2009.10019" target="_blank" rel="external nofollow noopener">Learning a Contact-Adaptive Controller for Robust, Efficient Legged Locomotion.</a> </div> <div class="author"> Xingye Da, Zhaoming Xie, David Hoeller, Byron Boots, Animashree Anandkumar, Yuke Zhu, Buck Babich, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Conference on Robot Learning (CoRL)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2009.10019" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=JJOmFZKpYTo" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://news.developer.nvidia.com/contact-adaptive-controller-locomotion/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/visuomotor-ms-iros20.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="visuomotor-ms-iros20.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kurenkov2020vismechsearch" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2008.06073" target="_blank" rel="external nofollow noopener">Visuomotor Mechanical Search: Learning to Retrieve Target Objects in Clutter.</a> </div> <div class="author"> Andrey Kurenkov, Joseph Taglic, Rohun Kulkarni, Marcus Dominguez-Kuhne, <em>Animesh Garg</em>, Roberto Martín-Martín, and Silvio Saverese </div> <div class="periodical"> <em>In IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2008.06073" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://ai.stanford.edu/mech-search/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/ocean-uai21.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ocean-uai21.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ren2020ocean" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2008.07087" target="_blank" rel="external nofollow noopener">Ocean: Online Task Inference for Compositional Tasks with Context Adaptation.</a> </div> <div class="author"> Hongyu Ren, Yuke Zhu, Jure Leskovec, Anima Anandkumar, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Conference on Uncertainty in Artificial Intelligence (UAI)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2008.07087" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="http://www.auai.org/uai2020/proceedings/569_main_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://github.com/pairlab/ocean" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/condensa-micro20.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="condensa-micro20.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="joseph2020condensa" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1911.02497" target="_blank" rel="external nofollow noopener">A Programmable Approach to Neural Network Compression.</a> </div> <div class="author"> Vinu Joseph, Ganesh Gopalakrishnan, Saurav Muralidharan, Michael Garland, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>IEEE Micro</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/1911.02497" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://ieeexplore.ieee.org/document/9151283" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://github.com/NVlabs/condensa" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://sites.google.com/view/condensa-bo/home" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/s3gan-icml20.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="s3gan-icml20.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="nie2020semisupervised" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2003.03461" target="_blank" rel="external nofollow noopener">Semi-Supervised StyleGAN for Disentanglement Learning.</a> </div> <div class="author"> Weili Nie, Tero Karras, <em>Animesh Garg</em>, Shoubhik Debhath, Anjul Patney, Ankit B. Patel, and Anima Anandkumar </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2003.03461" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/NVlabs/High-res-disentanglement-datasets" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://docs.google.com/presentation/d/127ChXpeWUNXIOkf6Z6qB201BhnJUxZepK4mvtsq9ELM/edit?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-regular fa-file-powerpoint"></i> Slides</a> <a href="https://sites.google.com/nvidia.com/semi-stylegan" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/avh-icml20.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="avh-icml20.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2020avh" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1912.02279" target="_blank" rel="external nofollow noopener">Angular Visual Hardness.</a> </div> <div class="author"> Beidi Chen, Weiyang Liu, <em>Animesh Garg</em>, Zhiding Yu, Anshumali Shrivastava, Jan Kautz, and Anima Anandkumar </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/1912.02279" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://proceedings.icml.cc/paper/2020/hash/7cc5ca26d6fbb6db2b134ef07cc68925-Abstract.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://icml.cc/media/Slides/icml/2020/virtual(no-parent)-14-15-00UTC-6648-angular_visual_.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fa-regular fa-file-powerpoint"></i> Slides</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/lsc-icra20.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lsc-icra20.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="losey2020controlling" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1909.09674" target="_blank" rel="external nofollow noopener">Controlling Assistive Robots with Learned Latent Actions.</a> </div> <div class="author"> Dylan P. Losey, Krishnan Srinivasan, Ajay Mandlekar, <em>Animesh Garg</em>, and Dorsa Sadigh </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/1909.09674" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/wjnhrzugBj4" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="http://ai.stanford.edu/blog/assistive-latent-spaces/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/iris-icra20.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="iris-icra20.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mandlekar2020iris" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1911.05321" target="_blank" rel="external nofollow noopener">IRIS: Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data.</a> </div> <div class="author"> Ajay Mandlekar, Fabio Ramos, Byron Boots, Silvio Savarese, Li Fei-Fei, <em>Animesh Garg</em>, and Dieter Fox </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/1911.05321" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/H9KZgrI2I7I" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://sites.google.com/stanford.edu/iris/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/motion-reasoning-iros19.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="motion-reasoning-iros19.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="huang2020motion" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1911.05864" target="_blank" rel="external nofollow noopener">Motion Reasoning for Goal-Based Imitation Learning.</a> </div> <div class="author"> De-An Huang, Yu-Wei Chao, Chris Paxton, Xinke Deng, Li Fei-Fei, Juan Carlos Niebles, <em>Animesh Garg</em>, and Dieter Fox </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/1911.05864" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=OdqJuvAHvGE" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/guapo-icra20.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="guapo-icra20.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lee2020combining" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2005.10872" target="_blank" rel="external nofollow noopener">Guided Uncertainty-Aware Policy Optimization: Combining Learning and Model-Based Strategies for Sample-Efficient Policy Learning.</a> </div> <div class="author"> Michelle A. Lee, Carlos Florensa, Jonathan Tremblay, Nathan Ratliff, <em>Animesh Garg</em>, Fabio Ramos, and Dieter Fox </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2020 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/2005.10872" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/NwMukXa8kys" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Paper Award at 2019 Neurips Workshop on Robot Learning</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/lee-tro20-making.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lee-tro20-making.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lee2020making" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1907.13098" target="_blank" rel="external nofollow noopener">Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks.</a> </div> <div class="author"> Michelle A. Lee, Yuke Zhu, Peter Zachares, Matthew Tan, Krishnan Srinivasan, Silvio Savarese, Li Fei-Fei, <em>Animesh Garg</em>, and Jeannette Bohg </div> <div class="periodical"> <em>IEEE Transactions on Robotics (T-RO)</em>, 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/1907.13098" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://sites.google.com/view/visionandtouch" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="martin2019variable" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1906.08880" target="_blank" rel="external nofollow noopener">Variable Impedance Control in End-Effector Space: An Action Space for Reinforcement Learning in Contact-Rich Tasks.</a> </div> <div class="author"> Roberto Martı́n-Martı́n, Michelle A Lee, Rachel Gardner, Silvio Savarese, Jeannette Bohg, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2019 </div> <div class="links"> <a href="http://arxiv.org/abs/1906.08880" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://stanfordvl.github.io/vices/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/roboturk-real-iros19.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="roboturk-real-iros19.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mandlekar2019roboturkreal" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1911.04052" target="_blank" rel="external nofollow noopener">Scaling Robot Supervision to Hundreds of Hours with RoboTurk: Robotic Manipulation Dataset through Human Reasoning and Dexterity.</a> </div> <div class="author"> Ajay Mandlekar, Jonathan Booher, Max Spero, Albert Tung, Anchit Gupta, Yuke Zhu, <em>Animesh Garg</em>, Silvio Savarese, and Li Fei-Fei </div> <div class="periodical"> <em>In IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2019 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/1911.04052" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="http://ai.stanford.edu/blog/roboturk/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> <a href="https://cvgl.stanford.edu/projects/roboturk/ccr-web/dataset_real.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="http://roboturk.stanford.edu/realrobotdataset" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>IROS Best Cognitive Robotics Paper Finalist</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="huang2019continuous" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1908.06769" target="_blank" rel="external nofollow noopener">Continuous Relaxation of Symbolic Planner for One-Shot Imitation Learning.</a> </div> <div class="author"> De-An Huang, Danfei Xu, Yuke Zhu, <em>Animesh Garg</em>, Silvio Savarese, Li Fei-Fei, and Juan Carlos Carlos </div> <div class="periodical"> <em>In IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2019 </div> <div class="links"> <a href="http://arxiv.org/abs/1908.06769" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=emSbxWlOQBc" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/cavin-corl19.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cavin-corl19.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="fang2019dynamics" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1910.13395" target="_blank" rel="external nofollow noopener">Dynamics Learning with Cascaded Variational Inference for Multi-Step Manipulation.</a> </div> <div class="author"> Kuan Fang, Yuke Zhu, <em>Animesh Garg</em>, Silvio Savarese, and Li Fei-Fei </div> <div class="periodical"> <em>In Conference on Robot Learning (CoRL)</em>, 2019 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/1910.13395" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="http://pair.stanford.edu/cavin/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral Presentation</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/acteach-corl19.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="acteach-corl19.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kurenkov2019ac" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1909.04121" target="_blank" rel="external nofollow noopener">AC-Teach: A Bayesian Actor-Critic Method for Policy Learning with an Ensemble of Suboptimal Teachers.</a> </div> <div class="author"> Andrey Kurenkov, Ajay Mandlekar, Roberto Martín-Martín, Silvio Savarese, and <em>Animesh Garg</em> </div> <div class="periodical"> <em>In Conference on Robot Learning (CoRL)</em>, 2019 </div> <div class="links"> <a href="http://arxiv.org/abs/1909.04121" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="http://ai.stanford.edu/blog/acteach/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> <a href="https://github.com/StanfordVL/ac-teach" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://sites.google.com/view/acteach/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="fang2018tog-ijrr" class="col-sm-9"> <div class="title"> <a href="https://doi.org/10.1177%2F0278364919872545" target="_blank" rel="external nofollow noopener">Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision.</a> </div> <div class="author"> Kuan Fang, Yuke Zhu, <em>Animesh Garg</em>, Andrey Kurenkov, Viraj Mehta, Li Fei-Fei, and Silvio Savarese </div> <div class="periodical"> <em>International Journal of Robotics Research (IJRR)</em>, 2019 </div> <div class="links"> <a href="https://doi.org/10.1177%2F0278364919872545" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=YI-3sf067f8" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://sites.google.com/view/task-oriented-grasp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/ntg-cvpr19.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ntg-cvpr19.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="huang2018ntg" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1807.03480" target="_blank" rel="external nofollow noopener">Neural Task Graphs: Generalizing to unseen tasks from a single video demonstration.</a> </div> <div class="author"> De-An Huang, Suraj Nair, Danfei Xu, Yuke Zhu, <em>Animesh Garg</em>, Li Fei-Fei, Silvio Savarese, and Juan Carlos Niebles </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/1807.03480" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=Rwog52mbMCI&amp;feature=youtu.be" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral Presentation</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/multimodal-icra19.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="multimodal-icra19.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lee2019making" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1810.10191" target="_blank" rel="external nofollow noopener">Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks.</a> </div> <div class="author"> Michelle A Lee<sup>*</sup>, Yuke Zhu<sup>*</sup>, Krishnan Srinivasan, Parth Shah, Silvio Savarese, Li Fei-Fei, <em>Animesh Garg</em>, and Jeannette contribution) </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2019 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://arxiv.org/abs/1810.10191" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/usFQ8hNtE8c" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://sites.google.com/view/visionandtouch" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>ICRA Best Paper Award and Finalist: Best Cognitive Robotics Paper</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/mechsearch-icra19.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mechsearch-icra19.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="danielczuk2019mech" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1903.01588" target="_blank" rel="external nofollow noopener">Mechanical Search: Multi-Step Retrieval of a Target Object Occluded by Clutter.</a> </div> <div class="author"> Mike Danielczuk, Andrey Kurenkov, Ashwin Balakrishna, Matthew Matl, Roberto Martín-Martín, <em>Animesh Garg</em>, Silvio Savarese, and Ken Goldberg </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button"><i class="fas fa-filter"></i> Abs</a> <a href="http://arxiv.org/abs/1903.01588" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/lCwdGSDkbG4" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://ai.stanford.edu/mech-search/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="abstract hidden"> <p>When operating in unstructured environments such as warehouses, homes, and retail centers, robots are frequently required to interactively search for and retrieve specific objects from cluttered bins, shelves, or tables. Mechanical Search describes the class of tasks where the goal is to locate and extract a known target object. In this paper, we formalize Mechanical Search and study a version where distractor objects are heaped over the target object in a bin. The robot uses an RGBD perception system and control policies to iteratively select, parameterize, and perform one of 3 actions – push, suction, grasp – until the target object is extracted, or either a time limit is exceeded, or no high confidence push or grasp is available. We present a study of 5 algorithmic policies for mechanical search, with 15,000 simulated trials and 300 physical trials for heaps ranging from 10 to 20 objects. Results suggest that success can be achieved in this long-horizon task with algorithmic policies in over 95% of instances and that the number of actions required scales approximately linearly with the size of the heap.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mandlekar2018roboturk" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1811.02790" target="_blank" rel="external nofollow noopener">ROBOTURK: A Crowdsourcing Platform for Robotic Skill Learning through Imitation.</a> </div> <div class="author"> Ajay Mandlekar, Yuke Zhu, <em>Animesh Garg</em>, Jonathan Booher, Max Spero, Albert Tung, Julian Gao, John Emmons, Anchit Gupta, Emre Orbay, Silvio Savarese, and Li Fei-Fei </div> <div class="periodical"> <em>In Conference on Robot Learning (CoRL)</em>, 2018 </div> <div class="links"> <a href="http://arxiv.org/abs/1811.02790" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="http://proceedings.mlr.press/v87/mandlekar18a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="http://ai.stanford.edu/blog/roboturk/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> <a href="https://cvgl.stanford.edu/projects/roboturk/ccr-web/dataset_sim.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="http://roboturk.stanford.edu/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/tog-rss18.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tog-rss18.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="fang2018learning" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1806.09266" target="_blank" rel="external nofollow noopener">Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision.</a> </div> <div class="author"> Kuan Fang, Yuke Zhu, <em>Animesh Garg</em>, Andrey Kurenkov, Viraj Mehta, Li Fei-Fei, and Silvio Savarese </div> <div class="periodical"> <em>In Robotics: Systems and Science (RSS)</em>, 2018 </div> <div class="links"> <a href="http://arxiv.org/abs/1806.09266" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=YI-3sf067f8" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://sites.google.com/view/task-oriented-grasp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="swirl-ijrr18" class="col-sm-9"> <div class="title"> <a href="https://pairlab.github.io/al-folio/assets/pdf/garg_swirl_ijrr18.pdf" target="_blank">SWIRL: A Sequential Windowed Inverse Reinforcement Learning Algorithm for Robot Tasks With Delayed Rewards.</a> </div> <div class="author"> Sanjay Krishnan, <em>Animesh Garg</em>, Richard Liaw, Brijen Thananjeyan, Lauren Miller, Florian T Pokorny, and Ken Goldberg </div> <div class="periodical"> <em>International Journal of Robotics Research (IJRR)</em>, 2018 </div> <div class="links"> <a href="https://doi.org/10.1177%2F0278364918784350" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-link"></i> link</a> <a href="/al-folio/assets/pdf/garg_swirl_ijrr18.pdf" class="btn btn-sm z-depth-0" role="button"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/finding-it-cvpr18.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="finding-it-cvpr18.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="huang18ramil" class="col-sm-9"> <div class="title"> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Finding_It_Weakly-Supervised_CVPR_2018_paper.pdf" target="_blank" rel="external nofollow noopener">Finding It: Weakly-Supervised Reference-Aware Visual Grounding in Instructional Video.</a> </div> <div class="author"> De-An Huang, Shyamal Buch, Lucio Dery, <em>Animesh Garg</em>, Li Fei-Fei, and Juan Carlos Niebles </div> <div class="periodical"> <em>In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2018 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Finding_It_Weakly-Supervised_CVPR_2018_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://drive.google.com/file/d/1uvnw6VDn0r1nS3ePyFKaCbEx5GZw1ZEy/view" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-tv"></i> Poster</a> <a href="https://finding-it.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral Presentation</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/ntp-icra18.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ntp-icra18.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xu2018neural" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1710.01813" target="_blank" rel="external nofollow noopener">Neural Task Programming: Learning to generalize across hierarchical tasks.</a> </div> <div class="author"> Danfei Xu, Suraj Nair, Yuke Zhu, Julian Gao, <em>Animesh Garg</em>, Li Fei-Fei, and Silvio Savarese </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2018 </div> <div class="links"> <a href="http://arxiv.org/abs/1710.01813" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=THq7I7C5rkk&amp;feature=youtu.be" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://stanfordvl.github.io/ntp/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kurenkov2018deformnet" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1708.04672" target="_blank" rel="external nofollow noopener">DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction from a Single Image.</a> </div> <div class="author"> Andrey Kurenkov<sup>*</sup>, Jingwei Ji<sup>*</sup>, <em>Animesh Garg</em>, Viraj Mehta, JunYoung Gwak, Christopher Choy, and Silvio contribution) </div> <div class="periodical"> <em>In IEEE Winter Conference on Applications of Computer Vision (WACV)</em>, 2018 </div> <div class="links"> <a href="http://arxiv.org/abs/1708.04672" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://deformnet-site.github.io/DeformNet-website/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="harrison2017adapt" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1707.04674" target="_blank" rel="external nofollow noopener">AdaPT: Zero-Shot Adaptive Policy Transfer for Stochastic Dynamical Systems.</a> </div> <div class="author"> James Harrison<sup>*</sup>, <em>Animesh Garg<sup>*</sup></em>, Boris Ivanovic, Yuke Zhu, Silvio Savarese, Li Fei-Fei, and Marco contribution) </div> <div class="periodical"> <em>In International Symposium on Robotics Research (ISRR)</em>, 2017 </div> <div class="links"> <a href="http://arxiv.org/abs/1707.04674" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="tsc-ijrr17" class="col-sm-9"> <div class="title"> <a href="https://dl.acm.org/doi/abs/10.1177/0278364917743319" target="_blank" rel="external nofollow noopener">Transition State Clustering: Unsupervised surgical trajectory segmentation for robot learning.</a> </div> <div class="author"> Sanjay Krishnan<sup>*</sup>, <em>Animesh Garg<sup>*</sup></em>, Sachin Patil, Colin Lea, Gregory Hager, Pieter Abbeel, and Ken contribution) </div> <div class="periodical"> <em>International Journal of Robotics Research (IJRR)</em>, 2017 </div> <div class="links"> <a href="https://dl.acm.org/doi/abs/10.1177/0278364917743319" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="https://github.com/BerkeleyAutomation/tsc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="gwak2017weakly" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1705.10904" target="_blank" rel="external nofollow noopener">Weakly supervised 3D Reconstruction with Adversarial Constraint.</a> </div> <div class="author"> JunYoung Gwak<sup>*</sup>, Christopher B Choy<sup>*</sup>, <em>Animesh Garg</em>, Manmohan Chandraker, and Silvio contribution) </div> <div class="periodical"> <em>In IEEE Conference on 3D Vision (3DV)</em>, 2017 </div> <div class="links"> <a href="http://arxiv.org/abs/1705.10904" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/jgwak/McRecon" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mandlekar2017arpl" class="col-sm-9"> <div class="title"> <a href="https://stanfordvl.github.io/ARPL/arpl_mzg_iros17.pdf" target="_blank" rel="external nofollow noopener">Adversarially Robust Policy Learning: Active Construction of Physically-Plausible Perturbations.</a> </div> <div class="author"> Ajay Mandlekar<sup>*</sup>, Yuke Zhu<sup>*</sup>, <em>Animesh Garg<sup>*</sup></em>, Li Fei-Fei, and Silvio contribution) </div> <div class="periodical"> <em>In IEEE International Conference on Intelligent Robots and Systems (IROS)</em>, 2017 </div> <div class="links"> <a href="https://stanfordvl.github.io/ARPL/arpl_mzg_iros17.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=yZ-gSsbbzh0" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://stanfordvl.github.io/ARPL/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="thananjeyan2017multilateral" class="col-sm-9"> <div class="title"> <a href="https://ieeexplore.ieee.org/document/7989275" target="_blank" rel="external nofollow noopener">Multilateral Surgical Pattern Cutting in 2D Orthotropic Gauze with Deep Reinforcement Learning Policies for Tensioning.</a> </div> <div class="author"> Brijen Thananjeyan, <em>Animesh Garg</em>, Sanjay Krishnan, Carolyn Chen, Lauren Miller, and Ken Goldberg </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2017 </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/7989275" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=l6gQg2VbGcc" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="krishnan2016swirl" class="col-sm-9"> <div class="title"> <a href="https://pairlab.github.io/al-folio/assets/pdf/krishnan-SWIRL-WAFR-2016.pdf" target="_blank">SWIRL: A Sequential Windowed Inverse Reinforcement Learning Algorithm for Robot Tasks With Delayed Rewards.</a> </div> <div class="author"> Sanjay Krishnan, <em>Animesh Garg</em>, Richard Liaw, Brijen Thananjeyan, Lauren Miller, Florian T Pokorny, and Ken Goldberg </div> <div class="periodical"> <em>In Workshop on Algorithmic Foundations of Robotics (WAFR)</em>, 2016 </div> <div class="links"> <a href="/al-folio/assets/pdf/krishnan-SWIRL-WAFR-2016.pdf" class="btn btn-sm z-depth-0" role="button"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/pida-case16.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="pida-case16.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mckinley2016pida" class="col-sm-9"> <div class="title"> Interchangeable Surgical Instrument System with Application to Supervised Automation of Multilateral Tumor Resection. . </div> <div class="author"> Stephen McKinley, <em>Animesh Garg</em>, Siddarth Sen, David V. Gealy, Jonathan McKinley, Yiming Jen, Menglung Guo, Doug Boyd, and Ken Goldberg </div> <div class="periodical"> <em>In IEEE International Conference on Automation Science &amp; Engg. (CASE)</em>, 2016 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=YiPq9t0tR3U" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="http://berkeleyautomation.github.io/surgical-tools/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Video Award at 2015 Hamlyn Symposium</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="murali2016tscdl" class="col-sm-9"> <div class="title"> TSC-DL: Unsupervised Trajectory Segmentation of Multi-Modal Surgical Demonstrations with Deep Learning . </div> <div class="author"> Adithyavairavan Murali<sup>*</sup>, <em>Animesh Garg<sup>*</sup></em>, Sanjay Krishnan<sup>*</sup>, Florian Pokorny, Pieter Abbeel, Trevor Darrell, and Ken contribution) </div> <div class="periodical"> <em>In IEEE International Conference on Robotics &amp; Automation (ICRA)</em>, 2016 </div> <div class="links"> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/L561cJh7DLE" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://github.com/BerkeleyAutomation/tsc-dl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="http://berkeleyautomation.github.io/tsc-dl/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/amts-icra16.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="amts-icra16.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sen2016suturing" class="col-sm-9"> <div class="title"> Automating Multi-Throw Multilateral Surgical Suturing with a Mechanical Needle Guide and Sequential Convex Optimization. </div> <div class="author"> Siddarth Sen<sup>*</sup>, <em>Animesh Garg<sup>*</sup></em>, David Gealy, Stephen McKinley, Yiming Jen, and Ken contribution) </div> <div class="periodical"> <em>In IEEE International Conference on Robotics &amp; Automation (ICRA)</em>, 2016 </div> <div class="links"> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/z1ehShXFToc" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="http://berkeleyautomation.github.io/amts/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/gpas-case16.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="gpas-case16.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="garg2016gpas" class="col-sm-9"> <div class="title"> <a href="http://berkeleyautomation.github.io/gpas/files/garg-case16-gpas.pdf" target="_blank" rel="external nofollow noopener">Tumor localization using automated palpation with Gaussian Process Adaptive Sampling.</a> </div> <div class="author"> <em>Animesh Garg</em>, Siddarth Sen, Rishi Kapadia, Yiming Jen, Stephen McKinley, Lauren Miller, and Ken Goldberg </div> <div class="periodical"> <em>In IEEE International Conference on Automation Science &amp; Engg. (CASE)</em>, 2016 </div> <div class="links"> <a href="http://berkeleyautomation.github.io/gpas/files/garg-case16-gpas.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="http://berkeleyautomation.github.io/gpas/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/sensor-case15.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sensor-case15.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mckinley2015disposable" class="col-sm-9"> <div class="title"> <a href="https://doi.org/10.1109/CoASE.2015.7294253" target="_blank" rel="external nofollow noopener">A Single-Use Haptic Palpation Probe for Locating Subcutaneous Blood Vessels in Robot-Assisted Minimally Invasive Surgery.</a> </div> <div class="author"> Stephen McKinley, <em>Animesh Garg</em>, Siddarth Sen, Rishi Kapadia, Adithyavairavan Murali, Kirk Nichols, Susan Lim, Sachin Patil, Pieter Abbeel, Allison M. Okamura, and Ken Goldberg </div> <div class="periodical"> <em>In IEEE International Conference on Automation Science &amp; Engg. (CASE)</em>, 2015 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a class="abstract btn btn-sm z-depth-0" role="button"><i class="fas fa-filter"></i> Abs</a> <a href="https://doi.org/10.1109/CoASE.2015.7294253" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Poster/Demo Award at ICRA 2015 Workshop on Shared Frameworks for Medical Robotics</p> </div> <div class="abstract hidden"> <p>We present the design and evaluation of a novel low-cost palpation probe for Robot assisted Minimally Invasive Surgery (RMIS) for localizing subcutaneous blood vessels. It measures probe tip deflection using a Hall Effect sensor as the spherical tip is moved tangentially across a surface under automated control. The probe is intended to be single-use and disposable, built from 3D printed parts and commercially available electronics. The prototype has a cross-section of less than 15mm×10mm and fits on the end of an 8mm diameter needle driver in the Intuitive Surgical da Vinci ® Research Kit (dVRK). We report experiments for quasi-static sliding palpation with silicone based tissue phantoms with embedded cylinders as subcutaneous blood vessel phantoms. We analyzed signal-to-noise ratios with multiple diameters of silicone cylinders (1.58-4.75 mm) at varying subcutaneous depths (1-5 mm) with a range of indentation depths (0-8 mm) and sliding speeds (0.5-21 mm/s). Results suggest that the probe can detect subcutaneous structures in phantoms of diameter 2.25 mm at a depth of up to 5mm below the tissue surface.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/lbo-icra15.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lbo-icra15.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="murali2015learning" class="col-sm-9"> <div class="title"> <a href="https://ieeexplore.ieee.org/document/7139344" target="_blank" rel="external nofollow noopener">Learning by Observation for Surgical Subtasks: Multilateral Cutting of 3D Viscoelastic and 2D Orthotropic Tissue Phantoms.</a> </div> <div class="author"> Adithyavairavan Murali, Siddarth Sen, Ben Kehoe, <em>Animesh Garg</em>, Seth McFarland, Sachin Patil, W Douglas Boyd, Susan Lim, Pieter Abbeel, and Ken Goldberg </div> <div class="periodical"> <em>In IEEE International Conference on Robotics &amp; Automation (ICRA)</em>, 2015 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a class="abstract btn btn-sm z-depth-0" role="button"><i class="fas fa-filter"></i> Abs</a> <a href="https://ieeexplore.ieee.org/document/7139344" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="http://www.youtube.com/watch?v=beVWB6NtAaA" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Finalist: Best Paper, Student Paper, and Medical Robotics Paper Award</p> </div> <div class="abstract hidden"> <p>Automating repetitive surgical subtasks such as suturing, cutting and debridement can reduce surgeon fatigue and procedure times and facilitate supervised tele-surgery. Programming is difficult because human tissue is deformable and highly specular. Using the da Vinci Research Kit (DVRK) robotic surgical assistant, we explore a “Learning By Observation” (LBO) approach where we identify, segment, and parameterize motion sequences and sensor conditions to build a finite state machine (FSM) for each subtask. The robot then executes the FSM repeatedly to tune parameters and if necessary update the FSM structure. We evaluate the approach on two surgical subtasks: debridement of 3D Viscoelastic Tissue Phantoms (3d-DVTP), in which small target fragments are removed from a 3D viscoelastic tissue phantom; and Pattern Cutting of 2D Orthotropic Tissue Phantoms (2d-PCOTP), a step in the standard Fundamentals of Laparoscopic Surgery training suite, in which a specified circular area must be cut from a sheet of orthotropic tissue phantom. We describe the approach and physical experiments with repeatability of 96% for 50 trials of the 3d-DVTP subtask and 70% for 20 trials of the 2d-PCOTP subtask.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="krishnan2015tsc" class="col-sm-9"> <div class="title"> Transition State Clustering: Unsupervised Surgical Trajectory Segmentation For Robot Learning. </div> <div class="author"> Sanjay Krishnan<sup>*</sup>, <em>Animesh Garg<sup>*</sup></em>, Sachin Patil, Colin Lea, Gregory Hager, Pieter Abbeel, and Ken contribution) </div> <div class="periodical"> <em>In International Symposium on Robotics Research (ISRR)</em>, 2015 </div> <div class="links"> <a href="https://github.com/BerkeleyAutomation/tsc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mellis2015material" class="col-sm-9"> <div class="title"> Evaluation of PC‐ISO for customized, 3D printed, gynecologic 192Ir HDR brachytherapy applicators. </div> <div class="author"> Katherine Mellis, Timmy Siauw, Atchar Sudhyadhom, Rajni Sethi, I-Chow Hsu, Jean Pouliot, <em>Animesh Garg</em>, and Ken Goldberg </div> <div class="periodical"> <em>Journal of Applied Clinical Medical Physics (JACMP)</em>, 2015 </div> <div class="links"> <a href="https://www.ncbi.nlm.nih.gov/pubmed/25679174" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="garg2014exact" class="col-sm-9"> <div class="title"> <a href="https://ieeexplore.ieee.org/document/6899376" target="_blank" rel="external nofollow noopener">Exact Reachability Analysis for Planning Skew-Line Needle Arrangements for Automated Brachytherapy.</a> </div> <div class="author"> <em>Animesh Garg</em>, Timmy Siauw, Guang Yang, Sachin Patil, J Adam M Cunha, I-Chow Hsu, Jean Pouliot, Alper Atamtürk, and Ken Goldberg </div> <div class="periodical"> <em>In IEEE International Conference on Automation Science &amp; Engg. (CASE)</em>, 2014 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button"><i class="fas fa-filter"></i> Abs</a> <a href="https://ieeexplore.ieee.org/document/6899376" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> <div class="abstract hidden"> <p>When planning skew-line needle arrangements for automated brachytherapy, one objective is to identify a set of candidate needles that enter from a specified entry region, avoid specified organs-at-risk and sufficiently cover the target (tumor) volume. Existing methods use uniform or random sampling to generate a set of candidate needles, which may not adequately cover the target volume. In this paper we present an exact reachability analysis that can be used to guide the selection of candidate needles and to identify which subset of the target volume may not be reachable. Assuming linear needles, convex polyhedral representations of entry zone, organs-at-risk and target volume, we give an exact polynomial time algorithm for checking existence and calculation of the non-reachable set in the target volume. We perform experiments using patient data from 18 brachytherapy cases and found that 11 cases had non-empty occluded volume inside the target ranging from 0.01% to 4.3% of target volume. We also report a sensitivity study showing the change in the occluded volume with dilation of the avoidance volume and entry zone.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="siauw2014customized" class="col-sm-9"> <div class="title"> <a href="https://doi.org/10.1016/j.brachy.2014.02.439" target="_blank" rel="external nofollow noopener">Customized Needle Guides for Inserting Non-Parallel Needle Arrangements in Prostate HDR Brachytherapy: A Phantom Study.</a> </div> <div class="author"> Timmy Siauw, J. Adam M. Cunha, <em>Animesh Garg</em>, Ken Goldberg, I Hsu, and Jean Pouliot </div> <div class="periodical"> <em>Brachytherapy</em>, 2014 </div> <div class="links"> <a href="https://doi.org/10.1016/j.brachy.2014.02.439" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="garg2013robot" class="col-sm-9"> <div class="title"> <a href="https://doi.org/10.1109/TASE.2013.2276940" target="_blank" rel="external nofollow noopener">Robot-Guided Open-Loop Insertion of Skew-Line Needle Arrangements for High Dose Rate Brachytherapy.</a> </div> <div class="author"> <em>Animesh Garg</em>, Timmy Siauw, Dmitry Berenson, J Adam M Cunha, I-C Hsu, Jean Pouliot, Dan Stoianovici, and Ken Goldberg </div> <div class="periodical"> <em>IEEE Transactions on Automation Science and Engineering (T-ASE)</em>, 2013 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button"><i class="fas fa-filter"></i> Abs</a> <a href="https://doi.org/10.1109/TASE.2013.2276940" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> <div class="abstract hidden"> <p>We present a study in human-centered automation that has potential to reduce patient side effects from high dose rate brachytherapy (HDR-BT). To efficiently deliver radiation to the prostate while minimizing trauma to sensitive structures such as the penile bulb, we modified the Acubot-RND 7-axis robot to guide insertion of diamond-tip needles into desired skew-line geometric arrangements. We extend and integrate two algorithms: Needle Planning with Integer Programming (NPIP) and Inverse Planning with Integer Programming (IPIP) to compute skew-line needle and dose plans. We performed three physical experiments with anatomically correct phantom models to study performance: two with the robot and one control experiment with an expert human physician (coauthor Hsu) without the robot. All were able to achieve needle arrangements that meet the RTOG-0321 clinical dose objectives with zero trauma to the penile bulb. We analyze systematic and random errors in needle placement; total RMS error for the robot system operating without feedback ranged from 2.6 to 4.3 mm, which is comparable to the RMS error of 2.7 mm obtained in an earlier study for PPI-BT treatment using a robot with 3D ultrasound feedback.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="garg2013algorithm" class="col-sm-9"> <div class="title"> <a href="https://ieeexplore.ieee.org/document/6654002" target="_blank" rel="external nofollow noopener">An Algorithm for Computing Customized 3D Printed Implants with Curvature Constrained Channels for Enhancing Intracavitary Brachytherapy Radiation Delivery.</a> </div> <div class="author"> <em>Animesh Garg</em>, Sachin Patil, Timmy Siauw, J Adam M Cunha, I Hsu, Pieter Abbeel, Jean Pouliot, and Ken Goldberg </div> <div class="periodical"> <em>In IEEE International Conference on Automation Science &amp; Engg. (CASE)</em>, 2013 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button"><i class="fas fa-filter"></i> Abs</a> <a href="https://ieeexplore.ieee.org/document/6654002" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> <div class="abstract hidden"> <p>Brachytherapy is a widely-used treatment modality for cancer in many sites in the body. In brachytherapy, small radioactive sources are positioned proximal to cancerous tumors. An ongoing challenge is to accurately place sources on a set of dwell positions to sufficiently irradiate the tumors while limiting radiation damage to healthy organs and tissues. In current practice, standardized applicators with internal channels are inserted into body cavities to guide the sources. These standardized implants are one-size-fits-all and are prone to shifting inside the body, resulting in suboptimal dosages. We propose a new approach that builds on recent results in 3D printing and steerable needle motion planning to create customized implants containing customized curvature-constrained internal channels that fit securely, minimize air gaps, and precisely guide radioactive sources through printed channels. When compared with standardized implants, customized implants also have the potential to provide better coverage: more potential source dwell positions proximal to tumors. We present an algorithm for computing curvature-constrained channels based on rapidly-expanding randomized trees (RRT). We consider a prototypical case of OB/GYN cervical and vaginal cancer with three treatment options: standardized ring implant (current practice), customized implant with linear channels, and customized implant with curved channels. Results with a two-parameter coverage metric suggest that customized implants with curved channels can offer significant improvement over current practice.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/acubot-case12.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="acubot-case12.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="garg2012initial" class="col-sm-9"> <div class="title"> <a href="https://doi.org/10.1109/CoASE.2012.6386483" target="_blank" rel="external nofollow noopener">Initial experiments toward automated robotic implantation of skew-line needle arrangements for HDR brachytherapy.</a> </div> <div class="author"> <em>A. Garg</em>, T. Siauw, D. Berenson, A. Cunha, I-Chow Hsu, J. Pouliot, D. Stoianovici, and K. Goldberg </div> <div class="periodical"> <em>In IEEE International Conference on Automation Science &amp; Engg. (CASE)</em>, 2012 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a class="abstract btn btn-sm z-depth-0" role="button"><i class="fas fa-filter"></i> Abs</a> <a href="https://doi.org/10.1109/CoASE.2012.6386483" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/Kk_wHiu8nGg" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>IEEE CASE Best Application Paper Award</p> </div> <div class="abstract hidden"> <p>Automation seeks to improve the reliability and quality of processes. This study aims to automate high dose rate brachytherapy (HDR-BT), a radiation therapy that places radioactive sources at the site of the tumor using needles. Although HDR-BT has a high rate of clinical success in curing prostate cancer, it also has several side effects related to needle and dose trauma. A new planning algorithm from previous work optimizes needle arrangements using skew-lines (non-parallel, non-intersecting lines). This paper presents initial experiments towards an automated system for implanting skew-line needle arrangements computed from a planning system. We describe the interface, calibration and integration of the robotic hardware with the planning system, and present experiments using our robotic system to implant needles into anatomically-correct tissue phantoms. Results suggest that this system can achieve HDR-BT treatment objectives with reduced trauma to organs and low demands on operator skill, thus making the procedure more reliable and repeatable. In the future, we believe that robotic HDR-BT will improve overall treatment quality with reduced dependence on physician skill.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="cunha2012robotic" class="col-sm-9"> <div class="title"> <a href="https://doi.org/10.1118/1.4736042" target="_blank" rel="external nofollow noopener">Robotic Brachytherapy Demonstration: Implant of HDR Brachytherapy Needle Configuration Computer-Optimized to Avoid Critical Structures Near the Bulb of the Penis.</a> </div> <div class="author"> JA Cunha, T Siauw, A Garg, N Zhang, K Goldberg, D Stoianovici, M Roach III, I-C Hsu, and J Pouliot </div> <div class="periodical"> <em>Medical Physics</em>, 2012 </div> <div class="links"> <a href="https://doi.org/10.1118/1.4736042" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="cunha2012robot" class="col-sm-9"> <div class="title"> <a href="https://www.thegreenjournal.com/article/S0167-8140(12)72081-9/abstract" target="_blank" rel="external nofollow noopener">Robot-guided Delivery of Brachytherapy Needles along Non-Parallel Paths to Avoid Penile Bulb Puncture.</a> </div> <div class="author"> JAM Cunha, A Garg, T Siauw, N Zhang, Y Zuo, K Goldberg, D Stoianovici, M Roach III, and J Pouliot </div> <div class="periodical"> <em>Radiotherapy and Oncology</em>, 2012 </div> <div class="links"> <a href="https://www.thegreenjournal.com/article/S0167-8140(12)72081-9/abstract" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="thakkar2012dtmf" class="col-sm-9"> <div class="title"> <a href="https://pairlab.github.io/al-folio/assets/pdf/10.4028/www.scientific.net/AMR.403-408.4727" target="_blank">Low-Cost Teleoperation of Remotely Located Actuators Based on Dual Tone Multi-Frequency Data Transfer.</a> </div> <div class="author"> Sahil Thakkar, <em>Animesh Garg</em>, Adesh Midha, and Prerna Gaur </div> <div class="periodical"> <em>In MEMS, NANO and Smart Systems</em>, 2012 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button"><i class="fas fa-filter"></i> Abs</a> <a href="/al-folio/assets/pdf/10.4028/www.scientific.net/AMR.403-408.4727" class="btn btn-sm z-depth-0" role="button"><i class="far fa-file-alt"></i> PDF</a> </div> <div class="abstract hidden"> <p>DTMF (Dual Tone Multi Frequency) is a system of signal tones used for telecommunications. DTMF uses two tones to represent each key on the touch pad. DTMF data transfer technique has advantages such as high reliability, constant speed, and high signal to noise ratio, low cost and optimal utilization of existing resources. These features make DTMF an attractive Data Transfer Technique. It finds application in home and car security systems, robot control, SMS and voice call controlled industrial applications. In this paper, we discuss the use of DTMF data transfer in a voice call to control a toy car. Cell phone 1(CP 1), which is at user end, makes a call to cell phone 2(CP 2) at the machine end and establishes a connection. A key is pressed at the user side. Two tones corresponding to one key are encoded and sent through the cell phone network. Both tones are tapped through the earphone jack of cell phone at machine end and are decoded. The output is fed to a Micro-controller. The Micro-controller is connected to the remote control unit of the toy car, which in turn controls the motion of the car. The car moves in various directions according to the key pressed user. The electronic circuit is divided into 2 parts. The transmitter side consisting of Cell phone 1 with an inbuilt encoder and the receiver side consisting of Cell Phone 2, 8870 DTMF decoder and Atmega 16 micro-controller. The programming has been carried out on AVR Bascom®.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="garg2012autotrix" class="col-sm-9"> <div class="title"> <a href="https://pairlab.github.io/al-folio/assets/pdf/10.4028/www.scientific.net/AMR.403-408.3884" target="_blank">The Autotrix: Design and Implementation of an Autonomous Urban Driving System.</a> </div> <div class="author"> <em>Animesh Garg</em>, Anju Toor, Sahil Thakkar, Shiwangi Goel, Sachin Maheshwari, and Satish Chand </div> <div class="periodical"> <em>In MEMS, NANO and Smart Systems</em>, 2012 </div> <div class="links"> <div class="keywords" style="display:none;"> <span class="badge bg-secondary" data-keywords="Path Planning, Obstacle Avoidance, Monocular Vision, Autonomous Driving, Global Positioning System in Urban Driving">Path Planning, Obstacle Avoidance, Monocular Vision, Autonomous Driving, Global Positioning System in Urban Driving</span> </div> <a class="abstract btn btn-sm z-depth-0" role="button"><i class="fas fa-filter"></i> Abs</a> <a href="/al-folio/assets/pdf/10.4028/www.scientific.net/AMR.403-408.3884" class="btn btn-sm z-depth-0" role="button"><i class="far fa-file-alt"></i> PDF</a> </div> <div class="abstract hidden"> <p>The Autotrix is an interactive, intelligent, Autonomous Guided Vehicle (AGV) designed to serve in urban environments. Autonomous ground vehicle navigation requires the integration of many technologies such as path planning, odometry, control, obstacle avoidance and situational awareness. The objective of this project is for this prototype to navigate autonomously in an urban environment and reach its destination while detecting and avoiding obstacles on the path .This will be achieved by extracting information from multiple sources of real-time data including digital camera, GPS &amp;ultra sonic sensors, collecting data from this extracted information, processing this data and send controlling instructions to our platform (Autotrix). The significance of this work is in presenting the methods needed for real time navigation; GPS based continuous mapping and obstacle avoidance for intelligent autonomous driving systems.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="garg2011object" class="col-sm-9"> <div class="title"> Object Identification and Mapping using Monocular Vision in an Autonomous Urban Driving System. </div> <div class="author"> <em>Animesh Garg</em>, Anju Toor, Sahil Thakkar, Shiwangi Goel, Sachin Maheshwari, and Satish Chand </div> <div class="periodical"> <em>In International Conference of Machine Vision</em>, 2010 </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">Preprints</h2> <ol class="bibliography" reversed="true"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="zhao2025anyplace" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2502.04531" target="_blank" rel="external nofollow noopener">AnyPlace: Learning Generalized Object Placement for Robot Manipulation.</a> </div> <div class="author"> Yuchi Zhao, Miroslav Bogdanovic, Chengyuan Luo, Steven Tohme, Kourosh Darvish, Alán Aspuru-Guzik, Florian Shkurti, and <em>Animesh Garg</em> </div> <div class="periodical"> 2025 </div> <div class="links"> <a href="http://arxiv.org/abs/2502.04531" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li></ol> <h2 class="bibliography">Peer-Reviewed Workshops</h2> <ol class="bibliography" reversed="true"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="bagajo2024diffsim2real" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2411.02189" target="_blank" rel="external nofollow noopener">DiffSim2Real: Deploying Quadrupedal Locomotion Policies Purely Trained in Differentiable Simulation.</a> </div> <div class="author"> Joshua Bagajo, Clemens Schwarke, Victor Klemm, Ignat Georgiev, Jean-Pierre Sleiman, Jesus Tordesillas, <em>Animesh Garg</em>, and Marco Hutter </div> <div class="periodical"> 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2411.02189" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="zhou2023multi" class="col-sm-9"> <div class="title"> Multi-Constraint Safe RL with Objective Suppression for Safety-Critical Applications. </div> <div class="author"> Zihan Zhou, Jonathan Booher, Wei Liu, Aleksandr Petiushko, and <em>Animesh Garg</em> </div> <div class="periodical"> 2023 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="sinha2022uniform" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2006.16524" target="_blank" rel="external nofollow noopener">Uniform Priors for Data-Efficient Transfer.</a> </div> <div class="author"> Samarth Sinha, Karsten Roth, Anirudh Goyal, Marzyeh Ghassemi, Hugo Larochelle, and <em>Animesh Garg</em> </div> <div class="periodical"> 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2006.16524" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/nmf-rss22.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="nmf-rss22.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2022neural" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2206.14854" target="_blank" rel="external nofollow noopener">Neural Motion Fields: Encoding Grasp Trajectories as Implicit Value Functions.</a> </div> <div class="author"> Yun-Chun Chen, Adithyavairavan Murali, Balakumar Sundaralingam, Wei Yang, <em>Animesh Garg</em>, and Dieter Fox </div> <div class="periodical"> 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2206.14854" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/d2rl-arxiv20.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="d2rl-arxiv20.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="d2rl2020" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2010.09163" target="_blank" rel="external nofollow noopener">D2RL: Deep Dense Architectures in Reinforcement Learning.</a> </div> <div class="author"> Samarth Sinha, Homanga Bharadhwaj, Aravind Srinivas, and <em>Animesh Garg</em> </div> <div class="periodical"> 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2010.09163" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://github.com/pairlab/d2rl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://sites.google.com/view/d2rl/home" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="pitis2020wkspcounterfactual" class="col-sm-9"> <div class="title"> Counterfactual Data Augmentation using Locally Factored Dynamics. </div> <div class="author"> Silviu Pitis, Elliot Creager, and <em>Animesh Garg</em> </div> <div class="periodical"> 2020 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="https://github.com/spitis/mrl/tree/master/experiments/coda" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-code"></i> Code</a> <a href="https://oolworkshop.github.io/program/ool_17.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-tv"></i> Poster</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Outstanding Paper Award at Object-Oriented Learning Workshop, ICML 2020</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="islam2022offline" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2212.14405" target="_blank" rel="external nofollow noopener">Offline Policy Optimization in RL with Variance Regularizaton.</a> </div> <div class="author"> Riashat Islam, Samarth Sinha, Homanga Bharadhwaj, Samin Yeasar Arnob, Zhuoran Yang, <em>Animesh Garg</em>, Zhaoran Wang, Lihong Li, and Doina Precup </div> <div class="periodical"> 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2212.14405" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="lee2019wkspcombining" class="col-sm-9"> <div class="title"> <a href="http://www.robot-learning.ml/2019/files/papers/Guided%20Uncertainty-Aware%20Policy%20Optimization:%20Combining%20Learning%20and%20Model-Based%20Strategies%20for%20Sample-Efficient%20Policy%20Learning.pdf" target="_blank" rel="external nofollow noopener">Combining Model-Free and Model-Based Strategies for Sample-Efficient Reinforcement Learning.</a> </div> <div class="author"> Michelle A. Lee, Carlos Florensa, Jonathan Tremblay, Nathan Ratliff, <em>Animesh Garg</em>, Fabio Ramos, and Dieter Fox </div> <div class="periodical"> 2019 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a href="http://www.robot-learning.ml/2019/files/papers/Guided%20Uncertainty-Aware%20Policy%20Optimization:%20Combining%20Learning%20and%20Model-Based%20Strategies%20for%20Sample-Efficient%20Policy%20Learning.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best paper award at the workshop</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="portwoord2019turbulence" class="col-sm-9"> <div class="title"> <a href="https://ml4physicalsciences.github.io/2019/files/NeurIPS_ML4PS_2019_67.pdf" target="_blank" rel="external nofollow noopener">Turbulence forecasting via Neural ODE.</a> </div> <div class="author"> Gavin Portwood, Peetak Mitra, Mateus Dias Ribeiro, Tan Minh Nguyen, Balasubramanya Nadiga, Juan Saenz, Micheal Chertkov, <em>Animesh Garg</em>, Anima Anandkumar, Andreas Dengel, Richard Baraniuk, and David Schmidt </div> <div class="periodical"> 2019 </div> <div class="links"> <a href="https://ml4physicalsciences.github.io/2019/files/NeurIPS_ML4PS_2019_67.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kuryenkov17corl" class="col-sm-9"> <div class="title"> <a href="https://deformnet-site.github.io/DeformNet-website/files/corl.pdf" target="_blank" rel="external nofollow noopener">Towards Grasp Transfer using Shape Deformation..</a> </div> <div class="author"> Andrey Kuyenkov<sup>*</sup>, Viraj Mehta<sup>*</sup>, Jingwei Ji, <em>Animesh Garg</em>, and Silvio contribution) </div> <div class="periodical"> 2017 </div> <div class="links"> <a href="https://deformnet-site.github.io/DeformNet-website/files/corl.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="/al-folio/assets/pdf/corl17-deformnet_poster" class="btn btn-sm z-depth-0" role="button"><i class="fas fa-tv"></i> Poster</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="xu17corl" class="col-sm-9"> <div class="title"> Hierarchical Task Generalization with Neural Programs. </div> <div class="author"> Danfei Xu, Yuke Zhu, Julian Gao, <em>Animesh Garg</em>, Li Fei-Fei, and Silvio Savarese </div> <div class="periodical"> 2017 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="xu17srssw" class="col-sm-9"> <div class="title"> Hierarchical Task Generalization with Neural Programs. </div> <div class="author"> Danfei Xu, Yuke Zhu, Julian Gao, <em>Animesh Garg</em>, Li Fei-Fei, and Silvio Savarese </div> <div class="periodical"> 2017 </div> <div class="links"> <a href="/al-folio/assets/pdf/files/ntp-rss17-ws.pdf" class="btn btn-sm z-depth-0" role="button"><i class="fas fa-tv"></i> Poster</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mandlekar17rldm" class="col-sm-9"> <div class="title"> <a href="http://www.princeton.edu/%C2%A0ndaw/RLDM17ExtendedAbstracts.pdf#section*.69" target="_blank" rel="external nofollow noopener">Adversarially Robust Policy Learning through Active Construction of Physically-Plausible Perturbations.</a> </div> <div class="author"> Ajay Mandlekar<sup>*</sup>, Yuke Zhu<sup>*</sup>, <em>Animesh Garg<sup>*</sup></em>, Li Fei-Fei, and Silvio contribution) </div> <div class="periodical"> 2017 </div> <div class="links"> <a href="http://www.princeton.edu/%C2%A0ndaw/RLDM17ExtendedAbstracts.pdf#section*.69" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="krishnan2016hirl" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1604.06508" target="_blank" rel="external nofollow noopener">HIRL: Hierarchical inverse reinforcement learning for long-horizon tasks with delayed rewards.</a> </div> <div class="author"> Sanjay Krishnan, <em>Animesh Garg</em>, Richard Liaw, Lauren Miller, Florian T Pokorny, and Ken Goldberg </div> <div class="periodical"> 2016 </div> <div class="links"> <a href="http://arxiv.org/abs/1604.06508" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="garg15visual" class="col-sm-9"> <div class="title"> <a href="http://berkeleyautomation.github.io/tsc-dl/files/gkm-wk_nips15-tsc.pdf" target="_blank" rel="external nofollow noopener">On Visual Feature Representations for Transition State Learning in Robotic Task Demonstrations.</a> </div> <div class="author"> <em>Animesh Garg<sup>*</sup></em>, Sanjay Krishnan<sup>*</sup>, Adithyavairavan Murali, Trevor Darrell, Pieter Abbeel, and Ken contribution) </div> <div class="periodical"> 2015 </div> <div class="links"> <a href="http://berkeleyautomation.github.io/tsc-dl/files/gkm-wk_nips15-tsc.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-file-alt"></i> PDF</a> <a href="http://berkeleyautomation.github.io/tsc-dl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mckinley2015autonomous" class="col-sm-9"> <div class="title"> Autonomous Tumor Localization and Extraction: Palpation, Incision, Debridement and Adhesive Closure with the da Vinci Research Kit. </div> <div class="author"> Stephen McKinley, Siddarth Sen, <em>Animesh Garg</em>, Yiming Jen, David Gealy, Pieter Abbeel, and Ken Goldberg </div> <div class="periodical"> 2015 </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"> <span style="color:DarkOrange; font-weight: bold;"><i class="fas fa-trophy"></i>  Awarded</span> </a> <br> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://www.youtube.com/watch?v=YiPq9t0tR3U" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Video Award</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mckinley2015automated" class="col-sm-9"> <div class="title"> Automated Delivery Instrument for Stem Cell Treatment Using the daVinci Robotic Surgical System. </div> <div class="author"> Stephen McKinley, <em>Animesh Garg</em>, Susan Lim, Sachin Patil, and Ken Goldberg </div> <div class="periodical"> 2015 </div> <div class="links"> <a href="/al-folio/assets/pdf/Stem-Cell-Delivery-Instrument-Poster-06-2015.pdf" class="btn btn-sm z-depth-0" role="button"><i class="fas fa-tv"></i> Poster</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">Theses</h2> <ol class="bibliography" reversed="true"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="garg2016phdthesis" class="col-sm-9"> <div class="title"> Optimization and Design for Automation of Brachytherapy Delivery and Learning Robot-Assisted Surgical Sub-Tasks. </div> <div class="author"> <em>Animesh Garg</em> </div> <div class="periodical"> <em>University of California, Berkeley</em>, 2016 </div> <div class="links"> <a href="http://escholarship.org/uc/item/89k6f68d" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="garg2016msthesis" class="col-sm-9"> <div class="title"> Autonomous Palpation for Tumor Localization: Design of a Palpation Probe and Gaussian Process Adaptive Sampling. </div> <div class="author"> <em>Animesh Garg</em> </div> <div class="periodical"> <em>EECS Department, University of California, Berkeley</em>, 2016 </div> <div class="links"> <a href="http://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-140.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">Patents</h2> <ol class="bibliography" reversed="true"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="pouliot2014patient" class="col-sm-9"> <div class="title"> Patient-Specific Temporary Implants For Accurately Guiding Local Means of Tumor Control Along Patient-Specific Internal Channels to Treat Cancers. </div> <div class="author"> Jean Pouliot, I-Chow Ken Goldberg, J. Adam Cunha, <em>Animesh Garg</em>, Sachin Patil, Pieter Abbeel, and Timmy Siauw </div> <div class="periodical"> <em>US Patent 10,286,197</em>, <em>May</em>, <em>2019</em>, 2016 </div> <div class="links"> <a href="https://patents.google.com/patent/US10286197B2/en" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-link"></i> link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="lim2016precision" class="col-sm-9"> <div class="title"> Precision injector/extractor for robot-assisted minimally-invasive surgery. </div> <div class="author"> Stephen Mckinley, <em>Animesh Garg</em>, Sachin Patil, Susan ML Lim, and Ken Goldberg </div> <div class="periodical"> <em>U.S. Provisional. PCT International Application No.: PCT/US2016/039,026</em>, <em>June</em>, <em>2016</em>, 2016 </div> <div class="periodical"> WO Patent App. PCT/US2016/039,026 </div> <div class="links"> <a href="https://patents.google.com/patent/US20180177558A1/en" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-link"></i> link</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mandlekar2024controlling" class="col-sm-9"> <div class="title"> Controlling position of robot by determining goal proposals by using neural networks. </div> <div class="author"> Ajay Uday Mandlekar, Fabio Tozeto Ramos, Byron Boots, GARG Animesh, and Dieter Fox </div> <div class="periodical"> <em></em>, <em>apr</em>, <em>2024</em>, 2016 </div> <div class="periodical"> US Patent 11,958,529 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mandlekar2023methods" class="col-sm-9"> <div class="title"> Methods and Systems to Remotely Operate Robotic Devices. </div> <div class="author"> Ajay U Mandlekar, Yuke Zhu, GARG Animesh, Silvio Savarese, and Fei-Fei Li </div> <div class="periodical"> <em></em>, <em>jul</em>, <em>2023</em>, 2016 </div> <div class="periodical"> US Patent App. 17/755,587 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="murali2023techniques" class="col-sm-9"> <div class="title"> Techniques for robot control using neural implicit value functions. </div> <div class="author"> Adithyavairavan Murali, Balakumar Sundaralingam, CHEN Yun-Chun, Dieter Fox, and GARG Animesh </div> <div class="periodical"> <em></em>, <em>aug</em>, <em>2023</em>, 2016 </div> <div class="periodical"> US Patent App. 17/856,699 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="ramos2023predicting" class="col-sm-9"> <div class="title"> Predicting object models. </div> <div class="author"> Fabio Tozeto Ramos, GARG Animesh, Krishna Murthy Jatavallabhula, and Miles Macklin </div> <div class="periodical"> <em></em>, <em>dec</em>, <em>2023</em>, 2016 </div> <div class="periodical"> US Patent App. 18/114,146 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="singh2024prompt" class="col-sm-9"> <div class="title"> Prompt generator for use with one or more machine learning processes. </div> <div class="author"> Ishika Singh, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, GARG Animesh, and Valts Blukis </div> <div class="periodical"> <em></em>, <em>mar</em>, <em>2024</em>, 2016 </div> <div class="periodical"> US Patent App. 18/122,594 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="dvornik2024step" class="col-sm-9"> <div class="title"> Step discovery and localization in instructional videos using a self-supervised transformer. </div> <div class="author"> Mikita Dvornik, Isma Hadji, Ran Zhang, Konstantinos Derpanis, Richard Wildes, GARG Animesh, and Allan Douglas Jepson </div> <div class="periodical"> <em></em>, <em>may</em>, <em>2024</em>, 2016 </div> <div class="periodical"> US Patent App. 18/227,560 </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="garg2024scene" class="col-sm-9"> <div class="title"> SCENE UNDERSTANDING USING LANGUAGE MODELS FOR ROBOTICS SYSTEMS AND APPLICATIONS. </div> <div class="author"> <em>Animesh Garg</em>, Dieter Fox, Tucker Ryer Hermans, and Weiyu Liu </div> <div class="periodical"> <em></em>, <em>nov</em>, <em>2024</em>, 2016 </div> <div class="periodical"> US Patent App. 18/319,546 </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">Technical Reports</h2> <ol class="bibliography" reversed="true"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="skreta2024replan" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2401.04157" target="_blank" rel="external nofollow noopener">Replan: Robotic replanning with perception and language models.</a> </div> <div class="author"> Marta Skreta, Zihan Zhou, Jia Lin Yuan, Kourosh Darvish, Alán Aspuru-Guzik, and <em>Animesh Garg</em> </div> <div class="periodical"> 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2401.04157" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/clairify-iros23.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="clairify-iros23.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="skreta2023errors" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2303.14100" target="_blank" rel="external nofollow noopener">Errors are Useful Prompts: Instruction Guided Task Programming with Verifier-Assisted Iterative Prompting.</a> </div> <div class="author"> Marta Skreta, Naruki Yoshikawa, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen, Kourosh Darvish, Alán Aspuru-Guzik, Florian Shkurti, and <em>Animesh Garg</em> </div> <div class="periodical"> 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2303.14100" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/-87yrXytluw" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://ac-rad.github.io/clairify/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="devaguptapu2023deltanetworks" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2303.14772" target="_blank" rel="external nofollow noopener">∆-Networks for Efficient Model Patching.</a> </div> <div class="author"> Chaitanya Devaguptapu, Samarth Sinha, K J Joseph, Vineeth N Balasubramanian, and <em>Animesh Garg</em> </div> <div class="periodical"> 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2303.14772" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/see-pp-2022.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="see-pp-2022.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2210.03825" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2210.03825" target="_blank" rel="external nofollow noopener">See, Plan, Predict: Language-guided Cognitive Planning with Video Prediction.</a> </div> <div class="author"> Maria Attarian, Advaya Gupta, Ziyi Zhou, Wei Yu, Igor Gilitschenski, and <em>Animesh Garg</em> </div> <div class="periodical"> 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2210.03825" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://see-pp.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/chemrobot-arxiv22.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="chemrobot-arxiv22.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yoshikawa2022adaptive" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2212.09672" target="_blank" rel="external nofollow noopener">An Adaptive Robotics Framework for Chemistry Lab Automation.</a> </div> <div class="author"> Naruki Yoshikawa, Andrew Zou Li, Kourosh Darvish, Yuchi Zhao, Haoping Xu, Alan Aspuru-Guzik, <em>Animesh Garg</em>, and Florian Shkurti </div> <div class="periodical"> 2022 </div> <div class="links"> <a href="http://arxiv.org/abs/2212.09672" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a class="venobox btn btn-sm z-depth-0" data-autoplay="true" data-vbtype="video" href="https://youtu.be/NjpZmaKQWls" rel="external nofollow noopener" target="_blank"><i class="fas fa-video"></i> Video</a> <a href="https://ac-rad.github.io/robot-chemist-tamp/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <style>@media(max-width:768px){.preview{display:none!important}}</style> <figure> <picture> <img src="/al-folio/assets/img/publication_preview/audit-ai-banner.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="audit-ai-banner.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="2109.12456" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2109.12456" target="_blank" rel="external nofollow noopener">Auditing AI models for Verified Deployment under Semantic Specifications.</a> </div> <div class="author"> Homanga Bharadhwaj, De-An Huang, Chaowei Xiao, Animashree Anandkumar, and <em>Animesh Garg</em> </div> <div class="periodical"> 2021 </div> <div class="links"> <a href="http://arxiv.org/abs/2109.12456" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://developer.nvidia.com/blog/nvidia-research-auditing-ai-models-for-verified-deployment-under-semantic-specifications/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> <a href="https://sites.google.com/view/audit-ai/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="fas fa-globe"></i> Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="2009.08577" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2009.08577" target="_blank" rel="external nofollow noopener">Making Sense of the Robotized Pandemic Response: A Comparison of Global and Canadian Robot Deployments and Success Factors.</a> </div> <div class="author"> Tim Barfoot, Jessica Burgner-Kahrs, Eric Diller, <em>Animesh Garg</em>, Andrew Goldenberg, Jonathan Kelly, Xinyu Liu, Hani E. Naguib, Goldie Nejat, Angela P. Schoellig, Florian Shkurti, Hallie Siegel, Yu Sun, and Steven Waslander </div> <div class="periodical"> 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2009.08577" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://robotics.utoronto.ca/covid-19-white-paper/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="2007.00177" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/2007.00177" target="_blank" rel="external nofollow noopener">De-anonymization of authors through arXiv submissions during double-blind review.</a> </div> <div class="author"> Homanga Bharadhwaj, Dylan Turpin, <em>Animesh Garg</em>, and Ashton Anderson </div> <div class="periodical"> 2020 </div> <div class="links"> <a href="http://arxiv.org/abs/2007.00177" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> <a href="https://homangab.github.io/ri-blog/2017/06/21/an-overview-of-deep-learning.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-newspaper"></i> Blog</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="1909.02749" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1909.02749" target="_blank" rel="external nofollow noopener">Video Interpolation and Prediction with Unsupervised Landmarks.</a> </div> <div class="author"> Kevin J. Shih, Aysegul Dundar, <em>Animesh Garg</em>, Robert Pottorf, Andrew Tao, and Bryan Catanzaro </div> <div class="periodical"> 2019 </div> <div class="links"> <a href="http://arxiv.org/abs/1909.02749" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="1711.01503" class="col-sm-9"> <div class="title"> <a href="http://arxiv.org/abs/1711.01503" target="_blank" rel="external nofollow noopener">Composing Meta-Policies for Autonomous Driving Using Hierarchical Deep Reinforcement Learning.</a> </div> <div class="author"> Richard Liaw, Sanjay Krishnan, <em>Animesh Garg</em>, Daniel Crankshaw, Joseph E Gonzalez, and Ken Goldberg </div> <div class="periodical"> 2017 </div> <div class="links"> <a href="http://arxiv.org/abs/1711.01503" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"><i class="far fa-bookmark"></i> arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="paluri2010autonomous" class="col-sm-9"> <div class="title"> Autonomous localization and navigation using 2D laser scanners. </div> <div class="author"> Manohar Paluri, <em>Animesh Garg</em>, and Henrik Christensen </div> <div class="periodical"> 2010 </div> <div class="links"> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-2" role="contentinfo"> <div class="container"> © Copyright 2025 PAIR Lab. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/al-folio/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/al-folio/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/al-folio/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/al-folio/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/al-folio/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/venobox@2.1.8/dist/venobox.min.js" integrity="sha256-LsGXHsHMMmTcz3KqTaWvLv6ome+7pRiic2LPnzTfiSo=" crossorigin="anonymous"></script> <script defer src="/al-folio/assets/js/venobox-setup.js?897c1d9c0b6fcf82b949511c1609d055" type="text/javascript"></script> <script src="/al-folio/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/al-folio/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/al-folio/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/al-folio/assets/js/search-data.js"></script> <script src="/al-folio/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>