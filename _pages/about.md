---
layout: about
title: about
permalink: /
subtitle: People, AI & Robots

profile:
  align: left
  image: pair-logo-image.png
  image_circular: false # crops the image to make it circular
  more_info: > #<p>Georgia Tech</p>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

PAIR Lab is directed by [Animesh Garg](https://animesh.garg.tech/) in the [School of Interactive Computing](https://www.ic.gatech.edu/) at [Georgia Tech](https://www.cc.gatech.edu)
Before moving to GT, we are at the [Department of Computer Science](https://web.cs.toronto.edu/) at the [University of Toronto](https://www.utoronto.ca/). 

<br>
Our research vision is to build the **Algorithmic Foundations for Generalizable Autonomy**, that enables robots to acquire skills, at both cognitive & dexterous levels, and to seamlessly interact & collaborate with humans in novel environments. We focus on understanding structured inductive biases and causality on a quest for general-purpose embodied intelligence that learns from imprecise information and achieves flexibility & efficiency of human reasoning.

<br>
[**Research**](/research): Our current research focuses on machine learning algorithms for perception and control in robotics. The principal focus of this research is to understand representations and algorithms to enable the efficiency and generality of learning for interaction in autonomous agents. 
We work on challenging open problems at the intersection of computer vision, machine learning, and robotics. We develop algorithms and systems that unify reinforcement learning, control theoretic modeling, causality, and 2D/3D visual scene understanding to teach robots to perceive and to interact with the physical world. [Read more](/research)

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/res-multimodal-test.gif" class="img-fluid rounded z-depth-1" height="100%" overflow="hidden" zoomable=true %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/res-suturing.gif" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid path="assets/img/res-laikago-dr.gif" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

**Research Interests**: Robotics, Reinforcement Learning, Causality, Perception  
**Current Applications**: Mobile-Manipulation in Retail/Warehouse, Personal/Sevice, and Surgical/Medical robotics.  

----
